# Data cleaning

This section provides an introduction data cleaning. When data is really messy, data cleaning can be a challenging task. We provide some approaches that however, will not include or solve all issues during data cleaning.

```{r}
#| label: read-data-clean
#| echo: false
#| warning: false

exDat <- readRDS("exampleDat.RDS")

```

```{css, echo=FALSE}
.vScrollbar {
  max-height: 250px;
  overflow-y: scroll;
}
```

## Why data cleaning?


The **validity ** of results of statistical data analyses depends on the **quality of the data**. The quality of the data depends on several factors such as:

-   sampling (number of cases, representativeness, etc.)    
-   research design    
-   quality of the survey instrument    
-   operationalization
-   ...
-   **data cleaning & data preparation**


## What is data cleaning?

Data cleaning (or data cleansing) is the process of identifying and correcting errors, inconsistencies, and inaccuracies in the data. It is **always the first step** after data entry or data transfer from external sources.

The steps of data cleaning vary depending on the type and the quality of data. The following steps can be seen as a general outline:

0.  Understand the structure of the data (set) &rarr; Codebook should help
1.  [Remove duplicate observations](#rem-duplicate)      
2.  [Handling missing data](#handle-missing)  
3.  [Plausibility checks](#plaus-checks) (aka data validation)


## How to clean data?

Depending on how much data cleaning is needed, it is recommended to clean data in a sequential way (We like it neat!). This means after we succeed with one step of data cleaning, we save the respective `R`- or `Quarto` script and the data set with an appropriate description. The sequential procedure is exemplified in the [Remove duplicate observations](#rem-duplicate) section.

::: {.callout-important} 

When cleaning a data set, you should **NEVER(!)** replace the raw data with processed data (i.e., overwrite the raw data file). The manipulated data should be assigned to a new object and thereafter **MUST BE** saved as a new file (see also below)!

The file of the raw data should also be a read-only file (i.e., right click on the `file > Properties > Attributes > Read-only`).

:::

 
Because it is also crucial to document the data cleaning process (i.e., to reconstruct all steps), we also recommend to use `Quarto` documents because of the increased readability.




## Remove duplicate observations {#rem-duplicate}

Duplicate observations are identified via the `id` and `variable` values (i.e., response patterns). In @tbl-dup-obs there are 3 different scenarios depicted that are problematic. 

+----+-----------------------------------------+--------+-----------------------------------+
|    | Scenario                                |        | Action                            |
+====+=========================================+========+===================================+
| 1. | Same `id` variable value, and same      | &rarr; | delete one observation            |
|    | variable values (response pattern)      |        |                                   |
+----+-----------------------------------------+--------+-----------------------------------+
| 2. | Same `id` variable value, but different | &rarr; | check data (i.e., questionnaires) |
|    | variable values (response pattern)      |        |                                   |
+----+-----------------------------------------+--------+-----------------------------------+
| 3. | Different `id` variable values, but     | &rarr; | complicated, it is possible, but  |
|    | same variable values (response pattern) |        | check data (i.e., questionnaires) |
+----+-----------------------------------------+--------+-----------------------------------+

: Overview of duplicate observations scenarios {#tbl-dup-obs}

::: {.callout-tip collapse="true" appearance="simple" title="Tip: Think carefully about the identification variables!"} 

Identification (ID) variables are eminent when working on projects that contain several sources (e.g., different questionnaires), or span across multiple years (e.g., longitudinal studies) and must be **planned before the data collection**.

ID variables should be ...

- uniquely identifying &rarr; no duplicates

- fully identifying &rarr; all observations have an ID variable value

- constant throughout the duration of projects &rarr; observations do not have different IDs in a other datasets 

- anonymous 

For more see here: <https://dimewiki.worldbank.org/ID_Variable_Properties>


:::


The procedure is as follows:

1.  Find duplicate observations    
2.  Exclude real (!) duplicates (but consult your supervisors!)

::: {.callout-warning collapse="false" appearance="simple" title="Generate some duplicate observations."}

The example data set `exDat` does not contain any duplicate observations. Hence, we have to create them. This is done with the `rbind` function (i.e., adding the first five rows `[1:5]` of the `exDat` data set to the `exDat` data set).

```{r}
#| label: add-dup-obs
#| code-fold: false
#| code-line-numbers: true


exDatID <- rbind(exDat,exDat[1:5,])
exDatID[c(751, 752),"id"] <- c(751, 752)
exDatID[6,"id"] <- 7
nrow(exDatID)
```

::: {.callout-imporant}
**!! Do not do this with real data !!**
:::

:::



How to find and remove duplicate observations via the `id` and `variable` values? In the following there are a base `R` and a `dplyr` [@R-dplyr] solution. Both approaches use the `duplicated()` function which requires a `vector`, a `data frame` or an `array` as input `x`. The output is logical vector (`TRUE`/`FALSE`) of the same length as `x`.


::: {.panel-tabset}
### Base R

The `duplicated()` function checks for each value whether it is duplicated.  In combination with the `which()` function, checking which indices are `TRUE`, we can extract the duplicates.

1. Check for duplicate `id` values. The procedure contains 4 steps.

```{r}
#| label: show-dup
#| code-line-numbers: true
#| 
exDatID$dupID <- ifelse ( duplicated(exDatID$id), "dup"," ")

whichID <- exDatID[which(exDatID$dupID == "dup"), "id"]

dupIDs <- exDatID[exDatID$id %in% whichID,]
dupIDs[order(dupIDs$id),]
```


Exclude duplicates... add here

```{r}


exDatID$dupID <- NULL
```

By negating the function (`!duplicated()`), duplicates can be excluded.

```{r}
#| class-output: vScrollbar
exDatID[which(!duplicated(exDatID$id)), ]
```

### dplyr package

Filtering can be done using the `dplyr::filter()` function in combination with `duplicated()`.

```{r}
exDatID |> 
  dplyr::filter(duplicated(id))
```

However, `dplyr` provides a function `dplyr::distinct()` which can be used to keep only unique rows.

```{r}
#| class-output: vScrollbar
dplyr::distinct(exDatID)
```
:::

::: {.callout-caution collapse="true"}
## Exercise: Remove duplicates!

Remove all duplicates contained in `exampleDat_ID.RDS` and assign the dataFrame to an object named `exDat_uniqueID`.

:::



## Handling missing data {#handle-missing}

Missing data is a common problem in most behavioral science research [@Enders2010; @Enders2023;@Schafer2002]. Especially, in questionnaire surveys it is unavoidable that values are missing because a field of the questionnaire was not filled in or a person dropped out of the study. Therefore, it is essential to examine the data with regard to missing data. By missing values, we refer to cells that could have a value, but whose value is not available (see section on [Data Types](intro-r-rstudio.qmd#data-types) in the [Introduction to R & RStudio](intro-r-rstudio.qmd) part).

The procedure encompasses ~~3~~ 2 steps:

1.  [Define missing values](#def-miss) 
2.  [Examine missing values](#examine-miss)  
3.  ([Omit missing values](#omit-miss) &rarr; usually **not** recommended)


### Define missing values {#def-miss}

In other statistical software programs (e.g., SPSS) or in study planning, missing values are often defined as numeric values (e.g., `-9`, `-88` or `-99`)^[Note that this is also recommended when designing a codebook, see here: <https://datawizkb.leibniz-psychology.org>] or as empty characters/strings (i.e., `""` or `" "`). In `R`, missing values are represented by the symbol `NA` (not available). This means, the first step is to ensure that all missing values are declared as `NA` in the data set.

::: {.callout-warning collapse="false" appearance="simple" title="Assign -99 values"}

The example data set `exDat` does also not contain any missing values that are not `NA` values. Hence, we have to create them. With the following code, we assign the values `-99` to the first 5 rows of the variable `age` and `-88` to the first 4 rows of the variables `sex` and `edu` (and store it in a new data set `exDatMis`).

```{r}
#| label: add-99
#| code-fold: false
#| code-line-numbers: false
exDatMis <- exDat
exDatMis[1:5, "age"] <- -99
exDatMis[1:4,c("sex", "edu")] <- -88
head(exDatMis, 6)
```


**!! Do not do this with real data !!**


:::

To demonstrate the effect, we calculate the mean of the variable `age` in the `exDat` and `exDatMis` data set:

```{r}
#| label: demo--99
#| code-fold: false
#| layout-ncol: 2

mean(exDat$age, na.rm = T)
mean(exDatMis$age, na.rm = T)
```

To set the numeric values of `-99` or `-88` to `NA`, we may use one of the following two approaches:

::: {.panel-tabset}
### Base R

For a single variable:

```{r}
#| label: declare-miss
#| code-fold: false
exDatMis$age[exDatMis$age == -99] <- NA
```

For multiple variables:

```{r}
#| label: declare-miss-mult-var
#| code-fold: false

colToNa <- c("sex", "edu")
exDatMis[colToNa][exDatMis[colToNa] == -88] <- NA
```

For the whole data set:

```{r}
#| label: declare-miss-whole
#| code-fold: false
#| eval: false
exDatMis[exDatMis == -99] <- NA
```

### dplyr package

The `na_if()` function from the `dplyr` package [@R-dplyr] is designed to to convert a (specific) values to `NA`.

For a single variable:

```{r}
#| label: declare-miss-dply
#| code-fold: false
#| eval: false

exDatMis$age <- dplyr::na_if(exDatMis$age, -99)
```

For multiple variables:

```{r}
#| label: declare-miss-mult-var-dplyr
#| code-fold: false
#| eval: false
colToNa <- c("sex", "edu")
exDatMis <- exDatMis |>
  dplyr::mutate(dplyr::across(colToNa, na_if, y = -88)) 
```


For the whole data set:

```{r}
#| label: declare-miss-whole-dplyr
#| code-fold: false
#| eval: false


exDatMis <- exDatMis |>
  dplyr::mutate(dplyr::across(colnames(exDatMis), na_if, y = -88))
```

But note that `na_if()` is meant for use with vectors rather than entire data frames.

:::




### Examine missing values {#examine-miss}

The `is.na` function indicates which elements are missing. It requires an input `x` that can be e.g., a `vector`, `data.frame` or `list`. The values that are returned depend on the input. For example, when you pass a `vector` to the function, it returns a `logical` `vector` of the same length as its argument `x`, containing `TRUE` for those elements marked `NA` or, for `numeric` or complex `vectors`, `NaN`, and `FALSE` otherwise.

```{r}
#| label: demo-isna
#| code-fold: false
is.na(
  c(1, NA, "hello", NaN, " ")
  )


```
In the following, we show how the `is.na` function may be applied to variables within a data set. To count the missing values (or to be more specific the returned `TRUE` values), we use the `sum` and `colSums` functions. 

::: {.callout-tip collapse="true" appearance="simple" title="Tip: summary() of a data.frame"}
The `summary()` function returns beside some descriptive statistics (e.g., minimum, maximum, mean, ...), also the amount of `NA`s of each variable of the given data set.

```{r}
#| label: demo-summary-miss
#| code-fold: false
summary(exDat)
```

:::


::: {.panel-tabset}
### Base R

For a single variable:

```{r}
#| label: demo-count-miss-single
#| code-fold: false

sum(is.na(exDat$msc2))

```

For multiple variables:

```{r}
#| label: demo-count-miss-mult
#| code-fold: false

colSums(is.na(exDat[,c("msc2", "sex", "edu")]))


```

For the whole data set:

```{r}
#| label: demo-count-miss-whole
#| code-fold: false

colSums(is.na(exDat))


```

### dplyr package

For a single variable:

```{r}
#| label: demo-count-miss-single-dplyr
#| code-fold: false
exDat |>
  dplyr::select(msc2) |>
  is.na() |>
  sum()
```


For multiple variables:

```{r}
#| label: demo-count-miss-mult-dplyr
#| code-fold: false

exDat |>
  dplyr::select(c("msc2", "sex", "edu")) |>
  is.na() |>
  colSums()
  


```

For the whole data set:

```{r}
#| label: demo-count-miss-whole-dplyr
#| code-fold: false

exDat |>
  is.na() |>
  colSums()

```

:::


::: {.callout-caution collapse="true"}
## Exercise: Count the missing values!

0. Create a `R`- or `Quarto` script/document.

1. Import the data set `` from the github repository 

2. Identify and define the missing values as `NA`

3. Count them for the whole data set.


:::



### Omit missing values {#omit-miss}

Although omitting or deleting missing values is a common practice, this is not a recommended approach handling missing data and should--in most data scenarios--be avoided altogether [@Schafer2002]. Two "state-of-the-art" missing data methods are maximum likelihood estimation [e.g., implemented in the `lavaan` package, see @R-lavaan] and multiple imputation [e.g., implemented in the `mice` package, see @R-mice; for good introductions to this topic, see @Enders2010].

Nevertheless, if you would like to omit missing values anyway, there are several functions to do this in `R`. Also, it is important to note that ignoring or omitting missing values are often the default options in `R`.

For example, by negating the `is.na` function (i.e., `!is.na`), those rows that do not contain `NA`s on a variable or data set are kept.

::: {.panel-tabset}

### Base R

For a single variable:

```{r}
#| label: omit-na-single
#| code-fold: false
#| class-output: vScrollbar

exDat[!is.na(exDat$age), ]

```


For the whole data set:

The `na.omit` function returns the object with incomplete cases removed.

```{r}
#| label: omit-na-data
#| code-fold: false
#| class-output: vScrollbar

exDatnoNA <- na.omit(exDat)
exDatnoNA
```

### dplyr package

To exclude observations that do have missing values, we may use the `filter` function from the `dplyr` package. 

For a single variable:

```{r}
#| label: omit-na-single-dplyr
#| code-fold: false
#| class-output: vScrollbar

exDat |>
  dplyr::filter(!is.na(age))
```

For the whole data set:

```{r}
#| label: omit-na-whole-dplyr
#| code-fold: false
#| class-output: vScrollbar

exDatnoNA <- exDat |>
  dplyr::filter() |>
  na.omit()
exDatnoNA
```

:::



## Plausibility checks {#plaus-checks}


So-called plausibility checks are performed in order to detect:

-   structural errors &rarr; e.g., the range of a lickert scale is from 1 to 4, but the value 5 occurs  
-   theoretical inconsistencies &rarr; e.g., 30 years of age in sample of primary students   
-   (statistical) outliers &rarr; see Excursus on outlier [below](#excurs-outlier)


::: {.callout-note collapse="true" appearance="simple"}
## Excursus: Outliers {#excurs-outlier}

According to [wikipedia](https://en.wikipedia.org/wiki/Outlier), outliers can be defined as a data point that differs significantly from other observations.

Outliers may occur due to different reasons:

- data entry errors
- measurement error
- "true" extreme values 

Outliers must be detected, because they may introduce bias into parameter estimates of statistical models and hence, compromise the validity of the results.

Different ways of detecting outliers:    

-   Z-score (e.g., above or below $3SD$)
-   Visualization (e.g., box plots, histograms, or scatter plot) 
-   Mahalanobis distance
- ...



:::

Plausibility checks can be performed both analytically and graphically. The `range` function is a useful function to quickly examine the minimum and maximum of variables that are no characters/string variables (i.e., `!is.character`).

::: {.panel-tabset}
### Base R

1. Identify all non-character variables using the `!is.character` function within a `lapply` loop. Because `lapply` returns a list, we need to `unlist` the output to get a logical vector.

```{r}
#| label: check-range-1
#| code-line-numbers: true

nChrV <- unlist(lapply(exDatMis,
                         function(x) !is.character(x)),
                use.names = FALSE)
#class(nChrV)
```

2. Then we can apply the `range` function to the respective variable within the `exDatMis`.

::: {.callout-tip collapse="true" appearance="simple"}
## Tip: The apply function {#apply-func}

The `apply` function is designed to apply functions (e.g., `range`) over array margins (e.g., rows or columns) and needs the following arguments (copied from the function description):

- `X`: an array, including a matrix.
- `MARGIN`: a vector giving the subscripts which the function will be applied over. E.g., for a matrix 1 indicates rows, **2 indicates columns**, c(1, 2) indicates rows and columns. Where X has named dimnames, it can be a character vector selecting dimension names.
- `FUN`: the function to be applied: see ‘Details’.

:::

```{r}
#| label: check-range-2
#| code-line-numbers: true
apply(exDatMis[,nChrV],
      2,
      FUN = range, na.rm=TRUE)

```
### dplyr package

In the `dplyr` package we first use the `select` function (i.e., to select the variables) in combination with `where` function to identify all non-character variables by stating `!is.character`. Then applying the `range` function on very variable in the data set.

```{r}
#| label: check-range-dplyr

exDatMis |>
  dplyr::select(
    dplyr::where(~!is.character(.))
    ) |>
  dplyr::summarise_all("range", na.rm = TRUE)

```

:::


::: {.callout-caution collapse="true"}
## Exercise: Make the value 30 of the age variable to NA.

1. Identify the observation, using the `which` function.

```{r}
#| label: ident-age-30
#| code-fold: false
exDat[which(exDat$age == 30),c("id", "age")]

```

2. Set the value to `NA`

```{r}
#| label: make-age-30-NA
#| code-fold: false
exDat[which(exDat$age == 30),"age"] <- NA

```

:::



### Categorical variables

#### Frequencies/Counts

To do further plausibility checks on categorical variable, we may examine counts at each combination of factor levels (e.g., examine extreme responses in one category).

::: {.panel-tabset}
##### Base R

The `table` function builds a contingency table of the counts at each combination of factor levels. 

::: {.callout-note collapse="true" appearance="simple"}

Note that by default, `NA`s are not included in the `table` function. To include `NA`s, we need to change the `useNA` argument to `"ifany"` (only if the count is positive) or `"always"` (even for zero counts).

:::

```{r}
#| label: clean-demo-table
#| code-fold: false
table(exDatMis$edu, useNA = "always")
```

##### dplyr package

The `dplyr` approach is using the `count` function that counts the unique values of one or more variables.

```{r}
#| label: clean-demo-count
#| code-fold: false
exDatMis |>
  dplyr::count(edu) 

```

:::

#### Graphical inspection using bar charts 

Bar charts are one way of graphically checking the plausibility of discrete variables. Plots can be created with `R` [@R-base], as shown below. However, there are also packages like `ggplot2` [@R-ggplot2] that are specifically designed for data visualization. See the [tidyverse documentation](https://ggplot2.tidyverse.org/) of `ggplot2-package` for more details.

```{r}
#| label: fig-bar-charts
#| fig-cap: "Frequencies of the education expression in the example data set"
#| eval: false


barplot(table(exDat$edu, useNA = "always"),
        names.arg = c(0:4, "NA"),
        main = "Education in example data set", # plot title
        xlab = "exDat$edu", # x-axis label
        ylab = "Count",  # y-axis label
        ylim = c(0, 300) # y-axis range
        )
```





:::

### Continious variables

#### ...

#### Graphical inspection using histogram

Boxplots allow visualization of the most important robust measures of location and dispersion.

![Different parts of a boxplot ([Galarnyk, 2019](https://www.kdnuggets.com/2019/11/understanding-boxplots.html))](images/parts-of-boxplot.png)

```{r}
#| label: fig-range-of-items-boxplots
#| fig-cap: "Ranges of all discrete variables in example data set"
#| eval: false


boxplot(exDat[, -5],
        main = "Ranges of all discrete variables in example data set", # plot title
        xlab = "Variables", # x-axis label
        ylab = "Range" # y-axis label
        )
```


Histograms are graphical representations of frequency distributions of metric variables. Just like [bar charts](#bar-charts), these visualizations can be modified more using packages like `ggplot2` [@R-ggplot2].

```{r}
#| label: fig-histogram
#| fig-cap: "Frequency distribution of age in example data set"
#| eval: false

hist(exDat$age,
     main = "Age in example data set",
     breaks = 20,
     xlim = c(min(round(exDat$age), na.rm = T) - 1,
              max(round(exDat$age), na.rm = T) + 1),
     ylim = c(0, 100))
```




