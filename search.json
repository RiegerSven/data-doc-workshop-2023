[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data documentation with R and Quarto",
    "section": "",
    "text": "Preface & Preperation\nThis Quarto book is designed to provide an introduction into data documentation with R and Quarto and serves as the accompanying script for the workshop. For an overview about the workshop agenda see the Introduction section.\nPlease prepare yourself by following the steps below:\nIf you encounter any problems, please send us an email."
  },
  {
    "objectID": "index.html#software-install",
    "href": "index.html#software-install",
    "title": "Data documentation with R and Quarto",
    "section": "Software installation",
    "text": "Software installation\nPlease install the following software and make sure that you are download the latest (released!) version of each program:\n\nR v4.2.3 (R Core Team 2023): https://cran.r-project.org/bin/windows/base/\nRStudio v2023.3.0.386 (Posit team 2023): https://posit.co/downloads/\nQuarto v1.3 (Allaire 2022): https://quarto.org/docs/get-started/"
  },
  {
    "objectID": "index.html#pkg-install",
    "href": "index.html#pkg-install",
    "title": "Data documentation with R and Quarto",
    "section": "Package installation",
    "text": "Package installation\n\nR is an integrated suite of software facilities for data manipulation, calculation and graphical display (see https://www.r-project.org).\n\nR is–among other things–great, because there is a large collection of packages. During the workshop, we will use the following R packages:\n\nShow/hide codepkgList &lt;- c(\"rmarkdown\",\n             \"knitr\", # tables\n             \"kableExtra\", # tables\n             \"data.table\", # rbindlist function\n             \"lavaan\", # generate data\n             \"dplyr\", # prepare data\n             \"car\", # recoding\n             \"psych\", # descriptive statistics\n             \"ggplot2\") # plots\n\n\n\nrmarkdown v2.21 (Allaire et al. 2023)\n\nknitr v1.42 (Xie 2023)\n\nkableExtra v1.3.4 (Zhu 2021)\n\ndata.table v1.14.8 (Dowle and Srinivasan 2023)\n\nlavaan v0.6.15 (Rosseel, Jorgensen, and Rockwood 2023)\n\ndplyr v1.1.1 (Wickham, François, et al. 2023)\n\ncar v3.1.1 (Fox, Weisberg, and Price 2022)\n\npsych v2.3.3 (Revelle 2023)\n\nggplot2 v3.4.1 (Wickham, Chang, et al. 2023)\n\n\nYou can install them (check the versions!) with the following code:\n\nShow/hide codelapply(pkgList,\n       function(x) \n         if(!x %in% rownames(installed.packages())) install.packages(x))\n\n\nThe book was last rendered on 28 March 2023.\n\n\n\n\n\n\nInformation About the Current R Session\n\n\n\n\n\n\nShow/hide codesessionInfo()\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.utf8     LC_CTYPE=German_Germany.utf8      \n[3] LC_MONETARY=German_Germany.utf8    LC_NUMERIC=C                      \n[5] LC_TIME=English_United States.1252\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.5.4 compiler_4.2.3    fastmap_1.1.0     cli_3.3.0        \n [5] tools_4.2.3       htmltools_0.5.4   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.21    knitr_1.42        jsonlite_1.8.4    xfun_0.36        \n[13] digest_0.6.29     rlang_1.1.0       evaluate_0.19    \n\n\nNote that we often did not load the packages, but use the function via :: (e.g., psych::describe())."
  },
  {
    "objectID": "index.html#gen-dat",
    "href": "index.html#gen-dat",
    "title": "Data documentation with R and Quarto",
    "section": "Data set",
    "text": "Data set\nFinally, we will use an (simulated) example data set. To get it, execute the following code:\n\nShow/hide codePopMod &lt;- \"\neta1 =~ .8*msc1 + .8*msc2 + -.8*msc3 + -.8*msc4\neta1 ~~ 1*eta1\neta1 ~ 0*1\n\nmsc3 ~~ .2*msc4\n\nmsc1 | -1.5*t1 + 0*t2 + 1.5*t3\nmsc2 | -1.5*t1 + 0*t2 + 1.5*t3\nmsc3 | 1.5*t1 + 0*t2 + -1.5*t3\nmsc4 | 1.5*t1 + 0*t2 + -1.5*t3\n\nage ~ 10*1\nage ~~ 2.5*age\n\nsex | 0*t1\nsex ~*~ .5*sex\n\neta1 ~~ age + sex\n\"\n\nexDat &lt;- lavaan::simulateData(model = PopMod,\n                              sample.nobs = seq(50,250, by = 50),\n                              seed = 999)\n\n\nSome cosmetics, and “adding” missing data.\n\nShow/hide codeexDat$sex &lt;- exDat$sex-1\nexDat$edu &lt;- exDat$group-1\nexDat$group &lt;- NULL\n\npropMiss1 &lt;- .05\npropMiss2 &lt;- .1\n\nexDat$sex &lt;- ifelse (\n  rbinom(\n    nrow(exDat),\n    size = 1,\n    propMiss1) == 1,\n  NA,\n  exDat$sex\n  )\n\nexDat$age &lt;- ifelse (\n  rbinom(\n    nrow(exDat),\n    size = 1,\n    propMiss2) == 1,\n  NA,\n  exDat$age\n  )\n\nexDat$msc2 &lt;- ifelse (\n  rbinom(\n    nrow(exDat),\n    size = 1,\n    propMiss2) == 1,\n  NA,\n  exDat$msc2\n  )\n\n\n\n\n\n\n\n\nSome descriptive statistics\n\n\n\n\n\n\n\n\nDescriptive statistics of the generated data \n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nmsc1\n1\n750\n2.52\n0.74\n3.00\n2.52\n1.48\n1.00\n4.00\n3.0\n-0.02\n-0.31\n0.03\n\n\nmsc2\n2\n680\n2.54\n0.72\n3.00\n2.53\n1.48\n1.00\n4.00\n3.0\n-0.02\n-0.27\n0.03\n\n\nmsc3\n3\n750\n2.49\n0.75\n2.00\n2.49\n1.48\n1.00\n4.00\n3.0\n0.00\n-0.34\n0.03\n\n\nmsc4\n4\n750\n2.48\n0.75\n2.00\n2.48\n1.48\n1.00\n4.00\n3.0\n0.06\n-0.33\n0.03\n\n\nage\n5\n670\n10.01\n1.58\n10.03\n10.02\n1.46\n5.44\n14.84\n9.4\n-0.06\n0.07\n0.06\n\n\nsex\n6\n711\n0.50\n0.50\n0.00\n0.50\n0.00\n0.00\n1.00\n1.0\n0.01\n-2.00\n0.02\n\n\nedu\n7\n750\n2.67\n1.25\n3.00\n2.79\n1.48\n0.00\n4.00\n4.0\n-0.59\n-0.73\n0.05\n\n\n\n\n\n\n\n\nCorrelation table of the generated data \n\n\nmsc1\nmsc2\nmsc3\nmsc4\nage\nsex\nedu\n\n\n\nmsc1\n1.00\n\n\n\n\n\n\n\n\nmsc2\n0.54\n1.00\n\n\n\n\n\n\n\nmsc3\n-0.59\n-0.55\n1.00\n\n\n\n\n\n\nmsc4\n-0.58\n-0.53\n0.72\n1.00\n\n\n\n\n\nage\n-0.02\n0.03\n0.04\n0.04\n1.00\n\n\n\n\nsex\n0.05\n0.02\n-0.04\n-0.02\n-0.04\n1.00\n\n\n\nedu\n0.01\n-0.03\n0.00\n0.05\n-0.03\n-0.04\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAllaire, JJ. 2022. Quarto: R Interface to Quarto Markdown Publishing System. https://github.com/quarto-dev/quarto-r.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2023. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown.\n\n\nDowle, Matt, and Arun Srinivasan. 2023. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nFox, John, Sanford Weisberg, and Brad Price. 2022. Car: Companion to Applied Regression. https://CRAN.R-project.org/package=car.\n\n\nPosit team. 2023. RStudio: Integrated Development Environment for r. Boston, MA: Posit Software, PBC. http://www.posit.co/.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRevelle, William. 2023. Psych: Procedures for Psychological, Psychometric, and Personality Research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf.\n\n\nRosseel, Yves, Terrence D. Jorgensen, and Nicholas Rockwood. 2023. Lavaan: Latent Variable Analysis. https://lavaan.ugent.be.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nXie, Yihui. 2023. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome\n\nWho are we?\nWhy this workshop?\n\n\n\nSome words regarding data sets\n\nCosts\nResponsibility\n\n\n\nWhat awaits you in the workshop?\n\nInput\nExercises\n\n\n\nAgenda\n\nsee on the left, and thereafter, on the right!\n\n\n\nMaterial\n\nAll material can be found on the network drive L"
  },
  {
    "objectID": "gen-info.html#what-is-data-documentation",
    "href": "gen-info.html#what-is-data-documentation",
    "title": "\n1  General information on data documentation\n",
    "section": "\n1.1 What is data documentation?",
    "text": "1.1 What is data documentation?\n\nData documentation is a central part of data management1 in general and is part of the DFG Guidelines for safeguarding good scientific research practice (code of conduct)\n\nGuideline 12: Documentation (for more see below)\n\n\n\n\n\n\n\n\n\nGuideline 12: Documentation\n\n\n\n\n\n\nResearchers document all information relevant to the production of a research result as clearly as is required by and is appropriate for the relevant subject area to allow the result to be reviewed and assessed. In general, this also includes documenting individual results that do not support the research hypothesis. The selection of results must be avoided. Where subject-specific recommendations exist for review and assessment, researchers create documentation in accordance with these guidelines. If the documentation does not satisfy these requirements, the constraints and the reasons for them are clearly explained. Documentation and research results must not be manipulated; they are protected as effectively as possible against manipulation.\n\nExplanations:\n\nAn important basis for enabling replication is to make available the information necessary to understand the research (including the research data used or generated, the methodological, evaluation and analytical steps taken, and, if relevant, the development of the hypothesis), to ensure that citations are clear, and, as far as possible, to enable third parties to access this information. Where research software is being developed, the source code is documented.\n\n\n\n\n\nData documentation is a continuous process and it should start at the beginning (see e.g., Figure 1.1) of each project that collects (any kind of) data\n\n\n\nFigure 1.1: Proposed institutional research data management workflow by Wissik and Ďurčo (2015)\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the following, we restrict the term data documentation to the documentation of a single data set."
  },
  {
    "objectID": "gen-info.html#who-uses-data-documentation",
    "href": "gen-info.html#who-uses-data-documentation",
    "title": "\n1  General information on data documentation\n",
    "section": "\n1.2 Who uses data documentation?",
    "text": "1.2 Who uses data documentation?\nEverybody who works with the data set(s). It serves as a guidance, especially for people who did not collect the data themselves."
  },
  {
    "objectID": "gen-info.html#how-is-data-documentation-structured",
    "href": "gen-info.html#how-is-data-documentation-structured",
    "title": "\n1  General information on data documentation\n",
    "section": "\n1.3 How is data documentation structured?",
    "text": "1.3 How is data documentation structured?\nData documentation include several parts:\n\nGeneral information on the data set and the usage of it\nDocumentation of the survey process\n\nInformation about the variables (e.g., demographic variables), (achievement) tests, items and scales\n\nScale level\nItem wording\nDescriptive Statistics (e.g., \\(N, M, SD,Min, Max,...\\); for more see below)\nCross-references to other studies\nSources\n\n\nBibliography\n\nAn example of a table of conents of a so-called “Skalenhandbuch” can be seen in Figure 1.2.\n\n\nFigure 1.2: Example of table of conents of a scale manual"
  },
  {
    "objectID": "gen-info.html#procedure-of-data-documentation",
    "href": "gen-info.html#procedure-of-data-documentation",
    "title": "\n1  General information on data documentation\n",
    "section": "\n1.4 Procedure of data documentation",
    "text": "1.4 Procedure of data documentation\n\n1.4.1 Basis\nThe basis of data documentation are the:\n\ncodebooks & questionnaires\nthe (final) data sets\n\nTo get an overview, you should start with carefully reviewing these sources and think about a meaningful structure and order.\n\n\n\n\n\n\nTip: How to design codebooks?\n\n\n\nYou can find some information at the https://datawizkb.leibniz-psychology.org website.\n\n\n\n1.4.2 Order\n\n\nIt is advisable to group the variables according to their content. In the following example variable clusters are listed:\n\nSocio-demographic variables (e.g., age, sex, family background, income, household, …)\nTests (e.g., school achievement tests, tests on cognitive ability)\nPsycho-social variables (e.g., Self-concepts, motivation, personality)\n…\n\n\nAlso, related scales should be reported together within a respective variable cluster (e.g., math, English and German self-concept scales)\nDiscuss the concrete order of the variables with your supervisor\nNames of variables, items and scales must be identical across codebooks, questionaires, and data sets\n\n1.4.3 Template\n\n\n\n\n\n\nImportant\n\n\n\nYou should always use a template! You can find it/them on the network drive L, too.\n\n\nThere are two options:\n\nCalculate the required statistics and transfer the values into one of the millions word templates (not recommended)\n\nUse the Quarto template (recommended)\n\nfor now the template generates only html2 documents\n\n\n\n1.4.4 Functions\nThe following functions were written to make your job a little bit easier.\n\nIf you know what you are doing, feel free to change or adjust them.\nIf you need more or other functions, please write us an email.\n\n\n\n\n1.4.4.1 Table for variable overview (not finished)\n\nThe varOverview function translates the general information into a table and has the following arguments:\n\n\nname: Name of the variable\n\ntype: Input is a character: Either variable or scale\n\n\nitemword: Requires a named list as input. Should contain the names and wording of the items.\n\nquestionaire: Input is a character: Which questionnaire?\n\nprompt: Input is a character. Wording of the question,\n\nresponse: Input is a character. Response format.\n\ncross: Input is a character. Cross-reference to other studies.\n\nsource: Input is a character. Potential reference.\n\nnote: Input is a character. Room for additional notes.\n\n\nShow/hide functionvarOverview &lt;- function ( name,\n                          type = \"variable\",\n                          itemword = NULL,\n                          questionaire = NULL,\n                          prompt = NULL,\n                          response = NULL,\n                          cross = NULL,\n                          source = NULL,\n                          note = NULL) {\n  \n  if (type == \"variable\") {\n    namDes &lt;- \"Name of variable:\"\n  }\n  \n  if (type == \"scale\") {\n    namDes &lt;- \"Name of scale:\"\n  }\n  \n  if (type == \"scale\" & is.null(itemword) ) {\n    stop(\"please provide the itemwording of the items\")\n  } \n  \n  if(!is.null(itemword)) {\n    \n    if ( is.null(names(itemword)) ) {\n      stop(\"please provide a named list as input: e.g., list(item1 = c('I like apples.'\")\n      \n      \n    } else {\n      \n      itemLab &lt;- names(itemword)\n      itemword &lt;- unlist(itemword)\n      \n      }\n    \n    \n    \n  } else {\n    \n    itemLab &lt;- NULL\n    itemword &lt;- NULL\n    \n  }\n  \n  \n  if (!is.null(questionaire)) {\n    \n    questLab &lt;- \"Questionaire:\"\n    questionaire &lt;- paste0(questionaire, collapse = \"; \")\n    \n  } else {\n    \n    questLab &lt;- NULL\n    \n  }\n  \n  if (!is.null(prompt)) {\n    \n    promptLab &lt;- \"Prompt in Questionaire:\"\n    prompt &lt;- paste0(prompt, collapse = \":\")\n    \n  } else {\n    \n    promptLab &lt;- NULL\n    \n  }\n  \n  if (!is.null(response)) {\n    \n    responseLab &lt;- \"Response format:\"\n    response &lt;- paste0(response, collapse = \"; \")\n    \n  } else {\n    \n    responseLab &lt;- NULL\n    \n  }\n  \n  if (!is.null(cross)) {\n    \n    crossLab &lt;- \"Cross reference:\"\n    cross &lt;- paste0(cross, collapse = \"; \")\n    \n  } else {\n    \n    crossLab &lt;- NULL\n    \n  }\n  \n  if (!is.null(source)) {\n    \n    sourceLab &lt;- \"Source:\"\n    source &lt;- knitr::asis_output(paste0(source, collapse = \"; \"))\n    \n  } else {\n    \n    sourceLab &lt;- NULL\n    \n  }\n  \n  if (!is.null(note)) {\n    \n    #generalTitel &lt;- \"Note:\"\n    noteLab &lt;- \"Note:\"\n    note &lt;- paste0(note, collapse = \"; \")\n    \n  } else {\n    \n    #generalTitel &lt;- \"\"\n    noteLab &lt;- NULL\n    \n  }\n  \n  tempTab &lt;- data.frame(\n    \"Col1\" = c(namDes,\n               questLab,\n               promptLab,\n               responseLab,\n               crossLab,\n               sourceLab,\n               noteLab,\n               \"\",\n               itemLab),\n    \"Col2\" = c(name,\n               questionaire,\n               prompt,\n               response,\n               cross,\n               source,\n               note,\n               \"\",\n               itemword)\n    )\n  \n  kableExtra::kbl(tempTab,\n               col.names = NULL,\n               align = \"l\"\n               ,booktabs = TRUE\n               ) |&gt;\n    kableExtra::kable_styling(\n      full_width = TRUE,\n      bootstrap_options = c(\"hover\", \"responsive\")\n      , latex_options = \"HOLD_position\"\n      ) |&gt;\n    kableExtra::column_spec(column = 1, width = \"12em\")\n  \n}\n\n\nAn example execution.\n\nShow/hide codevarOverview(name = \"gender\",\n            prompt = \"The question in the questionaire...\",\n            response = c(\"0 = male\",\n                         \"1 = female\",\n                         \"2 = divers\"),\n            cross = c(\"A study\", \"Another study\"),\n            source = \"@Kunter2002\",\n            note = \"Here is room for some notes\")\n\n\n\n\nTable 1.1: Variable: gender\n\n\nName of variable:\ngender\n\n\nPrompt in Questionaire:\nThe question in the questionaire...\n\n\nResponse format:\n0 = male; 1 = female; 2 = divers\n\n\nCross reference:\nA study; Another study\n\n\nSource:\n@Kunter2002\n\n\nNote:\nHere is room for some notes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe reference is not rendered correctly. This is a known bug: see here: https://github.com/quarto-dev/quarto-cli/issues/3340 and will be hopefully solved in the next release.\n\n\n\n1.4.4.2 Continuous variables\nThe contVar function is based on the describe function from the psych package (Revelle 2023) and has the following arguments:\n\n\nvariable: This should be a character or a character vector (name of variable)\n\ndata: The data frame\n\nwhich.stat: Which statistics should be calculated? Default is: N, Mean, SD, Min, Max. Because the function is based on the describe function from psych package, you can also request: trimmed mean, median, mad, skew, kurtosis, standard error.\n\ntable: logical. Default is TRUE. Then the output is printed as a table using the kbl function from the kableExtra package (Zhu 2021). If set to false, the output is printed as a data.frame.\n\n\nShow/hide functioncontVar &lt;- function ( variable,\n                      data,\n                      which.stat = c(\"N\",\n                                     \"Mean\", \"SD\",\n                                     \"Min\", \"Max\"),\n                      table = TRUE) {\n\n  \n  \n  # calculate descriptives\n  tempDescr &lt;- as.data.frame(\n    psych::describe(\n      data[,variable]\n      )\n    )[tolower(which.stat)]\n  \n  tempDescr$varNam &lt;- variable\n  rownames(tempDescr) &lt;- NULL\n  \n  \n  # calculate missing in %\n  if ( length(variable) == 1 ) {\n    \n    missDF &lt;- as.data.frame(mean(is.na(data[,variable]))*100)\n    \n  } else {\n    \n    missDF &lt;- as.data.frame(colMeans(is.na(data[,variable]))*100)\n    \n  }\n  \n  colnames(missDF) &lt;- \"miss\"\n  \n  tempDescr$miss &lt;- paste0(\n    sprintf(missDF$miss,\n            fmt = '%#.1f'),\n    \"%\")\n  \n  \n  if ( table == TRUE ) {\n    \n    tempTab &lt;- kableExtra::kbl(\n      x = tempDescr[,c(\"varNam\",\n                       tolower(which.stat),\n                       \"miss\")],\n      col.names = c(\"Variable\", which.stat, \"Miss.\"),\n      row.names = FALSE,\n      digits = 2,\n      align = c(\"l\", rep(\"c\",length(which.stat)), \"c\")\n      ,booktabs = TRUE\n      #,format = \"html\"\n      ) |&gt;\n      kableExtra::kable_styling(\n        full_width = TRUE,\n        bootstrap_options = c(\"hover\", \"responsive\")\n        ,latex_options = \"HOLD_position\"\n        )\n    \n    tempOut &lt;- tempTab\n    tempOut\n    \n    } else {\n      \n    tempOut &lt;- tempDescr[,c(\"varNam\",\n                            tolower(which.stat),\n                            \"miss\")]\n    \n    return(tempOut)\n    \n  }\n  \n}\n\n\nAn example execution.\n\nShow/hide codevarOverview(name = \"age\",\n            type = \"variable\",\n            questionaire = \"Student\",\n            prompt = \"How old are you?\",\n            response = \"open\",\n            cross = \"not applicable\",\n            source = \"not applicable\",\n            note = \"\")\ncontVar(variable = \"age\", data = exDat)\n\n\nTable 1.2: Variable: age\n\n\n\n\n\n(a) Overview\n\n\nName of variable:\nage\n\n\nQuestionaire:\nStudent\n\n\nPrompt in Questionaire:\nHow old are you?\n\n\nResponse format:\nopen\n\n\nCross reference:\nnot applicable\n\n\nSource:\nnot applicable\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Calculated statistics\n\nVariable\nN\nMean\nSD\nMin\nMax\nMiss.\n\n\nage\n670\n10.01\n1.58\n5.44\n14.84\n10.7%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.4.4.3 Categorical variables\nThe catVar function is based on the table function from R (R Core Team 2023) and has the following arguments:\n\n\nvariable: This should be a character or a character vector (name of variable)\n\ndata: The data frame\n\ntable: logical. Default is TRUE. Then the output is printed as a table using the kbl function from the kableExtra package (Zhu 2021). If set to false, the output is printed as a data.frame.\n\n\nShow/hide functioncatVar &lt;- function ( variable,\n                     data,\n                     table = TRUE) {\n\n  \n  # calculate freq. as function\n  calcFreq &lt;- function ( variable, data) {\n  \n    # calc abs and rel freq.\n    tempFreq &lt;- data.frame( abs = table(data[,variable],\n                                        useNA = \"always\"))\n    \n    tempFreq$rel &lt;- table(data[,variable],\n                          useNA = \"always\")/length(data[,variable])*100\n    \n    colnames(tempFreq) &lt;- c(\"var\",\n                            \"Absolute\",\n                            \"Relative\")\n  \n    # calculate sum\n    tempFreq &lt;- rbind(tempFreq,\n                      data.frame(var = \"Sum\",\n                                 t(colSums(tempFreq[!is.na(tempFreq$var),-1])))\n                      )\n    \n  \n    # cosmetics\n    \n    tempFreq$Relative &lt;- paste0(\n      sprintf(tempFreq$Relative,\n              fmt = '%#.1f'),\n      \"%\")\n  \n    tempTab &lt;- as.data.frame(t(tempFreq[,-1]))\n    colnames(tempTab) &lt;- tempFreq[,1]\n    colnames(tempTab)[is.na(colnames(tempTab))] &lt;- \"Miss\"\n    \n    tempTab &lt;- as.data.frame(\n      t(sapply(colnames(tempTab),\n               function(x) paste0(tempTab[1,x],\n                                  \" (\",\n                                  tempTab[2,x], \")\"),\n               simplify = TRUE)\n        )\n      )\n      \n    return(tempTab)\n    }\n  \n  tempFreq &lt;- data.table::rbindlist(\n    sapply(variable,\n           function(x) \n             calcFreq(variable = x, data = data),\n           simplify = FALSE),\n    idcol = \"Variable\", use.names = T, fill = T)\n  \n  # get colnames to sort\n  colToSort &lt;- c(\"Variable\", colnames(tempFreq)[!colnames(tempFreq) %in% \n                                                  c(\"Variable\",\n                                                    \"Miss\",\n                                                    \"Sum\"\n                                                    #\"Sum (miss)\"\n                                                    )],\n                 \"Sum\",\n                 \"Miss\"\n                 #\"Sum (miss)\",\n                 )\n  \n  tempFreq &lt;- tempFreq[,..colToSort]\n  \n  \n  if ( table == TRUE ) {\n    \n    tempTab &lt;- kableExtra::kbl(\n      x = tempFreq,\n      align = \"c\"\n      ) |&gt;\n      kableExtra::kable_styling(\n        full_width = TRUE,\n        bootstrap_options = c(\"hover\", \"responsive\")\n        #,latex_options = \"HOLD_position\"\n        ) \n    \n    tempOut &lt;- tempTab\n    tempOut\n    \n    } else {\n    \n    tempOut &lt;- tempFreq[,..colToSort]\n      \n    return(tempOut)\n    \n  }\n  \n}\n\n\nAn example execution.\n\nShow/hide codevarOverview(name = \"edu\",\n            type = \"variable\",\n            questionaire = \"Parent\",\n            prompt = \"Welchen Schulabschluss haben Sie? Bitte geben Sie *nur* Ihren höchsten Abschluss an.\",\n            response = c(\n              \"0 = Kein Schulabschluss\",\n              \"1 = Abschluss einer Sonderschule/Foerderschule\",\n              \"2 = einer Polytechnischen Oberschule nach der 8. Klasse\", \n              \"3 = Hauptschulabschluss/ Volksschulabschluss\",\n              \"4 = ...\"),\n            cross = \"NEPS\",\n            source = \"@Kunter2002\",\n            note = \"\")\ncatVar(variable = c(\"edu\"),\n       data = exDat)\n\n\nTable 1.3: Variable: Education\n\n\n\n\n\n(a) Overview\n\n\nName of variable:\nedu\n\n\nQuestionaire:\nParent\n\n\nPrompt in Questionaire:\nWelchen Schulabschluss haben Sie? Bitte geben Sie *nur* Ihren höchsten Abschluss an.\n\n\nResponse format:\n0 = Kein Schulabschluss; 1 = Abschluss einer Sonderschule/Foerderschule; 2 = einer Polytechnischen Oberschule nach der 8. Klasse; 3 = Hauptschulabschluss/ Volksschulabschluss; 4 = ...\n\n\nCross reference:\nNEPS\n\n\nSource:\n@Kunter2002\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Calculated statistics\n\nVariable\n0\n1\n2\n3\n4\nSum\nMiss\n\n\nedu\n50 (6.7%)\n100 (13.3%)\n150 (20.0%)\n200 (26.7%)\n250 (33.3%)\n750 (100.0%)\n0 (0.0%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.4.4.4 Scale score\nThe scaleScore function is based on the alpha function from the psych package (Revelle 2023) and has the following arguments:\n\n\nitems: This should be a character vector (name of items) or a named list\n\ndata: The data frame\n\nrecItems: Numeric vector of the reversed worded items.\n\nrecode: logical. Default is FALSE. If TRUE the items in recItems will be recoded.\n\nwhich.stat: Which statistics should be calculated? Default is: N, Mean, SD, Min, Max. Because the function is based on the describe function from psych package, you can also request: trimmed mean, median, mad, skew, kurtosis, standard error.\n\ntable: logical. Default is TRUE. Then the output is printed as a table using the kbl function from the kableExtra package (Zhu 2021). If set to false, the scale score (and if requested the recoded items) are returned.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe scale score is built based on only valid items (i.e., na.rm = FALSE argument of the rowSums function). This means if one item has missing value, no score is computed.\n\n\n\nShow/hide functionscaleScore &lt;- function ( items,\n                         scaleNameShort = NULL,\n                         recItems = NULL,\n                         recode = FALSE,\n                         data,\n                         which.stat = c(\"N\",\n                                        \"Mean\", \"SD\",\n                                        \"Min\", \"Max\"),\n                         table = TRUE) {\n  \n  # name check\n  \n  if (is.null(scaleNameShort)) {\n    stop(\"please provide the short name of the scale (variable name)\")\n  }\n  \n  \n  # recode check \n  \n  if (!is.null(recItems) & recode == FALSE) {\n    warning(\"Are the items already recoded?\\nIf not, you may use the recode argument.\")\n  }\n  \n  if (!is.null(names(items))) {\n    items &lt;- names(items)\n  }\n  \n  \n  # recode if necessary\n  if ( recode == T ) {\n    \n    data[,paste0(items[recItems],\"r\")] &lt;- sapply(\n      items[recItems],\n      function(x) {\n        tempRec &lt;- (max(data[,x]) + min(data[,x])) - data[,x]\n        return(tempRec)\n      }, simplify = FALSE)\n    \n    items[recItems] &lt;- paste0(items[recItems],\"r\")\n  }\n  \n  \n  # compute sumscore\n  data[,scaleNameShort] &lt;- rowSums(data[,items]) / length(items)\n  \n  # calculate descriptives\n  tempDescr &lt;- as.data.frame(\n    psych::describe(\n      data[,c(items,scaleNameShort)]\n      )\n    )[tolower(which.stat)]\n  \n  # calculate missing in %\n  missDF &lt;- as.data.frame(colMeans(is.na(data[,c(items,scaleNameShort)]))*100)\n  colnames(missDF) &lt;- \"miss\"\n  \n  missDF$miss &lt;- paste0(\n    sprintf(missDF$miss,\n            fmt = '%#.1f'),\n    \"%\")\n  \n  # calculate alpha et al\n  tempAlpha &lt;- psych::alpha(\n    data[,items]\n    )\n  \n  # extract r.cor & r.drop\n  rcordrop &lt;- tempAlpha$item.stats[,c(\"r.cor\", \"r.drop\")]\n  alpha &lt;- round(tempAlpha$total$raw_alpha,3)\n  \n  # merge dataframes\n  tempTab &lt;- merge(tempDescr, missDF, by = 0, sort = FALSE) \n  rownames(tempTab) &lt;- tempTab$Row.names\n  tempTab$Row.names &lt;- NULL\n  \n  tempTab &lt;- merge(tempTab, rcordrop, by = 0, all.x = T, sort = FALSE)\n  rownames(tempTab) &lt;- NULL\n  \n  # make tables\n  if ( table == TRUE ) {\n    \n    tempScaleTab &lt;- kableExtra::kbl(\n      x = tempTab,\n      col.names = c(\"Item\", which.stat, \"Missing\", \"$r_{it}$\", \"$r_{drop}$\"),\n      digits = 2,\n      align = c(\"l\", rep(\"c\",length(which.stat)), \"c\", \"c\", \"c\"),\n      booktabs = TRUE,\n      format = \"html\",\n      escape = FALSE\n      ) |&gt;\n      kableExtra::kable_styling(\n        full_width = TRUE,\n        bootstrap_options = c(\"hover\", \"responsive\")\n        #,latex_options = \"HOLD_position\"\n        ) |&gt;\n      kableExtra::footnote(general_title = \"Cronbachs $\\\\\\\\alpha$ = \",\n                           general = paste0(alpha),\n                           footnote_as_chunk = TRUE,\n                           threeparttable = TRUE) |&gt;\n      kableExtra::row_spec(row = nrow(tempTab),\n                           background = \"#d3d3d3\")\n    \n    tempOut &lt;- tempScaleTab\n    tempOut\n    \n    } else {\n      \n      tempOut &lt;- data[,c(items[recItems], scaleNameShort)]\n      print(tempTab)\n    \n    return(tempOut)\n    \n  }\n  \n}\n\n\nAn example execution.\n\nBefore executing the function, we create a named list. Item 3 and 4 are reversed worded items.\n\n\nShow/hide codemscItems &lt;- list(\"msc1\" = c(\"Ich bin gut in Mathematik.\"),\n                 \"msc2\" = c(\"Ich war in Mathematik immer gut.\"),\n                 \"msc3\" = c(\"Ich habe Verständnisschwierigkeiten bei allem, für das man Mathematik braucht.\"),\n                 \"msc4\" = c(\"Ich bin bei Aufgaben, die mathematisches Denken\nerfordern, nie gut.\"))\n\n\n\nThen we execute the two functions. because the items 3 and 4 are not recoded in the data set, we have to pass the information to the scaleScore function.\n\n\nShow/hide codevarOverview(name = \"Math Self-concept\",\n            type = \"scale\",\n            itemword = mscItems,\n            prompt = \"Wie sehr treffen die folgenden Aussagen auf Sie zu?\",\n            response = c(\"1 = trifft überhaupt nicht zu\",\n                        \"2 = trifft eher nicht zu\",\n                        \"3 = trifft eher zu\",\n                        \"4 = trifft völlig zu\"),\n           cross = \"TOSCA-R\",\n           source = \"\")\nscaleScore(items = names(mscItems),\n           scaleNameShort = \"msc\",\n           recItems = c(3,4),\n           recode = TRUE,\n           data = exDat,\n           table = T)\n\n\nTable 1.4: Variable Math Self-concept\n\n\n\n\n\n(a) Overview\n\n\nName of scale:\nMath Self-concept\n\n\nPrompt in Questionaire:\nWie sehr treffen die folgenden Aussagen auf Sie zu?\n\n\nResponse format:\n1 = trifft überhaupt nicht zu; 2 = trifft eher nicht zu; 3 = trifft eher zu; 4 = trifft völlig zu\n\n\nCross reference:\nTOSCA-R\n\n\nSource:\n\n\n\n\n\n\n\nmsc1\nIch bin gut in Mathematik.\n\n\nmsc2\nIch war in Mathematik immer gut.\n\n\nmsc3\nIch habe Verständnisschwierigkeiten bei allem, für das man Mathematik braucht.\n\n\nmsc4\nIch bin bei Aufgaben, die mathematisches Denken erfordern, nie gut.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Calculated statistics\n\nItem\nN\nMean\nSD\nMin\nMax\nMissing\n$r_{it}$\n$r_{drop}$\n\n\n\nmsc1\n750\n2.52\n0.74\n1\n4\n0.0%\n0.72\n0.67\n\n\nmsc2\n680\n2.54\n0.72\n1\n4\n9.3%\n0.67\n0.62\n\n\nmsc3r\n750\n2.51\n0.75\n1\n4\n0.0%\n0.82\n0.74\n\n\nmsc4r\n750\n2.52\n0.75\n1\n4\n0.0%\n0.80\n0.73\n\n\nmsc\n680\n2.53\n0.61\n1\n4\n9.3%\nNA\nNA\n\n\n\n\nCronbachs $\\\\alpha$ =   0.851\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRevelle, William. 2023. Psych: Procedures for Psychological, Psychometric, and Personality Research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf.\n\n\nWissik, T., and M. Ďurčo. 2015. “Research Data Workflows: From Research Data Lifecycle Models to Institutional Solutions.” CLARIN 2015 Selected Papers, Linköping Electronic Conference Proceedings, Annual Conference 2015, October 14–16, 2015, Wroclaw, Poland (Pp. 94–107). Linköping University Electronic Press, Linköpings Universitet. http://www.ep.liu.se/ecp/123/008/ecp15123008.pdf.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "gen-info.html#footnotes",
    "href": "gen-info.html#footnotes",
    "title": "\n1  General information on data documentation\n",
    "section": "",
    "text": "see also here: https://www.forschungsdaten-bildung.de/↩︎\nThis is (mainly) because there are some issues with the kableExtra package (Zhu 2021) and latex implementation (i.e., format: pdf) in Quarto.↩︎"
  },
  {
    "objectID": "intro-r-rstudio.html#what-is-r-rstudio",
    "href": "intro-r-rstudio.html#what-is-r-rstudio",
    "title": "\n2  Introduction to R & RStudio\n",
    "section": "\n2.1 What is R & RStudio?",
    "text": "2.1 What is R & RStudio?\n\nR: R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS (see https://www.r-project.org/).\nR Studio: Coding environment for R, built by Posit.\n\nSome advertisement from the Posit website:\n\nUsed by millions of people weekly, the RStudio integrated development environment (IDE) is a set of tools built to help you be more productive with R and Python. It includes a console, syntax-highlighting editor that supports direct code execution. It also features tools for plotting, viewing history, debugging and managing your workspace.\n\nOf course there are other IDEs (e.g., Visual Studio Code, but if you use R, RStudio is most likely the way to go."
  },
  {
    "objectID": "intro-r-rstudio.html#how-to-work-with-r-and-rstudio",
    "href": "intro-r-rstudio.html#how-to-work-with-r-and-rstudio",
    "title": "\n2  Introduction to R & RStudio\n",
    "section": "\n2.2 How to work with R and RStudio?",
    "text": "2.2 How to work with R and RStudio?\n\n\n\n\n\n\nExercise: Open RStudio!\n\n\n\n\n\nThis should look like this, maybe or probably with a different appearance (this is the Dracula theme). You can change this via Tools &gt; Global Options &gt; Appearance\n\n\n\n\nIn RStudio there are different panes1:\n\n2.2.1 Panes\n\n\nConsole\n\nHere you can access R\n\nE.g., ask R what is: 2 + 2\n\n\n\n\nSource/Script\n\nEditor to save scripts\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nYou should never work directly in the Console, but always use a R-script (e.g., script.R) or even better a Quarto document (e.g., script.qmd). It is important to understand and reproduce everything you did.\n\n\n\n\nEnvironment/History/…/Tutorial\n\nEnvironment: contains all objects that were created or loaded during an R session\nHistory:\n… e.g., the free and open source distributed version control system git\n\nTutorial: A tutorial to learn R with the learnr package (Aden-Buie et al. 2023)\n\n\n\n\nFiles/Plots/Packages/Help/Viewer\n\nFiles: is kind of the file manager\nPlots: shows the generated plots\nPackages: overview of the (loaded &) installed packages\nHelp: When you ask for help (e.g., regarding a specific function in R: ?mean)\nViewer: E.g., previewing rendered Quarto documents\n\n\n\n2.2.2 Projects\nIt is also reasonable to use the project option. This means, whenever you start a new project (e.g., a scale-manual), create an project: File &gt; New Project\n\n\n\n\n\n\nExercise: Create an project!\n\n\n\n\n\n\nChoose between:\n\n\nNew Directory (for today)\nExisting Directory\nVersion Control (this is recommended, but is beyond the scope of this workshop)\n\n\n\nChoose a project type (today a R project or Quarto project)\n\n\n\nProvide a short name, set the check mark Open in new session and click Create Project"
  },
  {
    "objectID": "intro-r-rstudio.html#short-introduction-to-the-r-programming-language",
    "href": "intro-r-rstudio.html#short-introduction-to-the-r-programming-language",
    "title": "\n2  Introduction to R & RStudio\n",
    "section": "\n2.3 Short introduction to the R programming language",
    "text": "2.3 Short introduction to the R programming language\nThis section gives a (very?) brief introduction to R programming language.\n\n\n\n\n\n\nFor comprehensive introductions…\n\n\n\n\n\nor overviews of the language see e.g.,\n\nR Manual on the CRAN website\nR for Data Science by Hadley Wickham and Garrett Grolemund\nHands-On Programming with R by Garrett Grolemund\nIntroduction to R by the IDRE Statistical Consulting Group\n…\n\n\n\n\n\nTo understand computations in R, two slogans are helpful:\n\nEverything that exists is an object.\n\nEverything that happens is a function call.\n\n\n– John Chambers (creator of the S programming language)\n\n\n\n2.3.1 Basics\nBefore working with R, there are a few basics you need to know:\n\n\n\n\nR is a case-sensitive programming language. This means that R distinguishes whether a word is written in upper or lower case\n\n\n\n\n\n\"name\" == \"Name\"\n\n[1] FALSE\n\n\n\n\n\n\n\n\nValues are assigned to objects using &lt;-\n\n\n\n\n\n\na &lt;- \"Hello world!\"\n\n\n\n\n\n\n\nArguments within functions are assigned using =\n\n\n\n\n\n\ndf &lt;- data.frame(\n  x = 1:4,\n  y = 3:6\n)\n\n\n\n\n2.3.2 Data Types\nThe basic data types2 in R are depicted in Table 2.1.\n\n\nTable 2.1: Basic data types in R\n\n\n\n\n\n\nType\nDescription\nValue (example)\n\n\n\nNumeric\nNumbers with decimal value or fraction\n3.7\n\n\nInteger\nCounting numbers and their additive inverses\n\n2, -115\n\n\n\nCharacter\naka string. Letters enclosed by quotes in the output.\n\n\"Hello World!\",\"4\"\n\n\n\nLogical \nboolean\n\nTRUE, FALSE\n\n\n\nFactor\nCategorial data\n- Level: characteristic value as seen by R\n- Label: designation of the characteristic attributes\n\n0, 1male,female\n\n\n\nSpecial\n\n\nMissing values: unknown cell value\n\nEmpty values: known empty cell value\n\n\nNANULL\n\n\n\n\n\n\n\n\n\n\n\nExercise: Use the class function to check the data type of an object!\n\n\n\n\n\n\nShow/hide codex &lt;- 10\nclass(x)\n\n[1] \"numeric\"\n\nShow/hide codey &lt;- \"Hello World\"\nclass(y)\n\n[1] \"character\"\n\n\n\n\n\n\n\n2.3.3 Data Structures\nR has a couple of different data structures3 which are briefly described in the following subsections.\n\n2.3.3.1 Vector\n\n\n\none-dimensional array\n\nsame data type\ne.g., c(45, 6, -83, 23, 61)\n\n\n\n\n\n\n\n\n\n\n\nTips for handling vectors\n\n\n\n\n\nCreate a vector with the c function\n\nv &lt;- c(45, 6, -83, 23, 61)\nv\n\n[1]  45   6 -83  23  61\n\n\nOr a named vector…\n\nvNam &lt;- c(a = 45, b = 6, c = -83, d = 23, e = 61)\nvNam\n\n  a   b   c   d   e \n 45   6 -83  23  61 \n\n\nCount the amount of items contained in vector\n\nlength(v)\n\n[1] 5\n\n\nVector indexing (by position)\n\nv[1]\n\n[1] 45\n\nv[-3]\n\n[1] 45  6 23 61\n\n\nSlicing vectors\n\nv[3:5]\n\n[1] -83  23  61\n\n\nGenerate regular sequences using seq function\n\nseq(from = 0,\n    to = 20,\n    by = 2)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\n\n\n\n\n\n\n\n2.3.3.2 Matrix\n\n\n\ntwo-dimensional\n\nsame data type\nexample see on the right\n\n\n\n\n\n\n\n\n\n\n\nTips for handling matrices\n\n\n\n\n\n\nThe matrix function creates a matrix from the given set of values\n\n\nm &lt;- matrix(data = c(1, 2, 3, 45, 36, 52),\n            nrow = 2,\n            ncol = 3,\n            byrow = TRUE)\nm\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]   45   36   52\n\n\n\nSlicing works also on matrices: m[row , column]\n\n\n\nm[, 1:2]\n\n     [,1] [,2]\n[1,]    1    2\n[2,]   45   36\n\n\n\n\n\n\n\n\n2.3.3.3 List\n\n\n\ncan contain elements of various data types\noften ordered collection of values\none-indexed (indexing starts with 1)\ne.g., list(\"hello\", 6, NULL)\n\n\n\n\n\n\n\n\n\n\n\nTips for handling lists\n\n\n\n\n\nCreate lists (with different elements, i.e., numbers and letters) with the list function\n\nl1 &lt;- list(1:5)\nl2 &lt;- list(letters[1:5])\nl3 &lt;- list(LETTERS[1:5])\n\nCreate a nested list…\n\nl4 &lt;- list(l1, l2, l3)\n\n…or a named (nested) list\n\nl4Nam &lt;- list(\"Numbers\" = l1,\n              \"SmallLetters\" = l2,\n              \"CaptialLetters\" = l3)\n\nAccess list or nested list elements\n\nl4[2]\n\n[[1]]\n[[1]][[1]]\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nl4[[2]][3]\n\n[[1]]\nNULL\n\n\nUnlist the list to get vector which contains all the atomic components\n\nunlist(l1)\n\n[1] 1 2 3 4 5\n\nunlist(l4)\n\n [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"a\" \"b\" \"c\" \"d\" \"e\" \"A\" \"B\" \"C\" \"D\" \"E\"\n\n\nCount amount of items contained in list\n\nlength(l4)\n\n[1] 3\n\nlength(unlist(l4))\n\n[1] 15\n\n\n\n\n\n\n\n\n2.3.3.4 Data frame\n\n\n\nvarious columns\ndifferent data types\nvariables = columns\nobservations = rows\nexample see on the right\n\n\n\n\n\n\n\n\n\n\n\nTips for handling dataFrames\n\n\n\n\n\n\ndf &lt;- data.frame(\n  id = 1:4,\n  age = c(12, 13, 12, 14),\n  sex = c(1, 1, 2, 2)\n)\ndf\n\n  id age sex\n1  1  12   1\n2  2  13   1\n3  3  12   2\n4  4  14   2\n\n\nNumber of observations\n\nnrow(df)\n\n[1] 4\n\n\nShow dimension (rows, columns) of dataframe\n\ndim(df)\n\n[1] 4 3\n\n\nColumn names\n\ncolnames(df)\n\n[1] \"id\"  \"age\" \"sex\"\n\n\nShow the first two rows of the dataframe\n\nhead(df, 2)\n\n  id age sex\n1  1  12   1\n2  2  13   1\n\n\nStructure of dataframe object\n\nstr(df)\n\n'data.frame':   4 obs. of  3 variables:\n $ id : int  1 2 3 4\n $ age: num  12 13 12 14\n $ sex: num  1 1 2 2\n\n\nSome descriptive statistics using the summary function (for more see Section Descriptive statistics and item analysis\n\nsummary(df)\n\n       id            age             sex     \n Min.   :1.00   Min.   :12.00   Min.   :1.0  \n 1st Qu.:1.75   1st Qu.:12.00   1st Qu.:1.0  \n Median :2.50   Median :12.50   Median :1.5  \n Mean   :2.50   Mean   :12.75   Mean   :1.5  \n 3rd Qu.:3.25   3rd Qu.:13.25   3rd Qu.:2.0  \n Max.   :4.00   Max.   :14.00   Max.   :2.0  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAden-Buie, Garrick, Barret Schloerke, JJ Allaire, and Alexander Rossell Hayes. 2023. Learnr: Interactive Tutorials for r. https://CRAN.R-project.org/package=learnr."
  },
  {
    "objectID": "intro-r-rstudio.html#footnotes",
    "href": "intro-r-rstudio.html#footnotes",
    "title": "\n2  Introduction to R & RStudio\n",
    "section": "",
    "text": "You can customize them: Tools &gt; Global Options &gt; Pane Layout↩︎\nWe omitted the complex type.↩︎\nWe omitted arrays.↩︎"
  },
  {
    "objectID": "intro-quarto.html#what-is-quarto",
    "href": "intro-quarto.html#what-is-quarto",
    "title": "\n3  A not so short introduction to Quarto\n",
    "section": "\n3.1 What is Quarto?",
    "text": "3.1 What is Quarto?\n\n\n\n\nBut, what is Pandoc? Pandoc is a universal document converter. It converts files from one markup format into another (e.g., markdown → HTML).\nIn short, with Quarto you can create different types of (reproducible) documents1 including:\n\nHTML\nPDF\nMS Word\nMarkdown\n\nThe focus of this workshop is on HTML (and PDF) documents. For an overview about all formats see here."
  },
  {
    "objectID": "intro-quarto.html#how-to-work-with-quarto",
    "href": "intro-quarto.html#how-to-work-with-quarto",
    "title": "\n3  A not so short introduction to Quarto\n",
    "section": "\n3.2 How to work with Quarto?",
    "text": "3.2 How to work with Quarto?\n\nIt is basically the same2 as working in regular a R-script.\n\nOpen a new file: File &gt; New File &gt; Quarto Document...\n\n\n\n\n\n\n\n\n\n\nExercise: Create your first Quarto document!\n\n\n\n\n\n\nProvide a title (& author name)\n\n\n\nSave the document with a reasonable name and use the Render button\n\n\n\n\n\n\nA quarto document roughly consists of two parts:\n\nThe YAML header\n\nThe Body\n\n\n\nThe website quarto.org is a great resource to learn it (e.g., follow the guide). It is a daily companion and covers the topics in much greater detail than this page."
  },
  {
    "objectID": "intro-quarto.html#yaml-header",
    "href": "intro-quarto.html#yaml-header",
    "title": "\n3  A not so short introduction to Quarto\n",
    "section": "\n3.3 The YAML header",
    "text": "3.3 The YAML header\nThe YAML3 header is enclosed by three dashes (---):\n---\ntitle: \"my-first-quarto-document\"\nformat: html\n---\n\n3.3.1 Overview of YAML syntax\nThe basic syntax of YAML uses so-called key-value pairs in the format key: value. This is extremely powerful, because you can generate great documents like this Quarto book without knowing much about HTML, LATEX or programming in general.\nSome useful key-value pairs:\nsubtitle: \"my subtitle\"\nauthor:\n  - \"John Doe\"\n  - \"Jane Roe\"\n  - \"Norah Jones\"\ndate: today\ntoc: true\ntoc-title: \"Inhaltsverzeichnis\"\nnumber-sections: true\n\n\n\n\n\n\nExercise: Identify useful key-value pairs\n\n\n\n\n\n\nFor the next 5 minutes or so, check out https://quarto.org and identify potential useful key: value pairs. Note: There are different YAML options for the formats:\n\nHTML\nPDF\n\n\nAdd them to your YAML header.\n\n\n\n\n\n3.3.2 Citing\nWith Quarto it is possible to automatically generate citations and bibliographies in many different ways.\nThe key: value pair to include citations in Quarto documents is:\nbibliography: r-refs.bib\nHere we use a so-called BibLaTex (.bib) file. These files can be generated with the most reference management software programs4 (e.g., Citavi, EndNote, zotero, …).\n\n\n\n\n\n\nRandom tip on maintenance of literature management\n\n\n\n\n\nIt is highly recommended to maintain your retrieved citations. This means, whenever you download a single (!) reference by means of the doi (Digital Object Identifier), check whether the reference information is correct. This saves a lot of time in the long run.\n\n\n\nA reference in the .bib-file looks like this:\n@Manual{R-base,\n  title = {R: A Language and Environment for Statistical Computing},\n  author = {{R Core Team}},\n  organization = {R Foundation for Statistical Computing},\n  address = {Vienna, Austria},\n  year = {2022},\n  url = {https://www.R-project.org/},\n}\n\n\n\n\n\n\nExercise: Create a .bib file for the R references\n\n\n\n\n\n\nCheck the path (same folder as the Quarto document, otherwise you have to provide the path in the bibliography).\n\n\nShow/hide codegetwd()\n\n\n\nSave the R packages in a character vector.\n\n\nShow/hide codepkgList &lt;- c(\"knitr\", # tables\n             \"kableExtra\", # tables\n             \"lavaan\", # generate data\n             \"car\", # recoding\n             \"psych\") # descriptive\n\n\n\nUse the write_bib function from the kntir package (Xie 2023).\n\n\nShow/hide codeknitr::write_bib(x = pkgList,\n                 file = \"r-refs.bib\")\n\n\n\n\n\nTo change the citation style (e.g., APA, Chicago Manual of Style), we use the csl key5:\ncsl: apa.csl\nThe apa.csl file can be found on github.\nThe citation syntax (How to cite the references in the text?) is briefly explained in the The Body subsection Citation syntax.\n\n3.3.3 Execution/Output options\nThere are many different options to customize the output of the (executed code).The options can be specified:\n\nglobally (see in the following)\nper code block (see the section on Chunk options)\n\nIn the following example, we set echo: false and warning: false.\nexecute:\n  echo: false\n  warning: false\nThis means that no code and no warnings are shown, except you state it otherwise in a specific code block.\nFor more (chunk) options see https://quarto.org/docs/computations/execution-options.html."
  },
  {
    "objectID": "intro-quarto.html#quarto-body",
    "href": "intro-quarto.html#quarto-body",
    "title": "\n3  A not so short introduction to Quarto\n",
    "section": "\n3.4 The body",
    "text": "3.4 The body\nAs explained in the section What is Quarto?:\n\nQuarto is based on Pandoc and uses its variation of markdown as its underlying document syntax (see https://quarto.org)\n\nThis means we can use Markdown syntax6 (together with the information in the YAML header) to generate the different types of documents (e.g., HTML, PDF, …).\n\n\n\n\n\n\nExercise: Work through the Markdown language section and the three subsections…\n\n\n\n\n\n\nText formatting\nHeadings\nLists\n\nThe information is very dense, so do not expect to remember everything.\n\n\n\n\n3.4.1 Markdown language\nThere are plenty of different guides to get a quick overview about the language (see e.g., markdownguide, or Quarto-website). The following code snippets are copied and sometimes slightly adjusted from https://quarto.org.\n\n3.4.1.1 Text formatting\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n*italics* and **bold**\n\nitalics and bold\n\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n\n~~strikethrough~~\nstrikethrough\n\n\n`verbatim code`\nverbatim code\n\n\n\n3.4.1.2 Headings\nTo create headings, add one (or more) # in front of the heading.\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n# Header 1\nHeader 1\n\n\n## Header 2\nHeader 2\n\n\n### Header 3\nHeader 3\n\n\n\n\nThis goes up to level 6 (i.e., ######) which probably is not recommended to use though.\n\n3.4.1.3 Lists\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n* unordered list\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n\n\nunordered list\n\nsub-item 1\n\nsub-item 2\n\nsub-sub-item 1\n\n\n\n\n\n\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n         A.  sub-sub-item 1\n\nordered list\n\nitem 2\n\n\nsub-item 1\n\nsub-sub-item 1\n\n\n\n\n\n\n\n\nMore example can be found on https://quarto.org/docs/authoring/markdown-basics.html#lists.\n\n3.4.2 Cross-referencing\nTo make a figure, table, equation, …, or section/heading referenceable, it is necessary to provide unique identifier. Identifiers must start with their type (e.g., #fig-, #tbl-, #eq-), except for headers (see in the following example):\nWhen we want to cross-reference the Images section, we have to provide unique identifier that is enclosed by braces {} (here: #include-images) after the heading:\n## Images {#include-images} \nAn example on how to reference figures is shown in the Images section.\nFor more on cross-referencing (e.g., how to make sub-figures) see again https://quarto.org/docs/authoring/cross-references.html.\n\n3.4.3 Images\nOne way to include images is as follows:\n![Here goes the caption](/path-to-file/myImage.png){#fig-myImage}\nThe caption [Here goes the caption] and label {#fig-myImage} make this figure referenceable. To reference it, use the following syntax:\nSee @fig-myImage for a graphical representation.\nIt renders to:\nSee Figure 3.1 for a graphical representation.\n\n\nFigure 3.1: Here goes the caption\n\n\n\n\n\n\n\n\nTip. There are a few other options to include images…\n\n\n\n\n\nOne of them is the include_graphics function from the knitr package (Xie 2023):\n\n```{r}\n#| label: fig-demo-include\n#| eval: false\n#| code-fold: false\n\nknitr::include_graphics(\"path-to-file\")\n```\n\nIt is referenceable via the label: fig-demo-include. For now ignore the other so-called chunk options (i.e., eval, code-fold). These are explained in the Chunk options section.\nFor more (e.g., HTML way &lt;img&gt; &lt;/img&gt; or &lt;iframe&gt;&lt;/iframe&gt;) see again https://quarto.org/docs/authoring/figures.html.\n\n\n\n\n3.4.4 Citation syntax\nRecall a reference in the .bib-file looks like this:\n@Manual{R-base,\n  title = {R: A Language and Environment for Statistical Computing},\n  author = {{R Core Team}},\n  organization = {R Foundation for Statistical Computing},\n  address = {Vienna, Austria},\n  year = {2022},\n  url = {https://www.R-project.org/},\n}\nTo cite the R program, use @ before the so-called BibLaTex key R-base. Three example follow:\n\n\n[@R-base] renders as: (R Core Team 2023)\n\n\n@R-base renders as: R Core Team (2023)\n\n\n[-@R-base] renders as: (2023)\n\n\nMultiple citations are separated by semicolons:\n\n\n[@R-base; @R-knitr] renders as: (R Core Team 2023; Xie 2023)\n\n\nFor more information on the citation syntax see the Pandoc Citations documentation.\n\n3.4.5 There is a lot more!\n\nTechnical writing (e.g., Equations): Use $ delimiters for inline math and $$ delimiters for display math (see https://quarto.org)\n\nLinks:\n\n\n[This is a link to google.de](www.google.de) which appears as This is a link to google.de\n\n\n&lt;https://quarto.org&gt; which appears as https://quarto.org\n\n\n\nDiagrams (e.g., Mermaid,Graphviz)\nVideos\n…"
  },
  {
    "objectID": "intro-quarto.html#computations",
    "href": "intro-quarto.html#computations",
    "title": "\n3  A not so short introduction to Quarto\n",
    "section": "\n3.5 Computations",
    "text": "3.5 Computations\n\n\n\n\n\n\nNote\n\n\n\nWhen using R, Quarto uses the Knitr engine7 to execute R code.\n\n\n\n3.5.1 R code blocks (or chunks)\nWithin a Quarto document source code8 can be displayed by using ``` at the start and the end of the code.\nThe starting ``` are followed by braces around the programming language (e.g., ```{python})\nR code is included by using braces around the letter r (i.e., ```{r}; the Windows shortcut is Ctrl+Shift+I)\nThis looks like this:\n\nShow/hide code```{r}\n#| label: fig-example-ggplot\n#| fig-cap: \"My first ggplot\"\n#| results: hold\n\nlibrary(ggplot2)\n\nggplot(data = diamonds,\n       aes(y = carat, x = price, color = cut)) +\n  geom_point() +\n  labs(y = \"Carat\", x = \"Price\", color = \"Cut\") +\n  theme_classic()\n```\n\n\n\nFigure 3.2: My first ggplot\n\n\n\n\n\n\n\n\n\n\nExercise: Create your first R code block.\n\n\n\n\n\n\n\n3.5.2 Chunk options9\n\nWhat are chunk options? Chunk options customize the output of the code blocks. In Quarto it is recommended10 to include the chunk options as special comments (i.e., |#) at the top of the chunk.\nIn the following example, we set output: false…\n\nShow/hide code```{r}\n#| label: my-first-chunk\n#| output: false\n\nprint(\"hello world!\")\n```\n\n\n… and hence, no output is shown.\nThe most common chunk options are:\n\n\n\n\n\n\n\nChunk option\nDescription\nValue\n\n\n\necho\nInclude the source code in output\ntrue/false/fenced\n\n\neval\nEvaluate the code chunk. If false the code of the chunk will not be executed, but depending on the echo value be displayed or not.\ntrue/false\n\n\ninclude\nInclude source code &(!) results in the output.\ntrue/false\n\n\nresults\nShould results be displayed in the output or not (false)? If yes how (markup vs. asis)?\n\nmarkup/asis/hold/ hide/false\n\n\n\nwarnings\nInclude warnings in output.\ntrue/false\n\n\n\n3.5.3 Rendering\nThere are a couple of ways to render a Quarto document:\n\nClicking the Render Button or using the keyboard shortcut (windows): Ctrl+Shift+K11\n\nUsing the terminal\n\nquarto render script.qmd --to html\nquarto render script.qmd --to pdf\n…\n\n\nUsing the quarto_render function from the quarto (Allaire 2022) package\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen rendering a Quarto document, the R code chunks are executed (except you stated: eval: false).\n\n\n\n\n\n\n\n\nAllaire, JJ. 2022. Quarto: R Interface to Quarto Markdown Publishing System. https://github.com/quarto-dev/quarto-r.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2023. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nXie, Yihui. 2023. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/."
  },
  {
    "objectID": "intro-quarto.html#footnotes",
    "href": "intro-quarto.html#footnotes",
    "title": "\n3  A not so short introduction to Quarto\n",
    "section": "",
    "text": "Note: It is also possible to generate, presentations (e.g., powerpoint, beamer), websites, books and even interactive components.↩︎\nNevertheless, it (probably) will take some time to get familiar with it↩︎\nYAML is an acronym for Yet Another Markup Language see https://en.wikipedia.org/wiki/YAML↩︎\nIf you do not use one, it is time now.↩︎\nCSL is the abbreviation for Citation Style Language (for more see https://en.wikipedia.org/wiki/Citation_Style_Language↩︎\nIt is also possible to use Latex or HTML syntax. However, you most likely run into problems when rendering into the respective other type.↩︎\nQuarto also supports the Jupyter engine.↩︎\nQuarto/Pandoc supports displaying (!) many different programming languages (see here)↩︎\nsee also here: https://yihui.org/knitr/options/↩︎\nThe rmarkdown syntax is different (e.g., {r my-label, echo = FALSE}), but it also works in Quarto.↩︎\nFor Mac it is: Cmd+Shift+K↩︎"
  },
  {
    "objectID": "data-cleaning.html",
    "href": "data-cleaning.html",
    "title": "\n4  Data cleaning\n",
    "section": "",
    "text": "5 Data preparation/processing\nSteps in data preparation include:"
  },
  {
    "objectID": "data-cleaning.html#control-of-unit-identifiers",
    "href": "data-cleaning.html#control-of-unit-identifiers",
    "title": "\n4  Data cleaning\n",
    "section": "\n4.1 Control of unit-identifiers",
    "text": "4.1 Control of unit-identifiers\n\n\n\n\n\n\nPlan your identification variables!\n\n\n\n\n\nIdentification variables (ID variables) are of great importance when dealing with study data. A suitable ID assignment should already be planned before the data collection.\n\n\n\nPurpose: Identify duplicates\nProcedure:\n\nFind duplicate IDs\n\nExclude duplicates (consultation with supervisors!)\n\nSince our example data set does not contain an ID variable, we modify the data set to illustrate this step of data cleaning. This data manipulation is done using the dplyr package (Wickham, François, et al. 2023).\n\nShow/hide codedoublingCases &lt;- sample(1:nrow(exDat), 5)\n\nexDat_ID &lt;- exDat |&gt; \n  mutate(id = 1:nrow(exDat),\n         .before = msc1) |&gt; \n  rbind(exDat[doublingCases, ] |&gt; \n          mutate(id = doublingCases,\n                 .before = msc1)) |&gt; \n  arrange(id)\n\n\n\n\nBase R\ndplyr package\n\n\n\nThe duplicated() function checks for each value whether it is duplicated. The output is logical vector. In combination with the which() function, checking which indices are TRUE, we can extract the duplicates.\n\nShow/hide codeexDat_ID[which(duplicated(exDat_ID$id)), ]\n\n      id msc1 msc2 msc3 msc4       age sex edu\n1201 120    3    2    3    2  9.562434   0   1\n1931 193    1    2    4    4 10.898386   0   2\n2091 209    2    2    3    2  9.748836   1   2\n3201 320    3    3    2    1  9.966598  NA   3\n4941 494    2    2    3    3        NA   1   3\n\n\nBy negating the function (!duplicated()), duplicates can be excluded.\n\nShow/hide codeexDat_ID[which(!duplicated(exDat_ID$id)), ]\n\n     id msc1 msc2 msc3 msc4       age sex edu\n1     1    2    3    2    2  9.815538   0   0\n2     2    3    2    1    1  8.980194   1   0\n3     3    2    2    3    3 12.758157   0   0\n4     4    2    2    3    2 10.578846   0   0\n5     5    3    2    2    2  9.894364   1   0\n6     6    3    3    3    2 10.446850   0   0\n7     7    4    4    1    2 10.897605   1   0\n8     8    3    3    2    1  7.977382   1   0\n9     9    3    3    2    1 10.688379  NA   0\n10   10    3    3    2    2  9.105864   0   0\n11   11    2    1    3    3  8.540117   0   0\n12   12    2    2    3    3 11.841954   0   0\n13   13    2    2    3    4 11.647655   0   0\n14   14    2    3    3    3 11.745306   0   0\n15   15    2    3    3    3  9.970630   0   0\n16   16    3    3    2    1  8.186501  NA   0\n17   17    2    2    2    2  7.773473   1   0\n18   18    2    2    3    2        NA   1   0\n19   19    2    2    3    3  9.339448   0   0\n20   20    4    4    1    1        NA   1   0\n21   21    4    3    2    2  9.831947   0   0\n22   22    2    3    3    3  9.890266   1   0\n23   23    2    3    2    2 11.501609   0   0\n24   24    2   NA    3    2  9.341404   0   0\n25   25    3    3    2    2 11.540030   1   0\n26   26    2    3    3    3 10.098491   1   0\n27   27    4    3    2    2 10.851320   1   0\n28   28    3    2    2    2  6.735228   1   0\n29   29    3    4    2    2 10.690059   1   0\n30   30    3    2    2    3  9.746659   1   0\n31   31    2    1    4    4  8.983450   0   0\n32   32    2   NA    3    3 11.557894   0   0\n33   33    2    2    3    2  8.057455   1   0\n34   34    2    2    3    3 10.134752   0   0\n35   35    2    3    3    2  8.096160   0   0\n36   36    4    3    1    1  9.404151  NA   0\n37   37    3    3    3    3 12.156118   0   0\n38   38    2    2    3    2  9.600157   0   0\n39   39    2    3    3    3 11.591400   0   0\n40   40    3    4    2    2 10.691193   1   0\n41   41    3    3    3    2 12.622380   0   0\n42   42    3    2    2    2 10.043774   1   0\n43   43    4    3    2    2  8.452508   0   0\n44   44    4    3    2    2 12.029754   1   0\n45   45    3    2    3    3  8.213722   1   0\n46   46    2    3    2    3 11.654911   0   0\n47   47    4    3    1    1  9.086209   1   0\n48   48    3   NA    3    3  9.535470   1   0\n49   49    2    3    3    3  9.617718   0   0\n50   50    2    3    2    2 10.347768   1   0\n51   51    2    1    3    3 10.735626   0   1\n52   52    3    3    3    2 10.903281   1   1\n53   53    2   NA    3    3 10.265831   1   1\n54   54    2    3    4    3 10.824752   0   1\n55   55    3    3    3    3  9.282584   0   1\n56   56    2    3    2    2        NA   0   1\n57   57    2    3    3    3  8.747505   1   1\n58   58    2    2    3    4  8.992998   1   1\n59   59    2    2    3    3 12.632563   1   1\n60   60    2    2    3    3 11.015445   1   1\n61   61    3    3    2    2  9.529734   1   1\n62   62    4    3    1    1 11.569437   1   1\n63   63    4    3    2    2 11.626011   1   1\n64   64    2   NA    3    3 12.371110   0   1\n65   65    2    2    2    3  8.712209   1   1\n66   66    1    2    3    2 12.271368   0   1\n67   67    3    3    2    2 11.514336   1   1\n68   68    4    4    2    1        NA   0   1\n69   69    2    2    2    2 10.858827   1   1\n70   70    2    2    3    4 11.416986   0   1\n71   71    2   NA    1    2 10.722411   0   1\n72   72    2    3    3    3  9.417725   1   1\n73   73    4    3    1    2 10.788379   1   1\n74   74    2    3    2    2  7.527881   1   1\n75   75    2    2    3    3  7.697320   0   1\n76   76    3    4    3    2  9.723288   1   1\n77   77    2    2    3    3  8.457035  NA   1\n78   78    3    3    3    3  9.552697   1   1\n79   79    3    3    3    3 10.766935   1   1\n80   80    3   NA    2    2  8.086932   1   1\n81   81    2    3    2    2 10.027268   0   1\n82   82    4    3    2    2 11.108152   1   1\n83   83    3    3    2    2  9.364853   1   1\n84   84    2   NA    4    4  9.229549   0   1\n85   85    4    3    1    1  8.791437   0   1\n86   86    2    2    3    3 14.699514   1   1\n87   87    1    2    4    3  9.310963   0   1\n88   88    2   NA    2    2  7.862333   0   1\n89   89    3    4    1    2  9.164070   0   1\n90   90    3    2    3    2  9.904690   0   1\n91   91    1    2    3    3  9.949049   0   1\n92   92    1    2    3    2 10.874213   0   1\n93   93    2    3    3    3  9.589440   0   1\n94   94    2    2    3    3  8.396720   0   1\n95   95    1    2    3    3  8.633062   1   1\n96   96    3    4    2    2 10.174559   1   1\n97   97    3    2    2    2        NA   1   1\n98   98    4    3    2    2  6.022669   1   1\n99   99    3    3    2    2 10.701638   1   1\n100 100    3   NA    2    2        NA   0   1\n101 101    2    3    3    3 11.536565   0   1\n102 102    3    3    2    3        NA   1   1\n103 103    2    2    3    3  7.082311   1   1\n104 104    3    3    2    3  7.990254   1   1\n105 105    2    2    3    3 13.223930   1   1\n106 106    2    3    2    3  8.847114   0   1\n107 107    2   NA    3    3 11.477532   0   1\n108 108    3    4    1    1  8.809008  NA   1\n109 109    2    2    3    2  8.917741   1   1\n110 110    2    2    3    4  9.059646   0   1\n111 111    2    2    3    3        NA   1   1\n112 112    2   NA    2    2  7.801995   1   1\n113 113    2   NA    3    3        NA   1   1\n114 114    4    3    1    1        NA   1   1\n115 115    2    2    3    3  8.336241   0   1\n116 116    3    3    2    2 12.158201   1   1\n117 117    2    2    2    3        NA   1   1\n118 118    2    2    4    3 11.067872   1   1\n119 119    3   NA    2    2 11.700517   0   1\n120 120    3    2    3    2  9.562434   0   1\n121 121    3    3    3    2  8.977396   0   1\n122 122    3    2    3    2 10.162202   0   1\n123 123    3    3    3    2  9.885336   0   1\n124 124    3    2    3    3 12.560990   1   1\n125 125    2    2    4    4 11.087431   1   1\n126 126    3    3    4    3 10.371456   1   1\n127 127    3    4    1    2  9.319275   1   1\n128 128    2    2    2    3 11.008828   1   1\n129 129    1    2    3    2  9.656535   0   1\n130 130    1    2    3    4 10.032404   0   1\n131 131    2    2    3    3  6.974716   1   1\n132 132    3    2    2    3  9.168019   1   1\n133 133    2    1    3    4 10.658201   1   1\n134 134    3    2    2    2 10.723573   1   1\n135 135    1    2    4    3  9.564175   1   1\n136 136    2    3    3    2  9.440463   1   1\n137 137    1    2    3    4  8.574188   1   1\n138 138    2    2    3    3  8.336412   0   1\n139 139    3    2    2    2 11.316498   0   1\n140 140    4    3    2    2 10.089194   1   1\n141 141    3    3    2    2 11.326115   0   1\n142 142    2    3    2    2 10.544879   1   1\n143 143    4    3    2    2  8.278763   0   1\n144 144    3    3    2    2  9.165442   0   1\n145 145    3    4    2    2 14.840083   0   1\n146 146    4    4    1    1  9.177470   0   1\n147 147    2    3    1    1 10.392509   1   1\n148 148    3    3    2    3 10.074265   1   1\n149 149    2   NA    2    2 10.394414   0   1\n150 150    2    3    2    2        NA   0   1\n151 151    2    2    3    3 11.303224   0   2\n152 152    3    3    2    2  8.301101   0   2\n153 153    3    4    2    2 11.552966   1   2\n154 154    3    3    2    2 10.420355   1   2\n155 155    3    4    2    2 12.648300   1   2\n156 156    2    2    3    2  9.985757   1   2\n157 157    2    3    2    2 10.504636   0   2\n158 158    1   NA    4    4        NA   1   2\n159 159    2    2    3    3  9.576623   0   2\n160 160    3    3    2    2 12.855773   1   2\n161 161    2    1    3    4 10.131071   0   2\n162 162    2    3    3    3 11.018442   1   2\n163 163    3    3    2    2 10.910317   1   2\n164 164    1   NA    3    4  9.682431   0   2\n165 165    3    2    3    3 10.402108   1   2\n166 166    2    2    3    2 11.020302   0   2\n167 167    2    2    3    3 10.862003   1   2\n168 168    3   NA    2    1 12.021632   0   2\n169 169    2   NA    2    3 11.145560   1   2\n170 170    3   NA    1    2 11.157485   1   2\n171 171    3    3    2    1 11.156488   1   2\n172 172    1    2    3    3 11.774043   0   2\n173 173    3    2    3    2  9.014673   0   2\n174 174    4    4    1    1  9.755259   1   2\n175 175    3    3    3    3  7.710862   0   2\n176 176    1    1    4    4 11.418964   1   2\n177 177    1    2    4    3 10.702477   0   2\n178 178    3    2    3    2 11.237905   1   2\n179 179    3    1    2    2  9.225546   0   2\n180 180    3    3    2    2  9.673228   0   2\n181 181    2    3    2    2  9.358897   0   2\n182 182    3    2    3    3  9.252146   1   2\n183 183    2    2    3    3  8.616693   0   2\n184 184    3    4    2    2 10.721936   0   2\n185 185    3    3    2    2 11.054393   0   2\n186 186    1    1    4    4  8.094315   1   2\n187 187    3    3    1    2  9.231779   0   2\n188 188    3    3    2    2  8.547865   1   2\n189 189    3    3    3    3 10.345779   0   2\n190 190    1    2    3    3 13.226910  NA   2\n191 191    2    2    3    4 10.411992   0   2\n192 192    3    3    2    3  8.971620   1   2\n193 193    1    2    4    4 10.898386   0   2\n194 194    2    2    3    3 10.625394   1   2\n195 195    2    2    3    4  6.357136   0   2\n196 196    1    2    3    3 12.102026   1   2\n197 197    2    3    3    2        NA   0   2\n198 198    2    3    3    3  6.586317   1   2\n199 199    3    3    3    2  9.050529   1   2\n200 200    2    2    3    3 12.723541   1   2\n201 201    2    2    3    3  9.753327  NA   2\n202 202    2    2    2    2 13.303115   1   2\n203 203    2    3    2    2        NA   0   2\n204 204    3    3    2    2 11.445677   0   2\n205 205    2    2    2    2  9.306572   0   2\n206 206    3    1    3    3  8.328087   0   2\n207 207    3    4    1    2 10.359319   0   2\n208 208    4    3    1    1        NA   0   2\n209 209    2    2    3    2  9.748836   1   2\n210 210    2    2    3    3 11.357677   0   2\n211 211    3    3    2    2  9.790493   1   2\n212 212    3    3    3    3  8.325024   0   2\n213 213    2    2    2    2  9.281008   1   2\n214 214    3    2    2    2 13.164568   0   2\n215 215    2    2    2    2  7.828867   0   2\n216 216    3    3    3    3 10.665805   0   2\n217 217    2    1    3    3 10.635206   1   2\n218 218    2   NA    3    2  7.969089   1   2\n219 219    2    2    2    3  8.923574   0   2\n220 220    2    2    2    2  7.883175  NA   2\n221 221    4   NA    2    1  8.577328   1   2\n222 222    2   NA    4    4  8.257213   1   2\n223 223    3    3    3    2 10.397873   1   2\n224 224    4    3    2    2 10.241358   1   2\n225 225    3    3    2    1  9.874614   1   2\n226 226    2    3    2    2  9.251216   0   2\n227 227    3    2    2    2 11.927287   0   2\n228 228    4    4    2    2 10.327432   0   2\n229 229    3    2    3    2  6.475004   0   2\n230 230    2    3    3    3 11.338842   0   2\n231 231    2    3    2    2        NA   1   2\n232 232    3    3    2    2  7.933710   0   2\n233 233    2    3    3    3 10.721250   1   2\n234 234    3    2    3    3  8.086553   0   2\n235 235    2    3    3    3 12.252961  NA   2\n236 236    3    3    2    2  9.883740  NA   2\n237 237    2    2    2    3 11.260712   0   2\n238 238    4    3    2    1        NA   1   2\n239 239    3   NA    2    2 13.991412   1   2\n240 240    2    3    2    3  9.606693   1   2\n241 241    2    2    2    2  9.965807   1   2\n242 242    3    3    2    2  6.665730  NA   2\n243 243    2    2    2    2 11.588374   1   2\n244 244    2    1    3    3 12.054486   0   2\n245 245    2    1    3    2  8.551229   1   2\n246 246    1    1    4    4 14.758472   1   2\n247 247    3    3    2    1 10.601619   1   2\n248 248    2    3    2    3  9.608768   1   2\n249 249    2    2    3    4 10.631563   0   2\n250 250    3    4    1    1  9.195155   0   2\n251 251    3    2    3    3 12.153778   1   2\n252 252    2    1    4    4 11.594112   1   2\n253 253    3    3    2    2 12.749052   0   2\n254 254    2    1    3    3 10.904641   1   2\n255 255    2    2    3    3  9.674235  NA   2\n256 256    3    3    1    1  9.382583   1   2\n257 257    2    2    4    3 10.075463   1   2\n258 258    1    1    3    2        NA   0   2\n259 259    3   NA    3    3        NA   1   2\n260 260    3    3    2    2 10.003249   0   2\n261 261    2    2    3    3 10.357645   0   2\n262 262    1    2    3    3 11.427154   0   2\n263 263    1    2    4    3 11.141758   1   2\n264 264    2    2    3    3 11.717822   0   2\n265 265    3    3    2    1  8.591719   1   2\n266 266    4    3    2    2  7.199316   1   2\n267 267    2    2    3    3  8.511259  NA   2\n268 268    1   NA    4    4 13.183838   1   2\n269 269    3   NA    2    2  9.723661   0   2\n270 270    3    2    1    1  9.901684   1   2\n271 271    2    2    2    3 11.543191   1   2\n272 272    3    2    3    2  9.905296   0   2\n273 273    3    3    2    2 10.804370   0   2\n274 274    3    3    1    1  9.135004   1   2\n275 275    3   NA    2    2  9.937281   1   2\n276 276    2    2    4    4  8.449205  NA   2\n277 277    4    4    2    2 10.110370   1   2\n278 278    2    3    3    3  8.910521   1   2\n279 279    3    3    2    2 11.335096   0   2\n280 280    2    3    3    3 10.872968   1   2\n281 281    3    3    2    2  9.550622   0   2\n282 282    1   NA    4    4        NA   1   2\n283 283    1   NA    3    4 12.176753   0   2\n284 284    2    2    2    2  9.628909   0   2\n285 285    2    2    3    3 13.948810   0   2\n286 286    2   NA    3    3 12.154323   1   2\n287 287    3    2    2    2  9.487855   1   2\n288 288    3    3    3    2 10.250928   0   2\n289 289    3    2    3    3 10.038493   0   2\n290 290    3    2    2    2  9.110477  NA   2\n291 291    3    3    2    3 11.294503   1   2\n292 292    2    2    3    3 12.974758   0   2\n293 293    3    3    2    2 10.285506   0   2\n294 294    3    2    3    3 10.156128   1   2\n295 295    3    4    3    3 10.477511   0   2\n296 296    2    2    3    4 11.463436   0   2\n297 297    2    3    2    2 10.958489   0   2\n298 298    3    2    2    2  8.164545   0   2\n299 299    2    3    3    3 10.140617   0   2\n300 300    3   NA    2    2  9.653269   1   2\n301 301    1    1    3    3        NA   0   3\n302 302    2    3    2    3  9.384978   1   3\n303 303    2    2    3    3  7.993749   1   3\n304 304    2    3    3    3  6.955896   1   3\n305 305    4    3    2    2 10.535078   0   3\n306 306    4    3    1    2        NA   1   3\n307 307    2    2    2    2  9.815517  NA   3\n308 308    4    4    1    1 10.504347   1   3\n309 309    2    3    2    2  9.939982   0   3\n310 310    3    3    3    3 10.389400   1   3\n311 311    2    2    3    3  9.448678   1   3\n312 312    2    4    1    2 10.221263   1   3\n313 313    2   NA    2    2  7.693476   0   3\n314 314    3    3    2    1 11.177018   1   3\n315 315    2    2    3    2  9.339305   0   3\n316 316    3    2    2    2  6.542470   1   3\n317 317    4    3    1    2  8.953333   1   3\n318 318    3    2    3    3        NA   0   3\n319 319    2    1    3    3  7.581036   0   3\n320 320    3    3    2    1  9.966598  NA   3\n321 321    3    2    3    3 10.881096   1   3\n322 322    2    2    4    3  9.503126   1   3\n323 323    3    3    2    2 10.542913   1   3\n324 324    2    1    4    3  7.226064   1   3\n325 325    2    2    3    3        NA   0   3\n326 326    3    3    1    2 10.473550   1   3\n327 327    3    2    2    2        NA   1   3\n328 328    3    3    2    2 10.490264   0   3\n329 329    3    3    2    1 11.740022   1   3\n330 330    3    3    2    2 11.473238   0   3\n331 331    3    3    2    3 12.689666  NA   3\n332 332    3    3    2    2        NA   0   3\n333 333    3    3    2    2  7.619042   0   3\n334 334    3    2    2    2  9.525225   1   3\n335 335    3    2    2    2  9.301695   1   3\n336 336    1    1    4    4 10.235494   1   3\n337 337    3    2    2    3        NA   0   3\n338 338    3    2    3    3 10.078303   0   3\n339 339    3    3    2    2        NA   1   3\n340 340    2    3    2    2  9.613427   0   3\n341 341    2    3    2    2 10.440469   1   3\n342 342    1    2    4    3        NA   0   3\n343 343    2    2    3    3  9.632019   0   3\n344 344    3   NA    2    1 11.285079   0   3\n345 345    3    4    2    2 12.780121  NA   3\n346 346    3    3    2    3 10.358045   0   3\n347 347    3    3    2    3  9.452587   0   3\n348 348    2    2    3    3 10.616298   0   3\n349 349    2    2    3    4 10.531881   1   3\n350 350    3    2    3    3 10.917065   0   3\n351 351    3    4    2    2  6.753558   1   3\n352 352    3    3    1    1  9.081102   1   3\n353 353    2    2    3    3  9.324282   0   3\n354 354    3    4    2    2  9.556236   1   3\n355 355    3    3    2    3  8.404846   1   3\n356 356    3    3    2    2  9.835171   1   3\n357 357    3    3    2    1        NA   1   3\n358 358    3    3    2    2  9.347660   1   3\n359 359    2   NA    3    3  7.015727   0   3\n360 360    3    3    2    2  8.146446   0   3\n361 361    3    3    1    2  7.774709   1   3\n362 362    3    3    2    2  6.083013   1   3\n363 363    2    3    3    3  8.618334   1   3\n364 364    2   NA    3    2 10.029465   0   3\n365 365    3   NA    2    1 10.539754   1   3\n366 366    2    3    3    3 11.498595   0   3\n367 367    2    2    4    4        NA   0   3\n368 368    3    4    2    2 11.885905   0   3\n369 369    2    1    3    3 10.151313   0   3\n370 370    2    3    2    3  8.703436   1   3\n371 371    1    2    3    4 11.715882   1   3\n372 372    2    2    3    3 10.497316  NA   3\n373 373    2    2    3    2  9.260014   0   3\n374 374    2    1    4    4 12.764876   0   3\n375 375    2    3    3    3 11.855908   0   3\n376 376    2    2    3    3 11.346669   1   3\n377 377    2    3    3    2 10.437059   0   3\n378 378    3    3    2    3        NA   0   3\n379 379    3   NA    2    2  8.338840   1   3\n380 380    3    2    2    3 11.449698   0   3\n381 381    3    3    2    2        NA   0   3\n382 382    2   NA    2    2 10.331462   0   3\n383 383    3    3    2    1 10.240093   1   3\n384 384    3    3    3    3 12.629684   0   3\n385 385    3    3    2    2 10.858224   0   3\n386 386    2    3    3    3        NA   1   3\n387 387    2    3    3    3 11.439490  NA   3\n388 388    3    3    2    2  8.881271   1   3\n389 389    3   NA    3    3 10.293081   1   3\n390 390    3    3    3    3 10.192251   0   3\n391 391    3    3    1    2 11.065900   0   3\n392 392    3    3    2    2 10.998406   1   3\n393 393    2    2    3    2  8.552346   1   3\n394 394    4    3    1    2  9.412805   0   3\n395 395    2    2    3    3  9.894383  NA   3\n396 396    1    2    3    3        NA   1   3\n397 397    3    3    2    2        NA   1   3\n398 398    3    2    3    3  9.242431   1   3\n399 399    2    2    3    3 10.957836  NA   3\n400 400    3    3    3    3 10.084902   1   3\n401 401    3    2    2    2 10.097882   0   3\n402 402    3    3    1    1 11.672478   0   3\n403 403    3    4    2    1 13.353267   0   3\n404 404    1    2    4    4 10.107733   0   3\n405 405    2    3    3    3 10.847647   0   3\n406 406    3    3    1    1  8.989002   1   3\n407 407    4    3    2    2  9.767775   0   3\n408 408    3    3    3    2  8.104969   1   3\n409 409    3    3    2    2 11.940227   0   3\n410 410    2    1    4    3  8.396467   1   3\n411 411    2   NA    2    3  9.219042   0   3\n412 412    2    2    2    3  9.927729   1   3\n413 413    3    3    2    2  9.120070   0   3\n414 414    3    2    2    2  9.359507   1   3\n415 415    3    2    3    3  7.340234   0   3\n416 416    3    3    2    2  8.565667   1   3\n417 417    3    2    2    3 11.829203   1   3\n418 418    2    2    2    2  9.444976   1   3\n419 419    1    1    4    4  8.163760   1   3\n420 420    1    2    2    3  7.971904   0   3\n421 421    2    2    2    3        NA   1   3\n422 422    2    2    3    2 10.435981   1   3\n423 423    1    2    3    3 11.167197   0   3\n424 424    4    3    2    2  9.076633   0   3\n425 425    3    3    2    2  9.734855   0   3\n426 426    3    3    1    1  9.520808   0   3\n427 427    2    2    2    2  8.750194   0   3\n428 428    2    2    3    3 10.203757   1   3\n429 429    3    3    2    2  8.855370   0   3\n430 430    3    2    3    2 13.023492   1   3\n431 431    3    3    3    2        NA   0   3\n432 432    3    2    3    2        NA  NA   3\n433 433    2    2    3    4  8.328651   1   3\n434 434    3    2    3    2  9.358613   0   3\n435 435    4    3    2    2 11.184436   0   3\n436 436    2    2    4    3 10.608993  NA   3\n437 437    2   NA    3    3 12.301002   0   3\n438 438    3    3    2    2        NA   0   3\n439 439    4    4    1    1  9.609236   0   3\n440 440    2    3    2    2  9.303808   0   3\n441 441    3    3    2    2 10.739005   0   3\n442 442    3    3    3    3        NA   0   3\n443 443    2    3    3    3 10.028578   1   3\n444 444    4    4    2    2 10.703093   1   3\n445 445    3    4    2    2        NA   1   3\n446 446    3    2    3    3 10.775893   1   3\n447 447    2    2    3    3 10.714497   0   3\n448 448    3    2    2    2  9.476227   0   3\n449 449    4   NA    1    1  7.254288   1   3\n450 450    2    2    3    2  5.788306  NA   3\n451 451    3    3    2    2  9.860913   0   3\n452 452    3    4    1    2  9.406198   1   3\n453 453    3    3    2    2  7.358570   0   3\n454 454    3    4    2    2  9.143064   1   3\n455 455    3    4    2    2 11.833885   0   3\n456 456    2    2    4    3 10.510292   1   3\n457 457    4    3    2    2 11.219608   1   3\n458 458    2    2    3    3 13.257474   0   3\n459 459    2    2    3    4  7.569693   0   3\n460 460    2    2    4    3 11.684286   1   3\n461 461    1    2    4    4 10.056906  NA   3\n462 462    2    2    3    3  9.203611   1   3\n463 463    2    2    3    3 11.462454   1   3\n464 464    3    2    3    3  8.608740   1   3\n465 465    3    3    3    2  8.550825   0   3\n466 466    2    2    3    3        NA   1   3\n467 467    2   NA    3    3  9.467938   1   3\n468 468    3    3    2    2  9.638242   0   3\n469 469    4    3    2    2 11.559736   0   3\n470 470    2    3    2    2  9.289579   1   3\n471 471    2    2    4    3 10.660731   0   3\n472 472    1    2    4    4  8.653708   1   3\n473 473    3   NA    2    3 11.267748   0   3\n474 474    3   NA    2    2  6.386290   0   3\n475 475    2    2    2    2 10.394297   0   3\n476 476    3    3    2    2        NA   1   3\n477 477    2    1    3    3 11.588138   1   3\n478 478    3    2    3    3  9.701818   1   3\n479 479    2    2    3    3 10.131820   0   3\n480 480    3    2    2    3 11.851048   0   3\n481 481    2    2    3    3  8.094906   0   3\n482 482    2    3    2    3  6.522122   0   3\n483 483    2   NA    4    4  9.492688   1   3\n484 484    3    2    2    2  7.171610   1   3\n485 485    4    3    1    2 10.449040   1   3\n486 486    3    3    2    2  8.565564   1   3\n487 487    2    3    2    3  9.692163   0   3\n488 488    2    3    3    2 10.544790   0   3\n489 489    1    1    4    4  9.152848   1   3\n490 490    3   NA    2    3 11.417658   0   3\n491 491    2   NA    3    3 10.335521   1   3\n492 492    3    4    2    2 12.157326   1   3\n493 493    2    2    4    3  8.071642   1   3\n494 494    2    2    3    3        NA   1   3\n495 495    2    2    2    2        NA   0   3\n496 496    2    2    2    2  9.657121   1   3\n497 497    2    2    3    3  8.421820   1   3\n498 498    2    2    3    2 11.234864   0   3\n499 499    3    3    3    2 11.684493   1   3\n500 500    2   NA    3    3 10.551730   1   3\n501 501    3    2    3    3  9.518572   0   4\n502 502    2   NA    2    2        NA   0   4\n503 503    3    2    2    2  9.394796   1   4\n504 504    3    2    2    2 10.871842   0   4\n505 505    3    3    1    1 11.807168   1   4\n506 506    4    4    2    2        NA   0   4\n507 507    2    3    3    3 11.295793   0   4\n508 508    3    2    3    3  9.704389   1   4\n509 509    3    3    2    1 12.982000   1   4\n510 510    3    2    2    3  8.051677   0   4\n511 511    2    3    3    3 10.134297   1   4\n512 512    2    3    2    2 10.915921   0   4\n513 513    4    3    2    3  9.464469  NA   4\n514 514    3    2    3    3  9.377179   1   4\n515 515    2   NA    3    3  6.628830   0   4\n516 516    2    2    3    3  9.799799   0   4\n517 517    2    2    3    3  9.352013   0   4\n518 518    3    2    3    3  7.578805   0   4\n519 519    2    3    3    2  8.955748   0   4\n520 520    3    3    1    2  7.345759   1   4\n521 521    2    3    3    2  9.038828   0   4\n522 522    3    2    3    3  6.462564   0   4\n523 523    3    3    2    2  8.710578   0   4\n524 524    2    2    3    3  8.078165   1   4\n525 525    3    3    3    3  9.308461   0   4\n526 526    2    3    3    2  9.621561   0   4\n527 527    2    3    2    2 10.468559   1   4\n528 528    2    2    4    3 12.527006   0   4\n529 529    1    1    4    4  9.713401   0   4\n530 530    2    3    2    3 12.449355   1   4\n531 531    4    3    1    2 10.171527   1   4\n532 532    2    2    4    3 11.592511   1   4\n533 533    2    2    3    3  9.746639   0   4\n534 534    2    2    2    3 11.539024   0   4\n535 535    3    4    1    1 12.662389   1   4\n536 536    3    3    2    2  8.558018   1   4\n537 537    3    4    1    2 12.490442   0   4\n538 538    3    4    2    2  8.849825   1   4\n539 539    3    3    3    3        NA   1   4\n540 540    2    2    2    3  9.856794   1   4\n541 541    1    2    3    4        NA   1   4\n542 542    2    3    2    3 10.455994   0   4\n543 543    3    3    1    2  8.953355   0   4\n544 544    3    3    2    2 10.233466   1   4\n545 545    2   NA    3    2 11.345757   0   4\n546 546    3    3    2    1 11.511366   0   4\n547 547    3    3    2    2  7.030045   0   4\n548 548    2    1    4    4 11.833564   0   4\n549 549    2   NA    4    3 10.347853   0   4\n550 550    2    3    2    2 10.669845   1   4\n551 551    3    3    3    2 11.945497   0   4\n552 552    3    3    1    1  7.631776   0   4\n553 553    2    2    3    3  7.929047   0   4\n554 554    2    3    2    2 10.655136   1   4\n555 555    4    4    1    1 11.651111   1   4\n556 556    3    3    2    2  9.499631   0   4\n557 557    2    3    2    3  9.869376   1   4\n558 558    3    3    1    2 10.573739   0   4\n559 559    2    2    3    4  6.777733   0   4\n560 560    3    3    2    1 10.292540   0   4\n561 561    3    2    3    2  8.420615   0   4\n562 562    3   NA    1    1        NA   0   4\n563 563    3    3    2    2        NA   0   4\n564 564    3   NA    2    2 11.011815  NA   4\n565 565    3    3    2    2  9.567283   1   4\n566 566    3    2    2    2  9.700664   1   4\n567 567    2    2    4    3  9.035493   1   4\n568 568    2    2    3    3  6.920118   0   4\n569 569    3   NA    2    2 12.785713   0   4\n570 570    3    3    3    2        NA   0   4\n571 571    4    4    1    1 11.561428   0   4\n572 572    3    2    2    2 10.479614   1   4\n573 573    3    2    2    3 12.062231   0   4\n574 574    3    3    3    2 11.258923   1   4\n575 575    2    2    3    3  8.535113   1   4\n576 576    3    2    2    2 12.190370  NA   4\n577 577    3    3    2    2  9.513192   0   4\n578 578    3    2    3    4        NA   1   4\n579 579    3    3    3    3        NA   1   4\n580 580    2   NA    3    3        NA   1   4\n581 581    1    2    3    3  7.840196   1   4\n582 582    3    2    1    2        NA   0   4\n583 583    2    3    3    3 11.716523   1   4\n584 584    2    2    3    3 10.115714   0   4\n585 585    2    1    2    3 10.487666   1   4\n586 586    3    3    2    2 10.129045   1   4\n587 587    4    3    2    2 10.213173   0   4\n588 588    1    1    3    3 12.114688   1   4\n589 589    2    2    3    3 11.655211   0   4\n590 590    1    2    4    4 10.474828   1   4\n591 591    2    3    3    2  9.222274   0   4\n592 592    3    3    3    3 10.053230   0   4\n593 593    2    1    3    3  8.360811  NA   4\n594 594    2    2    4    4        NA   1   4\n595 595    3    3    3    2 10.611019   0   4\n596 596    3    3    2    3 11.952722  NA   4\n597 597    2    3    2    2        NA   0   4\n598 598    2    3    3    3 12.403272   0   4\n599 599    2    2    3    4        NA   1   4\n600 600    4    3    1    1 12.933026   0   4\n601 601    3    4    2    2  9.675024  NA   4\n602 602    3    2    3    3  9.797451   0   4\n603 603    3   NA    3    3        NA   1   4\n604 604    2    3    3    3  5.697734   1   4\n605 605    4    3    3    2 11.315240   0   4\n606 606    3    3    2    2  9.398728   0   4\n607 607    2    2    3    3        NA   1   4\n608 608    3    4    2    1  7.712797   0   4\n609 609    4    3    2    2 11.397924   1   4\n610 610    2   NA    3    3 10.497554   1   4\n611 611    2   NA    2    2  9.537385   0   4\n612 612    2    1    4    3  8.434417   1   4\n613 613    2    2    3    3  9.741397   1   4\n614 614    3    2    2    3        NA   0   4\n615 615    2   NA    2    2 10.524864   1   4\n616 616    3    3    2    2  8.498451   0   4\n617 617    1    2    3    3 10.447842   0   4\n618 618    3    3    3    3  6.916193   0   4\n619 619    3    2    3    3  7.967729   0   4\n620 620    2    2    3    3 10.971877   0   4\n621 621    1    2    3    3 10.036674   1   4\n622 622    4    4    1    2 11.171656   0   4\n623 623    2    2    3    3  9.809559   1   4\n624 624    3    2    2    2  8.970928   0   4\n625 625    2    2    4    4 10.715082   0   4\n626 626    3    3    3    2  7.928970   1   4\n627 627    2    3    3    3  6.909529   1   4\n628 628    2    3    3    2 10.799244   0   4\n629 629    3   NA    2    2  6.011167   0   4\n630 630    2    2    2    1 12.505498   0   4\n631 631    4    4    1    1  9.779263   1   4\n632 632    3    3    2    3  9.474470   0   4\n633 633    2    2    3    3 12.139497   0   4\n634 634    3    3    3    2 11.067315   0   4\n635 635    3    4    2    3  8.320202   0   4\n636 636    3    2    2    2  7.182648   1   4\n637 637    2    2    4    4 10.130177   0   4\n638 638    3    3    3    3 12.496180   0   4\n639 639    2    2    3    3 12.592766   0   4\n640 640    2    2    2    3  9.907003   0   4\n641 641    3    2    3    3 11.737818   1   4\n642 642    3    2    2    1  8.821091   0   4\n643 643    2    3    3    2  6.860783   0   4\n644 644    3    2    3    3 10.268927   1   4\n645 645    3    3    2    2 10.266885   1   4\n646 646    3    3    2    2  5.763412   0   4\n647 647    3    2    2    2  7.066767   1   4\n648 648    3    3    3    2  9.180560   0   4\n649 649    3    3    2    2 12.972046   1   4\n650 650    1   NA    2    3  8.906204   1   4\n651 651    3    3    2    2 11.411023   1   4\n652 652    2    2    2    3 10.049973   0   4\n653 653    2    2    3    2 11.337266   0   4\n654 654    3    3    3    3 13.679508   0   4\n655 655    2    3    3    3  8.168574   1   4\n656 656    3    3    2    2 12.273152  NA   4\n657 657    2    3    3    3  9.269406   0   4\n658 658    2    3    2    2        NA   1   4\n659 659    3    3    2    2  8.932260   1   4\n660 660    3    3    1    2  7.922082   0   4\n661 661    2    2    3    3 11.825439   0   4\n662 662    3    2    2    2        NA   0   4\n663 663    2    1    3    3 13.418967   0   4\n664 664    3    2    3    3 12.795091   0   4\n665 665    2    3    3    3  9.076854   0   4\n666 666    2    2    2    2  9.791845   1   4\n667 667    2    3    2    2  7.201118   0   4\n668 668    2    3    2    2        NA   1   4\n669 669    3    3    3    3 11.357964   1   4\n670 670    3    3    2    2 10.881354   0   4\n671 671    2    1    3    3 10.379563   0   4\n672 672    3    2    3    3        NA   1   4\n673 673    3   NA    2    2  9.222115  NA   4\n674 674    3    3    3    2  8.146615   1   4\n675 675    2    3    2    2  9.175585   0   4\n676 676    2    2    4    4 12.131668   1   4\n677 677    2   NA    2    2 10.870383   0   4\n678 678    1    2    3    3 11.473233   1   4\n679 679    3    3    2    3  9.506655   1   4\n680 680    2    3    2    2 10.030170   0   4\n681 681    3   NA    2    2 10.886894  NA   4\n682 682    1    1    3    4 10.668823   0   4\n683 683    2    3    3    3  9.386863   1   4\n684 684    2    2    3    3  7.093356   1   4\n685 685    2    2    3    3 12.640182   1   4\n686 686    1    2    3    3  8.807493   1   4\n687 687    3    3    3    3 14.291764   0   4\n688 688    1    1    4    4        NA   0   4\n689 689    3    3    2    3  5.439760   0   4\n690 690    3    2    2    2        NA   0   4\n691 691    2    2    3    3  8.718412   1   4\n692 692    3    3    2    2  8.041810   1   4\n693 693    3    3    2    2        NA  NA   4\n694 694    3    2    3    3 10.982985   1   4\n695 695    1    2    2    3 10.007353   0   4\n696 696    3    2    2    2  8.467930   0   4\n697 697    4    4    1    2 10.328330  NA   4\n698 698    2    2    3    3 10.826550   1   4\n699 699    3    2    2    2  9.543067   1   4\n700 700    3    3    1    2 10.025428   1   4\n701 701    2    3    3    3 10.668717   1   4\n702 702    3    3    3    3 10.518729   1   4\n703 703    3    3    2    2 10.808743   1   4\n704 704    2    2    2    2  7.725368   1   4\n705 705    3    3    2    3 10.498354   1   4\n706 706    2    2    2    2        NA   0   4\n707 707    3    4    2    2 11.808316   1   4\n708 708    2    2    4    4  9.354355   0   4\n709 709    1    1    4    4  6.893923   0   4\n710 710    2    3    2    3 10.715373   1   4\n711 711    4    3    2    2        NA   1   4\n712 712    2    3    2    3 10.579138   1   4\n713 713    3    2    3    3  7.743470   1   4\n714 714    2    2    2    2        NA   1   4\n715 715    3    3    1    2 11.443266   1   4\n716 716    3    2    3    3 10.739886   0   4\n717 717    3    2    3    3  9.666964  NA   4\n718 718    3    2    2    2        NA   0   4\n719 719    4    3    2    2  9.963483   1   4\n720 720    3    3    3    3 12.146356   0   4\n721 721    4   NA    1    1        NA   1   4\n722 722    1    1    4    4 12.437140   0   4\n723 723    3    3    2    2  9.361663   0   4\n724 724    3    2    2    2        NA   1   4\n725 725    4    3    2    2 10.954406   0   4\n726 726    2    3    3    3  8.813882   1   4\n727 727    2    2    3    3  8.399134   1   4\n728 728    2    3    3    3        NA   0   4\n729 729    3   NA    2    2 10.716499   1   4\n730 730    2    2    3    3        NA   0   4\n731 731    2   NA    3    3  9.827114   0   4\n732 732    3    3    2    2 10.646740   1   4\n733 733    2    4    2    1 10.350377   0   4\n734 734    3    3    2    2 10.019486   1   4\n735 735    3    2    2    2  9.739026   1   4\n736 736    2    3    3    4  8.826410   0   4\n737 737    2    2    3    3  8.191695   1   4\n738 738    2    2    3    3  9.700108   0   4\n739 739    2    2    3    3  8.267847   0   4\n740 740    3    4    2    2  8.238960   1   4\n741 741    3    4    2    3  8.657699   1   4\n742 742    2    2    3    3 12.724873   1   4\n743 743    1    1    3    3  9.056560   1   4\n744 744    2    1    3    3 10.776392   1   4\n745 745    3    2    2    3 11.332372   0   4\n746 746    3    3    2    2  9.605044   0   4\n747 747    3    3    2    2 12.553403   0   4\n748 748    3    3    3    2  8.607291   1   4\n749 749    2    2    4    3        NA   0   4\n750 750    3    3    3    2 12.253184   1   4\n\n\n\n\nFiltering can be done using the dplyr::filter() function in combination with duplicated().\n\nShow/hide codeexDat_ID |&gt; \n  dplyr::filter(duplicated(id))\n\n      id msc1 msc2 msc3 msc4       age sex edu\n1201 120    3    2    3    2  9.562434   0   1\n1931 193    1    2    4    4 10.898386   0   2\n2091 209    2    2    3    2  9.748836   1   2\n3201 320    3    3    2    1  9.966598  NA   3\n4941 494    2    2    3    3        NA   1   3\n\n\nHowever, dplyr provides a function dplyr::distinct() which can be used to keep only unique rows.\n\nShow/hide codedplyr::distinct(exDat_ID)\n\n     id msc1 msc2 msc3 msc4       age sex edu\n1     1    2    3    2    2  9.815538   0   0\n2     2    3    2    1    1  8.980194   1   0\n3     3    2    2    3    3 12.758157   0   0\n4     4    2    2    3    2 10.578846   0   0\n5     5    3    2    2    2  9.894364   1   0\n6     6    3    3    3    2 10.446850   0   0\n7     7    4    4    1    2 10.897605   1   0\n8     8    3    3    2    1  7.977382   1   0\n9     9    3    3    2    1 10.688379  NA   0\n10   10    3    3    2    2  9.105864   0   0\n11   11    2    1    3    3  8.540117   0   0\n12   12    2    2    3    3 11.841954   0   0\n13   13    2    2    3    4 11.647655   0   0\n14   14    2    3    3    3 11.745306   0   0\n15   15    2    3    3    3  9.970630   0   0\n16   16    3    3    2    1  8.186501  NA   0\n17   17    2    2    2    2  7.773473   1   0\n18   18    2    2    3    2        NA   1   0\n19   19    2    2    3    3  9.339448   0   0\n20   20    4    4    1    1        NA   1   0\n21   21    4    3    2    2  9.831947   0   0\n22   22    2    3    3    3  9.890266   1   0\n23   23    2    3    2    2 11.501609   0   0\n24   24    2   NA    3    2  9.341404   0   0\n25   25    3    3    2    2 11.540030   1   0\n26   26    2    3    3    3 10.098491   1   0\n27   27    4    3    2    2 10.851320   1   0\n28   28    3    2    2    2  6.735228   1   0\n29   29    3    4    2    2 10.690059   1   0\n30   30    3    2    2    3  9.746659   1   0\n31   31    2    1    4    4  8.983450   0   0\n32   32    2   NA    3    3 11.557894   0   0\n33   33    2    2    3    2  8.057455   1   0\n34   34    2    2    3    3 10.134752   0   0\n35   35    2    3    3    2  8.096160   0   0\n36   36    4    3    1    1  9.404151  NA   0\n37   37    3    3    3    3 12.156118   0   0\n38   38    2    2    3    2  9.600157   0   0\n39   39    2    3    3    3 11.591400   0   0\n40   40    3    4    2    2 10.691193   1   0\n41   41    3    3    3    2 12.622380   0   0\n42   42    3    2    2    2 10.043774   1   0\n43   43    4    3    2    2  8.452508   0   0\n44   44    4    3    2    2 12.029754   1   0\n45   45    3    2    3    3  8.213722   1   0\n46   46    2    3    2    3 11.654911   0   0\n47   47    4    3    1    1  9.086209   1   0\n48   48    3   NA    3    3  9.535470   1   0\n49   49    2    3    3    3  9.617718   0   0\n50   50    2    3    2    2 10.347768   1   0\n51   51    2    1    3    3 10.735626   0   1\n52   52    3    3    3    2 10.903281   1   1\n53   53    2   NA    3    3 10.265831   1   1\n54   54    2    3    4    3 10.824752   0   1\n55   55    3    3    3    3  9.282584   0   1\n56   56    2    3    2    2        NA   0   1\n57   57    2    3    3    3  8.747505   1   1\n58   58    2    2    3    4  8.992998   1   1\n59   59    2    2    3    3 12.632563   1   1\n60   60    2    2    3    3 11.015445   1   1\n61   61    3    3    2    2  9.529734   1   1\n62   62    4    3    1    1 11.569437   1   1\n63   63    4    3    2    2 11.626011   1   1\n64   64    2   NA    3    3 12.371110   0   1\n65   65    2    2    2    3  8.712209   1   1\n66   66    1    2    3    2 12.271368   0   1\n67   67    3    3    2    2 11.514336   1   1\n68   68    4    4    2    1        NA   0   1\n69   69    2    2    2    2 10.858827   1   1\n70   70    2    2    3    4 11.416986   0   1\n71   71    2   NA    1    2 10.722411   0   1\n72   72    2    3    3    3  9.417725   1   1\n73   73    4    3    1    2 10.788379   1   1\n74   74    2    3    2    2  7.527881   1   1\n75   75    2    2    3    3  7.697320   0   1\n76   76    3    4    3    2  9.723288   1   1\n77   77    2    2    3    3  8.457035  NA   1\n78   78    3    3    3    3  9.552697   1   1\n79   79    3    3    3    3 10.766935   1   1\n80   80    3   NA    2    2  8.086932   1   1\n81   81    2    3    2    2 10.027268   0   1\n82   82    4    3    2    2 11.108152   1   1\n83   83    3    3    2    2  9.364853   1   1\n84   84    2   NA    4    4  9.229549   0   1\n85   85    4    3    1    1  8.791437   0   1\n86   86    2    2    3    3 14.699514   1   1\n87   87    1    2    4    3  9.310963   0   1\n88   88    2   NA    2    2  7.862333   0   1\n89   89    3    4    1    2  9.164070   0   1\n90   90    3    2    3    2  9.904690   0   1\n91   91    1    2    3    3  9.949049   0   1\n92   92    1    2    3    2 10.874213   0   1\n93   93    2    3    3    3  9.589440   0   1\n94   94    2    2    3    3  8.396720   0   1\n95   95    1    2    3    3  8.633062   1   1\n96   96    3    4    2    2 10.174559   1   1\n97   97    3    2    2    2        NA   1   1\n98   98    4    3    2    2  6.022669   1   1\n99   99    3    3    2    2 10.701638   1   1\n100 100    3   NA    2    2        NA   0   1\n101 101    2    3    3    3 11.536565   0   1\n102 102    3    3    2    3        NA   1   1\n103 103    2    2    3    3  7.082311   1   1\n104 104    3    3    2    3  7.990254   1   1\n105 105    2    2    3    3 13.223930   1   1\n106 106    2    3    2    3  8.847114   0   1\n107 107    2   NA    3    3 11.477532   0   1\n108 108    3    4    1    1  8.809008  NA   1\n109 109    2    2    3    2  8.917741   1   1\n110 110    2    2    3    4  9.059646   0   1\n111 111    2    2    3    3        NA   1   1\n112 112    2   NA    2    2  7.801995   1   1\n113 113    2   NA    3    3        NA   1   1\n114 114    4    3    1    1        NA   1   1\n115 115    2    2    3    3  8.336241   0   1\n116 116    3    3    2    2 12.158201   1   1\n117 117    2    2    2    3        NA   1   1\n118 118    2    2    4    3 11.067872   1   1\n119 119    3   NA    2    2 11.700517   0   1\n120 120    3    2    3    2  9.562434   0   1\n121 121    3    3    3    2  8.977396   0   1\n122 122    3    2    3    2 10.162202   0   1\n123 123    3    3    3    2  9.885336   0   1\n124 124    3    2    3    3 12.560990   1   1\n125 125    2    2    4    4 11.087431   1   1\n126 126    3    3    4    3 10.371456   1   1\n127 127    3    4    1    2  9.319275   1   1\n128 128    2    2    2    3 11.008828   1   1\n129 129    1    2    3    2  9.656535   0   1\n130 130    1    2    3    4 10.032404   0   1\n131 131    2    2    3    3  6.974716   1   1\n132 132    3    2    2    3  9.168019   1   1\n133 133    2    1    3    4 10.658201   1   1\n134 134    3    2    2    2 10.723573   1   1\n135 135    1    2    4    3  9.564175   1   1\n136 136    2    3    3    2  9.440463   1   1\n137 137    1    2    3    4  8.574188   1   1\n138 138    2    2    3    3  8.336412   0   1\n139 139    3    2    2    2 11.316498   0   1\n140 140    4    3    2    2 10.089194   1   1\n141 141    3    3    2    2 11.326115   0   1\n142 142    2    3    2    2 10.544879   1   1\n143 143    4    3    2    2  8.278763   0   1\n144 144    3    3    2    2  9.165442   0   1\n145 145    3    4    2    2 14.840083   0   1\n146 146    4    4    1    1  9.177470   0   1\n147 147    2    3    1    1 10.392509   1   1\n148 148    3    3    2    3 10.074265   1   1\n149 149    2   NA    2    2 10.394414   0   1\n150 150    2    3    2    2        NA   0   1\n151 151    2    2    3    3 11.303224   0   2\n152 152    3    3    2    2  8.301101   0   2\n153 153    3    4    2    2 11.552966   1   2\n154 154    3    3    2    2 10.420355   1   2\n155 155    3    4    2    2 12.648300   1   2\n156 156    2    2    3    2  9.985757   1   2\n157 157    2    3    2    2 10.504636   0   2\n158 158    1   NA    4    4        NA   1   2\n159 159    2    2    3    3  9.576623   0   2\n160 160    3    3    2    2 12.855773   1   2\n161 161    2    1    3    4 10.131071   0   2\n162 162    2    3    3    3 11.018442   1   2\n163 163    3    3    2    2 10.910317   1   2\n164 164    1   NA    3    4  9.682431   0   2\n165 165    3    2    3    3 10.402108   1   2\n166 166    2    2    3    2 11.020302   0   2\n167 167    2    2    3    3 10.862003   1   2\n168 168    3   NA    2    1 12.021632   0   2\n169 169    2   NA    2    3 11.145560   1   2\n170 170    3   NA    1    2 11.157485   1   2\n171 171    3    3    2    1 11.156488   1   2\n172 172    1    2    3    3 11.774043   0   2\n173 173    3    2    3    2  9.014673   0   2\n174 174    4    4    1    1  9.755259   1   2\n175 175    3    3    3    3  7.710862   0   2\n176 176    1    1    4    4 11.418964   1   2\n177 177    1    2    4    3 10.702477   0   2\n178 178    3    2    3    2 11.237905   1   2\n179 179    3    1    2    2  9.225546   0   2\n180 180    3    3    2    2  9.673228   0   2\n181 181    2    3    2    2  9.358897   0   2\n182 182    3    2    3    3  9.252146   1   2\n183 183    2    2    3    3  8.616693   0   2\n184 184    3    4    2    2 10.721936   0   2\n185 185    3    3    2    2 11.054393   0   2\n186 186    1    1    4    4  8.094315   1   2\n187 187    3    3    1    2  9.231779   0   2\n188 188    3    3    2    2  8.547865   1   2\n189 189    3    3    3    3 10.345779   0   2\n190 190    1    2    3    3 13.226910  NA   2\n191 191    2    2    3    4 10.411992   0   2\n192 192    3    3    2    3  8.971620   1   2\n193 193    1    2    4    4 10.898386   0   2\n194 194    2    2    3    3 10.625394   1   2\n195 195    2    2    3    4  6.357136   0   2\n196 196    1    2    3    3 12.102026   1   2\n197 197    2    3    3    2        NA   0   2\n198 198    2    3    3    3  6.586317   1   2\n199 199    3    3    3    2  9.050529   1   2\n200 200    2    2    3    3 12.723541   1   2\n201 201    2    2    3    3  9.753327  NA   2\n202 202    2    2    2    2 13.303115   1   2\n203 203    2    3    2    2        NA   0   2\n204 204    3    3    2    2 11.445677   0   2\n205 205    2    2    2    2  9.306572   0   2\n206 206    3    1    3    3  8.328087   0   2\n207 207    3    4    1    2 10.359319   0   2\n208 208    4    3    1    1        NA   0   2\n209 209    2    2    3    2  9.748836   1   2\n210 210    2    2    3    3 11.357677   0   2\n211 211    3    3    2    2  9.790493   1   2\n212 212    3    3    3    3  8.325024   0   2\n213 213    2    2    2    2  9.281008   1   2\n214 214    3    2    2    2 13.164568   0   2\n215 215    2    2    2    2  7.828867   0   2\n216 216    3    3    3    3 10.665805   0   2\n217 217    2    1    3    3 10.635206   1   2\n218 218    2   NA    3    2  7.969089   1   2\n219 219    2    2    2    3  8.923574   0   2\n220 220    2    2    2    2  7.883175  NA   2\n221 221    4   NA    2    1  8.577328   1   2\n222 222    2   NA    4    4  8.257213   1   2\n223 223    3    3    3    2 10.397873   1   2\n224 224    4    3    2    2 10.241358   1   2\n225 225    3    3    2    1  9.874614   1   2\n226 226    2    3    2    2  9.251216   0   2\n227 227    3    2    2    2 11.927287   0   2\n228 228    4    4    2    2 10.327432   0   2\n229 229    3    2    3    2  6.475004   0   2\n230 230    2    3    3    3 11.338842   0   2\n231 231    2    3    2    2        NA   1   2\n232 232    3    3    2    2  7.933710   0   2\n233 233    2    3    3    3 10.721250   1   2\n234 234    3    2    3    3  8.086553   0   2\n235 235    2    3    3    3 12.252961  NA   2\n236 236    3    3    2    2  9.883740  NA   2\n237 237    2    2    2    3 11.260712   0   2\n238 238    4    3    2    1        NA   1   2\n239 239    3   NA    2    2 13.991412   1   2\n240 240    2    3    2    3  9.606693   1   2\n241 241    2    2    2    2  9.965807   1   2\n242 242    3    3    2    2  6.665730  NA   2\n243 243    2    2    2    2 11.588374   1   2\n244 244    2    1    3    3 12.054486   0   2\n245 245    2    1    3    2  8.551229   1   2\n246 246    1    1    4    4 14.758472   1   2\n247 247    3    3    2    1 10.601619   1   2\n248 248    2    3    2    3  9.608768   1   2\n249 249    2    2    3    4 10.631563   0   2\n250 250    3    4    1    1  9.195155   0   2\n251 251    3    2    3    3 12.153778   1   2\n252 252    2    1    4    4 11.594112   1   2\n253 253    3    3    2    2 12.749052   0   2\n254 254    2    1    3    3 10.904641   1   2\n255 255    2    2    3    3  9.674235  NA   2\n256 256    3    3    1    1  9.382583   1   2\n257 257    2    2    4    3 10.075463   1   2\n258 258    1    1    3    2        NA   0   2\n259 259    3   NA    3    3        NA   1   2\n260 260    3    3    2    2 10.003249   0   2\n261 261    2    2    3    3 10.357645   0   2\n262 262    1    2    3    3 11.427154   0   2\n263 263    1    2    4    3 11.141758   1   2\n264 264    2    2    3    3 11.717822   0   2\n265 265    3    3    2    1  8.591719   1   2\n266 266    4    3    2    2  7.199316   1   2\n267 267    2    2    3    3  8.511259  NA   2\n268 268    1   NA    4    4 13.183838   1   2\n269 269    3   NA    2    2  9.723661   0   2\n270 270    3    2    1    1  9.901684   1   2\n271 271    2    2    2    3 11.543191   1   2\n272 272    3    2    3    2  9.905296   0   2\n273 273    3    3    2    2 10.804370   0   2\n274 274    3    3    1    1  9.135004   1   2\n275 275    3   NA    2    2  9.937281   1   2\n276 276    2    2    4    4  8.449205  NA   2\n277 277    4    4    2    2 10.110370   1   2\n278 278    2    3    3    3  8.910521   1   2\n279 279    3    3    2    2 11.335096   0   2\n280 280    2    3    3    3 10.872968   1   2\n281 281    3    3    2    2  9.550622   0   2\n282 282    1   NA    4    4        NA   1   2\n283 283    1   NA    3    4 12.176753   0   2\n284 284    2    2    2    2  9.628909   0   2\n285 285    2    2    3    3 13.948810   0   2\n286 286    2   NA    3    3 12.154323   1   2\n287 287    3    2    2    2  9.487855   1   2\n288 288    3    3    3    2 10.250928   0   2\n289 289    3    2    3    3 10.038493   0   2\n290 290    3    2    2    2  9.110477  NA   2\n291 291    3    3    2    3 11.294503   1   2\n292 292    2    2    3    3 12.974758   0   2\n293 293    3    3    2    2 10.285506   0   2\n294 294    3    2    3    3 10.156128   1   2\n295 295    3    4    3    3 10.477511   0   2\n296 296    2    2    3    4 11.463436   0   2\n297 297    2    3    2    2 10.958489   0   2\n298 298    3    2    2    2  8.164545   0   2\n299 299    2    3    3    3 10.140617   0   2\n300 300    3   NA    2    2  9.653269   1   2\n301 301    1    1    3    3        NA   0   3\n302 302    2    3    2    3  9.384978   1   3\n303 303    2    2    3    3  7.993749   1   3\n304 304    2    3    3    3  6.955896   1   3\n305 305    4    3    2    2 10.535078   0   3\n306 306    4    3    1    2        NA   1   3\n307 307    2    2    2    2  9.815517  NA   3\n308 308    4    4    1    1 10.504347   1   3\n309 309    2    3    2    2  9.939982   0   3\n310 310    3    3    3    3 10.389400   1   3\n311 311    2    2    3    3  9.448678   1   3\n312 312    2    4    1    2 10.221263   1   3\n313 313    2   NA    2    2  7.693476   0   3\n314 314    3    3    2    1 11.177018   1   3\n315 315    2    2    3    2  9.339305   0   3\n316 316    3    2    2    2  6.542470   1   3\n317 317    4    3    1    2  8.953333   1   3\n318 318    3    2    3    3        NA   0   3\n319 319    2    1    3    3  7.581036   0   3\n320 320    3    3    2    1  9.966598  NA   3\n321 321    3    2    3    3 10.881096   1   3\n322 322    2    2    4    3  9.503126   1   3\n323 323    3    3    2    2 10.542913   1   3\n324 324    2    1    4    3  7.226064   1   3\n325 325    2    2    3    3        NA   0   3\n326 326    3    3    1    2 10.473550   1   3\n327 327    3    2    2    2        NA   1   3\n328 328    3    3    2    2 10.490264   0   3\n329 329    3    3    2    1 11.740022   1   3\n330 330    3    3    2    2 11.473238   0   3\n331 331    3    3    2    3 12.689666  NA   3\n332 332    3    3    2    2        NA   0   3\n333 333    3    3    2    2  7.619042   0   3\n334 334    3    2    2    2  9.525225   1   3\n335 335    3    2    2    2  9.301695   1   3\n336 336    1    1    4    4 10.235494   1   3\n337 337    3    2    2    3        NA   0   3\n338 338    3    2    3    3 10.078303   0   3\n339 339    3    3    2    2        NA   1   3\n340 340    2    3    2    2  9.613427   0   3\n341 341    2    3    2    2 10.440469   1   3\n342 342    1    2    4    3        NA   0   3\n343 343    2    2    3    3  9.632019   0   3\n344 344    3   NA    2    1 11.285079   0   3\n345 345    3    4    2    2 12.780121  NA   3\n346 346    3    3    2    3 10.358045   0   3\n347 347    3    3    2    3  9.452587   0   3\n348 348    2    2    3    3 10.616298   0   3\n349 349    2    2    3    4 10.531881   1   3\n350 350    3    2    3    3 10.917065   0   3\n351 351    3    4    2    2  6.753558   1   3\n352 352    3    3    1    1  9.081102   1   3\n353 353    2    2    3    3  9.324282   0   3\n354 354    3    4    2    2  9.556236   1   3\n355 355    3    3    2    3  8.404846   1   3\n356 356    3    3    2    2  9.835171   1   3\n357 357    3    3    2    1        NA   1   3\n358 358    3    3    2    2  9.347660   1   3\n359 359    2   NA    3    3  7.015727   0   3\n360 360    3    3    2    2  8.146446   0   3\n361 361    3    3    1    2  7.774709   1   3\n362 362    3    3    2    2  6.083013   1   3\n363 363    2    3    3    3  8.618334   1   3\n364 364    2   NA    3    2 10.029465   0   3\n365 365    3   NA    2    1 10.539754   1   3\n366 366    2    3    3    3 11.498595   0   3\n367 367    2    2    4    4        NA   0   3\n368 368    3    4    2    2 11.885905   0   3\n369 369    2    1    3    3 10.151313   0   3\n370 370    2    3    2    3  8.703436   1   3\n371 371    1    2    3    4 11.715882   1   3\n372 372    2    2    3    3 10.497316  NA   3\n373 373    2    2    3    2  9.260014   0   3\n374 374    2    1    4    4 12.764876   0   3\n375 375    2    3    3    3 11.855908   0   3\n376 376    2    2    3    3 11.346669   1   3\n377 377    2    3    3    2 10.437059   0   3\n378 378    3    3    2    3        NA   0   3\n379 379    3   NA    2    2  8.338840   1   3\n380 380    3    2    2    3 11.449698   0   3\n381 381    3    3    2    2        NA   0   3\n382 382    2   NA    2    2 10.331462   0   3\n383 383    3    3    2    1 10.240093   1   3\n384 384    3    3    3    3 12.629684   0   3\n385 385    3    3    2    2 10.858224   0   3\n386 386    2    3    3    3        NA   1   3\n387 387    2    3    3    3 11.439490  NA   3\n388 388    3    3    2    2  8.881271   1   3\n389 389    3   NA    3    3 10.293081   1   3\n390 390    3    3    3    3 10.192251   0   3\n391 391    3    3    1    2 11.065900   0   3\n392 392    3    3    2    2 10.998406   1   3\n393 393    2    2    3    2  8.552346   1   3\n394 394    4    3    1    2  9.412805   0   3\n395 395    2    2    3    3  9.894383  NA   3\n396 396    1    2    3    3        NA   1   3\n397 397    3    3    2    2        NA   1   3\n398 398    3    2    3    3  9.242431   1   3\n399 399    2    2    3    3 10.957836  NA   3\n400 400    3    3    3    3 10.084902   1   3\n401 401    3    2    2    2 10.097882   0   3\n402 402    3    3    1    1 11.672478   0   3\n403 403    3    4    2    1 13.353267   0   3\n404 404    1    2    4    4 10.107733   0   3\n405 405    2    3    3    3 10.847647   0   3\n406 406    3    3    1    1  8.989002   1   3\n407 407    4    3    2    2  9.767775   0   3\n408 408    3    3    3    2  8.104969   1   3\n409 409    3    3    2    2 11.940227   0   3\n410 410    2    1    4    3  8.396467   1   3\n411 411    2   NA    2    3  9.219042   0   3\n412 412    2    2    2    3  9.927729   1   3\n413 413    3    3    2    2  9.120070   0   3\n414 414    3    2    2    2  9.359507   1   3\n415 415    3    2    3    3  7.340234   0   3\n416 416    3    3    2    2  8.565667   1   3\n417 417    3    2    2    3 11.829203   1   3\n418 418    2    2    2    2  9.444976   1   3\n419 419    1    1    4    4  8.163760   1   3\n420 420    1    2    2    3  7.971904   0   3\n421 421    2    2    2    3        NA   1   3\n422 422    2    2    3    2 10.435981   1   3\n423 423    1    2    3    3 11.167197   0   3\n424 424    4    3    2    2  9.076633   0   3\n425 425    3    3    2    2  9.734855   0   3\n426 426    3    3    1    1  9.520808   0   3\n427 427    2    2    2    2  8.750194   0   3\n428 428    2    2    3    3 10.203757   1   3\n429 429    3    3    2    2  8.855370   0   3\n430 430    3    2    3    2 13.023492   1   3\n431 431    3    3    3    2        NA   0   3\n432 432    3    2    3    2        NA  NA   3\n433 433    2    2    3    4  8.328651   1   3\n434 434    3    2    3    2  9.358613   0   3\n435 435    4    3    2    2 11.184436   0   3\n436 436    2    2    4    3 10.608993  NA   3\n437 437    2   NA    3    3 12.301002   0   3\n438 438    3    3    2    2        NA   0   3\n439 439    4    4    1    1  9.609236   0   3\n440 440    2    3    2    2  9.303808   0   3\n441 441    3    3    2    2 10.739005   0   3\n442 442    3    3    3    3        NA   0   3\n443 443    2    3    3    3 10.028578   1   3\n444 444    4    4    2    2 10.703093   1   3\n445 445    3    4    2    2        NA   1   3\n446 446    3    2    3    3 10.775893   1   3\n447 447    2    2    3    3 10.714497   0   3\n448 448    3    2    2    2  9.476227   0   3\n449 449    4   NA    1    1  7.254288   1   3\n450 450    2    2    3    2  5.788306  NA   3\n451 451    3    3    2    2  9.860913   0   3\n452 452    3    4    1    2  9.406198   1   3\n453 453    3    3    2    2  7.358570   0   3\n454 454    3    4    2    2  9.143064   1   3\n455 455    3    4    2    2 11.833885   0   3\n456 456    2    2    4    3 10.510292   1   3\n457 457    4    3    2    2 11.219608   1   3\n458 458    2    2    3    3 13.257474   0   3\n459 459    2    2    3    4  7.569693   0   3\n460 460    2    2    4    3 11.684286   1   3\n461 461    1    2    4    4 10.056906  NA   3\n462 462    2    2    3    3  9.203611   1   3\n463 463    2    2    3    3 11.462454   1   3\n464 464    3    2    3    3  8.608740   1   3\n465 465    3    3    3    2  8.550825   0   3\n466 466    2    2    3    3        NA   1   3\n467 467    2   NA    3    3  9.467938   1   3\n468 468    3    3    2    2  9.638242   0   3\n469 469    4    3    2    2 11.559736   0   3\n470 470    2    3    2    2  9.289579   1   3\n471 471    2    2    4    3 10.660731   0   3\n472 472    1    2    4    4  8.653708   1   3\n473 473    3   NA    2    3 11.267748   0   3\n474 474    3   NA    2    2  6.386290   0   3\n475 475    2    2    2    2 10.394297   0   3\n476 476    3    3    2    2        NA   1   3\n477 477    2    1    3    3 11.588138   1   3\n478 478    3    2    3    3  9.701818   1   3\n479 479    2    2    3    3 10.131820   0   3\n480 480    3    2    2    3 11.851048   0   3\n481 481    2    2    3    3  8.094906   0   3\n482 482    2    3    2    3  6.522122   0   3\n483 483    2   NA    4    4  9.492688   1   3\n484 484    3    2    2    2  7.171610   1   3\n485 485    4    3    1    2 10.449040   1   3\n486 486    3    3    2    2  8.565564   1   3\n487 487    2    3    2    3  9.692163   0   3\n488 488    2    3    3    2 10.544790   0   3\n489 489    1    1    4    4  9.152848   1   3\n490 490    3   NA    2    3 11.417658   0   3\n491 491    2   NA    3    3 10.335521   1   3\n492 492    3    4    2    2 12.157326   1   3\n493 493    2    2    4    3  8.071642   1   3\n494 494    2    2    3    3        NA   1   3\n495 495    2    2    2    2        NA   0   3\n496 496    2    2    2    2  9.657121   1   3\n497 497    2    2    3    3  8.421820   1   3\n498 498    2    2    3    2 11.234864   0   3\n499 499    3    3    3    2 11.684493   1   3\n500 500    2   NA    3    3 10.551730   1   3\n501 501    3    2    3    3  9.518572   0   4\n502 502    2   NA    2    2        NA   0   4\n503 503    3    2    2    2  9.394796   1   4\n504 504    3    2    2    2 10.871842   0   4\n505 505    3    3    1    1 11.807168   1   4\n506 506    4    4    2    2        NA   0   4\n507 507    2    3    3    3 11.295793   0   4\n508 508    3    2    3    3  9.704389   1   4\n509 509    3    3    2    1 12.982000   1   4\n510 510    3    2    2    3  8.051677   0   4\n511 511    2    3    3    3 10.134297   1   4\n512 512    2    3    2    2 10.915921   0   4\n513 513    4    3    2    3  9.464469  NA   4\n514 514    3    2    3    3  9.377179   1   4\n515 515    2   NA    3    3  6.628830   0   4\n516 516    2    2    3    3  9.799799   0   4\n517 517    2    2    3    3  9.352013   0   4\n518 518    3    2    3    3  7.578805   0   4\n519 519    2    3    3    2  8.955748   0   4\n520 520    3    3    1    2  7.345759   1   4\n521 521    2    3    3    2  9.038828   0   4\n522 522    3    2    3    3  6.462564   0   4\n523 523    3    3    2    2  8.710578   0   4\n524 524    2    2    3    3  8.078165   1   4\n525 525    3    3    3    3  9.308461   0   4\n526 526    2    3    3    2  9.621561   0   4\n527 527    2    3    2    2 10.468559   1   4\n528 528    2    2    4    3 12.527006   0   4\n529 529    1    1    4    4  9.713401   0   4\n530 530    2    3    2    3 12.449355   1   4\n531 531    4    3    1    2 10.171527   1   4\n532 532    2    2    4    3 11.592511   1   4\n533 533    2    2    3    3  9.746639   0   4\n534 534    2    2    2    3 11.539024   0   4\n535 535    3    4    1    1 12.662389   1   4\n536 536    3    3    2    2  8.558018   1   4\n537 537    3    4    1    2 12.490442   0   4\n538 538    3    4    2    2  8.849825   1   4\n539 539    3    3    3    3        NA   1   4\n540 540    2    2    2    3  9.856794   1   4\n541 541    1    2    3    4        NA   1   4\n542 542    2    3    2    3 10.455994   0   4\n543 543    3    3    1    2  8.953355   0   4\n544 544    3    3    2    2 10.233466   1   4\n545 545    2   NA    3    2 11.345757   0   4\n546 546    3    3    2    1 11.511366   0   4\n547 547    3    3    2    2  7.030045   0   4\n548 548    2    1    4    4 11.833564   0   4\n549 549    2   NA    4    3 10.347853   0   4\n550 550    2    3    2    2 10.669845   1   4\n551 551    3    3    3    2 11.945497   0   4\n552 552    3    3    1    1  7.631776   0   4\n553 553    2    2    3    3  7.929047   0   4\n554 554    2    3    2    2 10.655136   1   4\n555 555    4    4    1    1 11.651111   1   4\n556 556    3    3    2    2  9.499631   0   4\n557 557    2    3    2    3  9.869376   1   4\n558 558    3    3    1    2 10.573739   0   4\n559 559    2    2    3    4  6.777733   0   4\n560 560    3    3    2    1 10.292540   0   4\n561 561    3    2    3    2  8.420615   0   4\n562 562    3   NA    1    1        NA   0   4\n563 563    3    3    2    2        NA   0   4\n564 564    3   NA    2    2 11.011815  NA   4\n565 565    3    3    2    2  9.567283   1   4\n566 566    3    2    2    2  9.700664   1   4\n567 567    2    2    4    3  9.035493   1   4\n568 568    2    2    3    3  6.920118   0   4\n569 569    3   NA    2    2 12.785713   0   4\n570 570    3    3    3    2        NA   0   4\n571 571    4    4    1    1 11.561428   0   4\n572 572    3    2    2    2 10.479614   1   4\n573 573    3    2    2    3 12.062231   0   4\n574 574    3    3    3    2 11.258923   1   4\n575 575    2    2    3    3  8.535113   1   4\n576 576    3    2    2    2 12.190370  NA   4\n577 577    3    3    2    2  9.513192   0   4\n578 578    3    2    3    4        NA   1   4\n579 579    3    3    3    3        NA   1   4\n580 580    2   NA    3    3        NA   1   4\n581 581    1    2    3    3  7.840196   1   4\n582 582    3    2    1    2        NA   0   4\n583 583    2    3    3    3 11.716523   1   4\n584 584    2    2    3    3 10.115714   0   4\n585 585    2    1    2    3 10.487666   1   4\n586 586    3    3    2    2 10.129045   1   4\n587 587    4    3    2    2 10.213173   0   4\n588 588    1    1    3    3 12.114688   1   4\n589 589    2    2    3    3 11.655211   0   4\n590 590    1    2    4    4 10.474828   1   4\n591 591    2    3    3    2  9.222274   0   4\n592 592    3    3    3    3 10.053230   0   4\n593 593    2    1    3    3  8.360811  NA   4\n594 594    2    2    4    4        NA   1   4\n595 595    3    3    3    2 10.611019   0   4\n596 596    3    3    2    3 11.952722  NA   4\n597 597    2    3    2    2        NA   0   4\n598 598    2    3    3    3 12.403272   0   4\n599 599    2    2    3    4        NA   1   4\n600 600    4    3    1    1 12.933026   0   4\n601 601    3    4    2    2  9.675024  NA   4\n602 602    3    2    3    3  9.797451   0   4\n603 603    3   NA    3    3        NA   1   4\n604 604    2    3    3    3  5.697734   1   4\n605 605    4    3    3    2 11.315240   0   4\n606 606    3    3    2    2  9.398728   0   4\n607 607    2    2    3    3        NA   1   4\n608 608    3    4    2    1  7.712797   0   4\n609 609    4    3    2    2 11.397924   1   4\n610 610    2   NA    3    3 10.497554   1   4\n611 611    2   NA    2    2  9.537385   0   4\n612 612    2    1    4    3  8.434417   1   4\n613 613    2    2    3    3  9.741397   1   4\n614 614    3    2    2    3        NA   0   4\n615 615    2   NA    2    2 10.524864   1   4\n616 616    3    3    2    2  8.498451   0   4\n617 617    1    2    3    3 10.447842   0   4\n618 618    3    3    3    3  6.916193   0   4\n619 619    3    2    3    3  7.967729   0   4\n620 620    2    2    3    3 10.971877   0   4\n621 621    1    2    3    3 10.036674   1   4\n622 622    4    4    1    2 11.171656   0   4\n623 623    2    2    3    3  9.809559   1   4\n624 624    3    2    2    2  8.970928   0   4\n625 625    2    2    4    4 10.715082   0   4\n626 626    3    3    3    2  7.928970   1   4\n627 627    2    3    3    3  6.909529   1   4\n628 628    2    3    3    2 10.799244   0   4\n629 629    3   NA    2    2  6.011167   0   4\n630 630    2    2    2    1 12.505498   0   4\n631 631    4    4    1    1  9.779263   1   4\n632 632    3    3    2    3  9.474470   0   4\n633 633    2    2    3    3 12.139497   0   4\n634 634    3    3    3    2 11.067315   0   4\n635 635    3    4    2    3  8.320202   0   4\n636 636    3    2    2    2  7.182648   1   4\n637 637    2    2    4    4 10.130177   0   4\n638 638    3    3    3    3 12.496180   0   4\n639 639    2    2    3    3 12.592766   0   4\n640 640    2    2    2    3  9.907003   0   4\n641 641    3    2    3    3 11.737818   1   4\n642 642    3    2    2    1  8.821091   0   4\n643 643    2    3    3    2  6.860783   0   4\n644 644    3    2    3    3 10.268927   1   4\n645 645    3    3    2    2 10.266885   1   4\n646 646    3    3    2    2  5.763412   0   4\n647 647    3    2    2    2  7.066767   1   4\n648 648    3    3    3    2  9.180560   0   4\n649 649    3    3    2    2 12.972046   1   4\n650 650    1   NA    2    3  8.906204   1   4\n651 651    3    3    2    2 11.411023   1   4\n652 652    2    2    2    3 10.049973   0   4\n653 653    2    2    3    2 11.337266   0   4\n654 654    3    3    3    3 13.679508   0   4\n655 655    2    3    3    3  8.168574   1   4\n656 656    3    3    2    2 12.273152  NA   4\n657 657    2    3    3    3  9.269406   0   4\n658 658    2    3    2    2        NA   1   4\n659 659    3    3    2    2  8.932260   1   4\n660 660    3    3    1    2  7.922082   0   4\n661 661    2    2    3    3 11.825439   0   4\n662 662    3    2    2    2        NA   0   4\n663 663    2    1    3    3 13.418967   0   4\n664 664    3    2    3    3 12.795091   0   4\n665 665    2    3    3    3  9.076854   0   4\n666 666    2    2    2    2  9.791845   1   4\n667 667    2    3    2    2  7.201118   0   4\n668 668    2    3    2    2        NA   1   4\n669 669    3    3    3    3 11.357964   1   4\n670 670    3    3    2    2 10.881354   0   4\n671 671    2    1    3    3 10.379563   0   4\n672 672    3    2    3    3        NA   1   4\n673 673    3   NA    2    2  9.222115  NA   4\n674 674    3    3    3    2  8.146615   1   4\n675 675    2    3    2    2  9.175585   0   4\n676 676    2    2    4    4 12.131668   1   4\n677 677    2   NA    2    2 10.870383   0   4\n678 678    1    2    3    3 11.473233   1   4\n679 679    3    3    2    3  9.506655   1   4\n680 680    2    3    2    2 10.030170   0   4\n681 681    3   NA    2    2 10.886894  NA   4\n682 682    1    1    3    4 10.668823   0   4\n683 683    2    3    3    3  9.386863   1   4\n684 684    2    2    3    3  7.093356   1   4\n685 685    2    2    3    3 12.640182   1   4\n686 686    1    2    3    3  8.807493   1   4\n687 687    3    3    3    3 14.291764   0   4\n688 688    1    1    4    4        NA   0   4\n689 689    3    3    2    3  5.439760   0   4\n690 690    3    2    2    2        NA   0   4\n691 691    2    2    3    3  8.718412   1   4\n692 692    3    3    2    2  8.041810   1   4\n693 693    3    3    2    2        NA  NA   4\n694 694    3    2    3    3 10.982985   1   4\n695 695    1    2    2    3 10.007353   0   4\n696 696    3    2    2    2  8.467930   0   4\n697 697    4    4    1    2 10.328330  NA   4\n698 698    2    2    3    3 10.826550   1   4\n699 699    3    2    2    2  9.543067   1   4\n700 700    3    3    1    2 10.025428   1   4\n701 701    2    3    3    3 10.668717   1   4\n702 702    3    3    3    3 10.518729   1   4\n703 703    3    3    2    2 10.808743   1   4\n704 704    2    2    2    2  7.725368   1   4\n705 705    3    3    2    3 10.498354   1   4\n706 706    2    2    2    2        NA   0   4\n707 707    3    4    2    2 11.808316   1   4\n708 708    2    2    4    4  9.354355   0   4\n709 709    1    1    4    4  6.893923   0   4\n710 710    2    3    2    3 10.715373   1   4\n711 711    4    3    2    2        NA   1   4\n712 712    2    3    2    3 10.579138   1   4\n713 713    3    2    3    3  7.743470   1   4\n714 714    2    2    2    2        NA   1   4\n715 715    3    3    1    2 11.443266   1   4\n716 716    3    2    3    3 10.739886   0   4\n717 717    3    2    3    3  9.666964  NA   4\n718 718    3    2    2    2        NA   0   4\n719 719    4    3    2    2  9.963483   1   4\n720 720    3    3    3    3 12.146356   0   4\n721 721    4   NA    1    1        NA   1   4\n722 722    1    1    4    4 12.437140   0   4\n723 723    3    3    2    2  9.361663   0   4\n724 724    3    2    2    2        NA   1   4\n725 725    4    3    2    2 10.954406   0   4\n726 726    2    3    3    3  8.813882   1   4\n727 727    2    2    3    3  8.399134   1   4\n728 728    2    3    3    3        NA   0   4\n729 729    3   NA    2    2 10.716499   1   4\n730 730    2    2    3    3        NA   0   4\n731 731    2   NA    3    3  9.827114   0   4\n732 732    3    3    2    2 10.646740   1   4\n733 733    2    4    2    1 10.350377   0   4\n734 734    3    3    2    2 10.019486   1   4\n735 735    3    2    2    2  9.739026   1   4\n736 736    2    3    3    4  8.826410   0   4\n737 737    2    2    3    3  8.191695   1   4\n738 738    2    2    3    3  9.700108   0   4\n739 739    2    2    3    3  8.267847   0   4\n740 740    3    4    2    2  8.238960   1   4\n741 741    3    4    2    3  8.657699   1   4\n742 742    2    2    3    3 12.724873   1   4\n743 743    1    1    3    3  9.056560   1   4\n744 744    2    1    3    3 10.776392   1   4\n745 745    3    2    2    3 11.332372   0   4\n746 746    3    3    2    2  9.605044   0   4\n747 747    3    3    2    2 12.553403   0   4\n748 748    3    3    3    2  8.607291   1   4\n749 749    2    2    4    3        NA   0   4\n750 750    3    3    3    2 12.253184   1   4\n\n\n\n\n\n\n\n\n\n\n\nExercise: Remove duplicates!\n\n\n\n\n\nRemove all duplicates contained in exampleDat_ID.RDS and assign the dataFrame to an object named exDat_uniqueID.\n\n\n\n\n\n\nTip\n\n\n\n\n\nAssigning a dataFrame df to an object exDat_uniqueID:\nexDat_uniqueID &lt;- df"
  },
  {
    "objectID": "data-cleaning.html#examining-missing-data",
    "href": "data-cleaning.html#examining-missing-data",
    "title": "\n4  Data cleaning\n",
    "section": "\n4.2 Examining missing data",
    "text": "4.2 Examining missing data\nEspecially with questionnaires and surveys, it often happens that values are missing because, for example, a field of the questionnaire was not filled in. Therefore, it is important to look at the data and get an overview of missing values. By missing values, we refer to cells that could have a value, but whose value is not available (see Data Types.\nProcedure:\n\n\nCheck for missing values\n\n\nDefine missing values\n\nExclude missing values\n\n\n4.2.1 Check for missing values\nFor this part of the data cleaning process, the dplyr package offers no particular advantages over R Base.\nThe summary() function that gives an overview of the quartils, the mean and the amount of NAs of each variable of the given dataFrame.\n\nShow/hide codesummary(exDat)\n\n      msc1            msc2            msc3            msc4     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.00  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.00  \n Median :3.000   Median :3.000   Median :2.000   Median :2.00  \n Mean   :2.519   Mean   :2.544   Mean   :2.488   Mean   :2.48  \n 3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:3.00  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :4.00  \n                 NA's   :70                                    \n      age              sex              edu       \n Min.   : 5.440   Min.   :0.0000   Min.   :0.000  \n 1st Qu.: 9.052   1st Qu.:0.0000   1st Qu.:2.000  \n Median :10.030   Median :0.0000   Median :3.000  \n Mean   :10.009   Mean   :0.4979   Mean   :2.667  \n 3rd Qu.:11.018   3rd Qu.:1.0000   3rd Qu.:4.000  \n Max.   :14.840   Max.   :1.0000   Max.   :4.000  \n NA's   :80       NA's   :39                      \n\n\nWhen considering a single variable, the sum of cells with missing values can be calculated using the function sum().\n\nShow/hide codesum(is.na(exDat$msc2))\n\n[1] 70\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\n\n\nYou can apply this function to all variables of the data set:\n\nShow/hide codesapply(exDat, function(x) sum(is.na(x)))\n\nmsc1 msc2 msc3 msc4  age  sex  edu \n   0   70    0    0   80   39    0 \n\n\n\n\n\n\n4.2.2 Define missing values\nEspecially when working with SPSS generated data or character variables, missing values may not be encoded as NAs, but for example as empty characters (i.e. \"\" or \" \") or as numerics like -99 or -88. If you notice that a variable contains missing values that are not defined as NA, you should recode the corresponding values.\n\n\nBase R\ndplyr package\n\n\n\n\nShow/hide codeexDat[exDat == -99] &lt;- NA\n\n\n\n\ndplyr::na_if() can be used to convert a specific value contained in a variable to NA.\n\nShow/hide codeexDat$age &lt;- dplyr::na_if(exDat$age, -99)\n\n\n\n\n\n\n4.2.3 Exclude missing values\n\n\nBase R\ndplyr package\n\n\n\nBy negating the is.na() function, those rows that do not contain NAs on a variable are kept.\n\nShow/hide codeexDat[which(!is.na(exDat$age)), ]\n\n\nna.omit() returns only those rows in a dataFrame which do not contain any NAs.\n\nShow/hide codena.omit(exDat)\n\n    msc1 msc2 msc3 msc4       age sex edu\n1      2    3    2    2  9.815538   0   0\n2      3    2    1    1  8.980194   1   0\n3      2    2    3    3 12.758157   0   0\n4      2    2    3    2 10.578846   0   0\n5      3    2    2    2  9.894364   1   0\n6      3    3    3    2 10.446850   0   0\n7      4    4    1    2 10.897605   1   0\n8      3    3    2    1  7.977382   1   0\n10     3    3    2    2  9.105864   0   0\n11     2    1    3    3  8.540117   0   0\n12     2    2    3    3 11.841954   0   0\n13     2    2    3    4 11.647655   0   0\n14     2    3    3    3 11.745306   0   0\n15     2    3    3    3  9.970630   0   0\n17     2    2    2    2  7.773473   1   0\n19     2    2    3    3  9.339448   0   0\n21     4    3    2    2  9.831947   0   0\n22     2    3    3    3  9.890266   1   0\n23     2    3    2    2 11.501609   0   0\n25     3    3    2    2 11.540030   1   0\n26     2    3    3    3 10.098491   1   0\n27     4    3    2    2 10.851320   1   0\n28     3    2    2    2  6.735228   1   0\n29     3    4    2    2 10.690059   1   0\n30     3    2    2    3  9.746659   1   0\n31     2    1    4    4  8.983450   0   0\n33     2    2    3    2  8.057455   1   0\n34     2    2    3    3 10.134752   0   0\n35     2    3    3    2  8.096160   0   0\n37     3    3    3    3 12.156118   0   0\n38     2    2    3    2  9.600157   0   0\n39     2    3    3    3 11.591400   0   0\n40     3    4    2    2 10.691193   1   0\n41     3    3    3    2 12.622380   0   0\n42     3    2    2    2 10.043774   1   0\n43     4    3    2    2  8.452508   0   0\n44     4    3    2    2 12.029754   1   0\n45     3    2    3    3  8.213722   1   0\n46     2    3    2    3 11.654911   0   0\n47     4    3    1    1  9.086209   1   0\n49     2    3    3    3  9.617718   0   0\n50     2    3    2    2 10.347768   1   0\n51     2    1    3    3 10.735626   0   1\n52     3    3    3    2 10.903281   1   1\n54     2    3    4    3 10.824752   0   1\n55     3    3    3    3  9.282584   0   1\n57     2    3    3    3  8.747505   1   1\n58     2    2    3    4  8.992998   1   1\n59     2    2    3    3 12.632563   1   1\n60     2    2    3    3 11.015445   1   1\n61     3    3    2    2  9.529734   1   1\n62     4    3    1    1 11.569437   1   1\n63     4    3    2    2 11.626011   1   1\n65     2    2    2    3  8.712209   1   1\n66     1    2    3    2 12.271368   0   1\n67     3    3    2    2 11.514336   1   1\n69     2    2    2    2 10.858827   1   1\n70     2    2    3    4 11.416986   0   1\n72     2    3    3    3  9.417725   1   1\n73     4    3    1    2 10.788379   1   1\n74     2    3    2    2  7.527881   1   1\n75     2    2    3    3  7.697320   0   1\n76     3    4    3    2  9.723288   1   1\n78     3    3    3    3  9.552697   1   1\n79     3    3    3    3 10.766935   1   1\n81     2    3    2    2 10.027268   0   1\n82     4    3    2    2 11.108152   1   1\n83     3    3    2    2  9.364853   1   1\n85     4    3    1    1  8.791437   0   1\n86     2    2    3    3 14.699514   1   1\n87     1    2    4    3  9.310963   0   1\n89     3    4    1    2  9.164070   0   1\n90     3    2    3    2  9.904690   0   1\n91     1    2    3    3  9.949049   0   1\n92     1    2    3    2 10.874213   0   1\n93     2    3    3    3  9.589440   0   1\n94     2    2    3    3  8.396720   0   1\n95     1    2    3    3  8.633062   1   1\n96     3    4    2    2 10.174559   1   1\n98     4    3    2    2  6.022669   1   1\n99     3    3    2    2 10.701638   1   1\n101    2    3    3    3 11.536565   0   1\n103    2    2    3    3  7.082311   1   1\n104    3    3    2    3  7.990254   1   1\n105    2    2    3    3 13.223930   1   1\n106    2    3    2    3  8.847114   0   1\n109    2    2    3    2  8.917741   1   1\n110    2    2    3    4  9.059646   0   1\n115    2    2    3    3  8.336241   0   1\n116    3    3    2    2 12.158201   1   1\n118    2    2    4    3 11.067872   1   1\n120    3    2    3    2  9.562434   0   1\n121    3    3    3    2  8.977396   0   1\n122    3    2    3    2 10.162202   0   1\n123    3    3    3    2  9.885336   0   1\n124    3    2    3    3 12.560990   1   1\n125    2    2    4    4 11.087431   1   1\n126    3    3    4    3 10.371456   1   1\n127    3    4    1    2  9.319275   1   1\n128    2    2    2    3 11.008828   1   1\n129    1    2    3    2  9.656535   0   1\n130    1    2    3    4 10.032404   0   1\n131    2    2    3    3  6.974716   1   1\n132    3    2    2    3  9.168019   1   1\n133    2    1    3    4 10.658201   1   1\n134    3    2    2    2 10.723573   1   1\n135    1    2    4    3  9.564175   1   1\n136    2    3    3    2  9.440463   1   1\n137    1    2    3    4  8.574188   1   1\n138    2    2    3    3  8.336412   0   1\n139    3    2    2    2 11.316498   0   1\n140    4    3    2    2 10.089194   1   1\n141    3    3    2    2 11.326115   0   1\n142    2    3    2    2 10.544879   1   1\n143    4    3    2    2  8.278763   0   1\n144    3    3    2    2  9.165442   0   1\n145    3    4    2    2 14.840083   0   1\n146    4    4    1    1  9.177470   0   1\n147    2    3    1    1 10.392509   1   1\n148    3    3    2    3 10.074265   1   1\n151    2    2    3    3 11.303224   0   2\n152    3    3    2    2  8.301101   0   2\n153    3    4    2    2 11.552966   1   2\n154    3    3    2    2 10.420355   1   2\n155    3    4    2    2 12.648300   1   2\n156    2    2    3    2  9.985757   1   2\n157    2    3    2    2 10.504636   0   2\n159    2    2    3    3  9.576623   0   2\n160    3    3    2    2 12.855773   1   2\n161    2    1    3    4 10.131071   0   2\n162    2    3    3    3 11.018442   1   2\n163    3    3    2    2 10.910317   1   2\n165    3    2    3    3 10.402108   1   2\n166    2    2    3    2 11.020302   0   2\n167    2    2    3    3 10.862003   1   2\n171    3    3    2    1 11.156488   1   2\n172    1    2    3    3 11.774043   0   2\n173    3    2    3    2  9.014673   0   2\n174    4    4    1    1  9.755259   1   2\n175    3    3    3    3  7.710862   0   2\n176    1    1    4    4 11.418964   1   2\n177    1    2    4    3 10.702477   0   2\n178    3    2    3    2 11.237905   1   2\n179    3    1    2    2  9.225546   0   2\n180    3    3    2    2  9.673228   0   2\n181    2    3    2    2  9.358897   0   2\n182    3    2    3    3  9.252146   1   2\n183    2    2    3    3  8.616693   0   2\n184    3    4    2    2 10.721936   0   2\n185    3    3    2    2 11.054393   0   2\n186    1    1    4    4  8.094315   1   2\n187    3    3    1    2  9.231779   0   2\n188    3    3    2    2  8.547865   1   2\n189    3    3    3    3 10.345779   0   2\n191    2    2    3    4 10.411992   0   2\n192    3    3    2    3  8.971620   1   2\n193    1    2    4    4 10.898386   0   2\n194    2    2    3    3 10.625394   1   2\n195    2    2    3    4  6.357136   0   2\n196    1    2    3    3 12.102026   1   2\n198    2    3    3    3  6.586317   1   2\n199    3    3    3    2  9.050529   1   2\n200    2    2    3    3 12.723541   1   2\n202    2    2    2    2 13.303115   1   2\n204    3    3    2    2 11.445677   0   2\n205    2    2    2    2  9.306572   0   2\n206    3    1    3    3  8.328087   0   2\n207    3    4    1    2 10.359319   0   2\n209    2    2    3    2  9.748836   1   2\n210    2    2    3    3 11.357677   0   2\n211    3    3    2    2  9.790493   1   2\n212    3    3    3    3  8.325024   0   2\n213    2    2    2    2  9.281008   1   2\n214    3    2    2    2 13.164568   0   2\n215    2    2    2    2  7.828867   0   2\n216    3    3    3    3 10.665805   0   2\n217    2    1    3    3 10.635206   1   2\n219    2    2    2    3  8.923574   0   2\n223    3    3    3    2 10.397873   1   2\n224    4    3    2    2 10.241358   1   2\n225    3    3    2    1  9.874614   1   2\n226    2    3    2    2  9.251216   0   2\n227    3    2    2    2 11.927287   0   2\n228    4    4    2    2 10.327432   0   2\n229    3    2    3    2  6.475004   0   2\n230    2    3    3    3 11.338842   0   2\n232    3    3    2    2  7.933710   0   2\n233    2    3    3    3 10.721250   1   2\n234    3    2    3    3  8.086553   0   2\n237    2    2    2    3 11.260712   0   2\n240    2    3    2    3  9.606693   1   2\n241    2    2    2    2  9.965807   1   2\n243    2    2    2    2 11.588374   1   2\n244    2    1    3    3 12.054486   0   2\n245    2    1    3    2  8.551229   1   2\n246    1    1    4    4 14.758472   1   2\n247    3    3    2    1 10.601619   1   2\n248    2    3    2    3  9.608768   1   2\n249    2    2    3    4 10.631563   0   2\n250    3    4    1    1  9.195155   0   2\n251    3    2    3    3 12.153778   1   2\n252    2    1    4    4 11.594112   1   2\n253    3    3    2    2 12.749052   0   2\n254    2    1    3    3 10.904641   1   2\n256    3    3    1    1  9.382583   1   2\n257    2    2    4    3 10.075463   1   2\n260    3    3    2    2 10.003249   0   2\n261    2    2    3    3 10.357645   0   2\n262    1    2    3    3 11.427154   0   2\n263    1    2    4    3 11.141758   1   2\n264    2    2    3    3 11.717822   0   2\n265    3    3    2    1  8.591719   1   2\n266    4    3    2    2  7.199316   1   2\n270    3    2    1    1  9.901684   1   2\n271    2    2    2    3 11.543191   1   2\n272    3    2    3    2  9.905296   0   2\n273    3    3    2    2 10.804370   0   2\n274    3    3    1    1  9.135004   1   2\n277    4    4    2    2 10.110370   1   2\n278    2    3    3    3  8.910521   1   2\n279    3    3    2    2 11.335096   0   2\n280    2    3    3    3 10.872968   1   2\n281    3    3    2    2  9.550622   0   2\n284    2    2    2    2  9.628909   0   2\n285    2    2    3    3 13.948810   0   2\n287    3    2    2    2  9.487855   1   2\n288    3    3    3    2 10.250928   0   2\n289    3    2    3    3 10.038493   0   2\n291    3    3    2    3 11.294503   1   2\n292    2    2    3    3 12.974758   0   2\n293    3    3    2    2 10.285506   0   2\n294    3    2    3    3 10.156128   1   2\n295    3    4    3    3 10.477511   0   2\n296    2    2    3    4 11.463436   0   2\n297    2    3    2    2 10.958489   0   2\n298    3    2    2    2  8.164545   0   2\n299    2    3    3    3 10.140617   0   2\n302    2    3    2    3  9.384978   1   3\n303    2    2    3    3  7.993749   1   3\n304    2    3    3    3  6.955896   1   3\n305    4    3    2    2 10.535078   0   3\n308    4    4    1    1 10.504347   1   3\n309    2    3    2    2  9.939982   0   3\n310    3    3    3    3 10.389400   1   3\n311    2    2    3    3  9.448678   1   3\n312    2    4    1    2 10.221263   1   3\n314    3    3    2    1 11.177018   1   3\n315    2    2    3    2  9.339305   0   3\n316    3    2    2    2  6.542470   1   3\n317    4    3    1    2  8.953333   1   3\n319    2    1    3    3  7.581036   0   3\n321    3    2    3    3 10.881096   1   3\n322    2    2    4    3  9.503126   1   3\n323    3    3    2    2 10.542913   1   3\n324    2    1    4    3  7.226064   1   3\n326    3    3    1    2 10.473550   1   3\n328    3    3    2    2 10.490264   0   3\n329    3    3    2    1 11.740022   1   3\n330    3    3    2    2 11.473238   0   3\n333    3    3    2    2  7.619042   0   3\n334    3    2    2    2  9.525225   1   3\n335    3    2    2    2  9.301695   1   3\n336    1    1    4    4 10.235494   1   3\n338    3    2    3    3 10.078303   0   3\n340    2    3    2    2  9.613427   0   3\n341    2    3    2    2 10.440469   1   3\n343    2    2    3    3  9.632019   0   3\n346    3    3    2    3 10.358045   0   3\n347    3    3    2    3  9.452587   0   3\n348    2    2    3    3 10.616298   0   3\n349    2    2    3    4 10.531881   1   3\n350    3    2    3    3 10.917065   0   3\n351    3    4    2    2  6.753558   1   3\n352    3    3    1    1  9.081102   1   3\n353    2    2    3    3  9.324282   0   3\n354    3    4    2    2  9.556236   1   3\n355    3    3    2    3  8.404846   1   3\n356    3    3    2    2  9.835171   1   3\n358    3    3    2    2  9.347660   1   3\n360    3    3    2    2  8.146446   0   3\n361    3    3    1    2  7.774709   1   3\n362    3    3    2    2  6.083013   1   3\n363    2    3    3    3  8.618334   1   3\n366    2    3    3    3 11.498595   0   3\n368    3    4    2    2 11.885905   0   3\n369    2    1    3    3 10.151313   0   3\n370    2    3    2    3  8.703436   1   3\n371    1    2    3    4 11.715882   1   3\n373    2    2    3    2  9.260014   0   3\n374    2    1    4    4 12.764876   0   3\n375    2    3    3    3 11.855908   0   3\n376    2    2    3    3 11.346669   1   3\n377    2    3    3    2 10.437059   0   3\n380    3    2    2    3 11.449698   0   3\n383    3    3    2    1 10.240093   1   3\n384    3    3    3    3 12.629684   0   3\n385    3    3    2    2 10.858224   0   3\n388    3    3    2    2  8.881271   1   3\n390    3    3    3    3 10.192251   0   3\n391    3    3    1    2 11.065900   0   3\n392    3    3    2    2 10.998406   1   3\n393    2    2    3    2  8.552346   1   3\n394    4    3    1    2  9.412805   0   3\n398    3    2    3    3  9.242431   1   3\n400    3    3    3    3 10.084902   1   3\n401    3    2    2    2 10.097882   0   3\n402    3    3    1    1 11.672478   0   3\n403    3    4    2    1 13.353267   0   3\n404    1    2    4    4 10.107733   0   3\n405    2    3    3    3 10.847647   0   3\n406    3    3    1    1  8.989002   1   3\n407    4    3    2    2  9.767775   0   3\n408    3    3    3    2  8.104969   1   3\n409    3    3    2    2 11.940227   0   3\n410    2    1    4    3  8.396467   1   3\n412    2    2    2    3  9.927729   1   3\n413    3    3    2    2  9.120070   0   3\n414    3    2    2    2  9.359507   1   3\n415    3    2    3    3  7.340234   0   3\n416    3    3    2    2  8.565667   1   3\n417    3    2    2    3 11.829203   1   3\n418    2    2    2    2  9.444976   1   3\n419    1    1    4    4  8.163760   1   3\n420    1    2    2    3  7.971904   0   3\n422    2    2    3    2 10.435981   1   3\n423    1    2    3    3 11.167197   0   3\n424    4    3    2    2  9.076633   0   3\n425    3    3    2    2  9.734855   0   3\n426    3    3    1    1  9.520808   0   3\n427    2    2    2    2  8.750194   0   3\n428    2    2    3    3 10.203757   1   3\n429    3    3    2    2  8.855370   0   3\n430    3    2    3    2 13.023492   1   3\n433    2    2    3    4  8.328651   1   3\n434    3    2    3    2  9.358613   0   3\n435    4    3    2    2 11.184436   0   3\n439    4    4    1    1  9.609236   0   3\n440    2    3    2    2  9.303808   0   3\n441    3    3    2    2 10.739005   0   3\n443    2    3    3    3 10.028578   1   3\n444    4    4    2    2 10.703093   1   3\n446    3    2    3    3 10.775893   1   3\n447    2    2    3    3 10.714497   0   3\n448    3    2    2    2  9.476227   0   3\n451    3    3    2    2  9.860913   0   3\n452    3    4    1    2  9.406198   1   3\n453    3    3    2    2  7.358570   0   3\n454    3    4    2    2  9.143064   1   3\n455    3    4    2    2 11.833885   0   3\n456    2    2    4    3 10.510292   1   3\n457    4    3    2    2 11.219608   1   3\n458    2    2    3    3 13.257474   0   3\n459    2    2    3    4  7.569693   0   3\n460    2    2    4    3 11.684286   1   3\n462    2    2    3    3  9.203611   1   3\n463    2    2    3    3 11.462454   1   3\n464    3    2    3    3  8.608740   1   3\n465    3    3    3    2  8.550825   0   3\n468    3    3    2    2  9.638242   0   3\n469    4    3    2    2 11.559736   0   3\n470    2    3    2    2  9.289579   1   3\n471    2    2    4    3 10.660731   0   3\n472    1    2    4    4  8.653708   1   3\n475    2    2    2    2 10.394297   0   3\n477    2    1    3    3 11.588138   1   3\n478    3    2    3    3  9.701818   1   3\n479    2    2    3    3 10.131820   0   3\n480    3    2    2    3 11.851048   0   3\n481    2    2    3    3  8.094906   0   3\n482    2    3    2    3  6.522122   0   3\n484    3    2    2    2  7.171610   1   3\n485    4    3    1    2 10.449040   1   3\n486    3    3    2    2  8.565564   1   3\n487    2    3    2    3  9.692163   0   3\n488    2    3    3    2 10.544790   0   3\n489    1    1    4    4  9.152848   1   3\n492    3    4    2    2 12.157326   1   3\n493    2    2    4    3  8.071642   1   3\n496    2    2    2    2  9.657121   1   3\n497    2    2    3    3  8.421820   1   3\n498    2    2    3    2 11.234864   0   3\n499    3    3    3    2 11.684493   1   3\n501    3    2    3    3  9.518572   0   4\n503    3    2    2    2  9.394796   1   4\n504    3    2    2    2 10.871842   0   4\n505    3    3    1    1 11.807168   1   4\n507    2    3    3    3 11.295793   0   4\n508    3    2    3    3  9.704389   1   4\n509    3    3    2    1 12.982000   1   4\n510    3    2    2    3  8.051677   0   4\n511    2    3    3    3 10.134297   1   4\n512    2    3    2    2 10.915921   0   4\n514    3    2    3    3  9.377179   1   4\n516    2    2    3    3  9.799799   0   4\n517    2    2    3    3  9.352013   0   4\n518    3    2    3    3  7.578805   0   4\n519    2    3    3    2  8.955748   0   4\n520    3    3    1    2  7.345759   1   4\n521    2    3    3    2  9.038828   0   4\n522    3    2    3    3  6.462564   0   4\n523    3    3    2    2  8.710578   0   4\n524    2    2    3    3  8.078165   1   4\n525    3    3    3    3  9.308461   0   4\n526    2    3    3    2  9.621561   0   4\n527    2    3    2    2 10.468559   1   4\n528    2    2    4    3 12.527006   0   4\n529    1    1    4    4  9.713401   0   4\n530    2    3    2    3 12.449355   1   4\n531    4    3    1    2 10.171527   1   4\n532    2    2    4    3 11.592511   1   4\n533    2    2    3    3  9.746639   0   4\n534    2    2    2    3 11.539024   0   4\n535    3    4    1    1 12.662389   1   4\n536    3    3    2    2  8.558018   1   4\n537    3    4    1    2 12.490442   0   4\n538    3    4    2    2  8.849825   1   4\n540    2    2    2    3  9.856794   1   4\n542    2    3    2    3 10.455994   0   4\n543    3    3    1    2  8.953355   0   4\n544    3    3    2    2 10.233466   1   4\n546    3    3    2    1 11.511366   0   4\n547    3    3    2    2  7.030045   0   4\n548    2    1    4    4 11.833564   0   4\n550    2    3    2    2 10.669845   1   4\n551    3    3    3    2 11.945497   0   4\n552    3    3    1    1  7.631776   0   4\n553    2    2    3    3  7.929047   0   4\n554    2    3    2    2 10.655136   1   4\n555    4    4    1    1 11.651111   1   4\n556    3    3    2    2  9.499631   0   4\n557    2    3    2    3  9.869376   1   4\n558    3    3    1    2 10.573739   0   4\n559    2    2    3    4  6.777733   0   4\n560    3    3    2    1 10.292540   0   4\n561    3    2    3    2  8.420615   0   4\n565    3    3    2    2  9.567283   1   4\n566    3    2    2    2  9.700664   1   4\n567    2    2    4    3  9.035493   1   4\n568    2    2    3    3  6.920118   0   4\n571    4    4    1    1 11.561428   0   4\n572    3    2    2    2 10.479614   1   4\n573    3    2    2    3 12.062231   0   4\n574    3    3    3    2 11.258923   1   4\n575    2    2    3    3  8.535113   1   4\n577    3    3    2    2  9.513192   0   4\n581    1    2    3    3  7.840196   1   4\n583    2    3    3    3 11.716523   1   4\n584    2    2    3    3 10.115714   0   4\n585    2    1    2    3 10.487666   1   4\n586    3    3    2    2 10.129045   1   4\n587    4    3    2    2 10.213173   0   4\n588    1    1    3    3 12.114688   1   4\n589    2    2    3    3 11.655211   0   4\n590    1    2    4    4 10.474828   1   4\n591    2    3    3    2  9.222274   0   4\n592    3    3    3    3 10.053230   0   4\n595    3    3    3    2 10.611019   0   4\n598    2    3    3    3 12.403272   0   4\n600    4    3    1    1 12.933026   0   4\n602    3    2    3    3  9.797451   0   4\n604    2    3    3    3  5.697734   1   4\n605    4    3    3    2 11.315240   0   4\n606    3    3    2    2  9.398728   0   4\n608    3    4    2    1  7.712797   0   4\n609    4    3    2    2 11.397924   1   4\n612    2    1    4    3  8.434417   1   4\n613    2    2    3    3  9.741397   1   4\n616    3    3    2    2  8.498451   0   4\n617    1    2    3    3 10.447842   0   4\n618    3    3    3    3  6.916193   0   4\n619    3    2    3    3  7.967729   0   4\n620    2    2    3    3 10.971877   0   4\n621    1    2    3    3 10.036674   1   4\n622    4    4    1    2 11.171656   0   4\n623    2    2    3    3  9.809559   1   4\n624    3    2    2    2  8.970928   0   4\n625    2    2    4    4 10.715082   0   4\n626    3    3    3    2  7.928970   1   4\n627    2    3    3    3  6.909529   1   4\n628    2    3    3    2 10.799244   0   4\n630    2    2    2    1 12.505498   0   4\n631    4    4    1    1  9.779263   1   4\n632    3    3    2    3  9.474470   0   4\n633    2    2    3    3 12.139497   0   4\n634    3    3    3    2 11.067315   0   4\n635    3    4    2    3  8.320202   0   4\n636    3    2    2    2  7.182648   1   4\n637    2    2    4    4 10.130177   0   4\n638    3    3    3    3 12.496180   0   4\n639    2    2    3    3 12.592766   0   4\n640    2    2    2    3  9.907003   0   4\n641    3    2    3    3 11.737818   1   4\n642    3    2    2    1  8.821091   0   4\n643    2    3    3    2  6.860783   0   4\n644    3    2    3    3 10.268927   1   4\n645    3    3    2    2 10.266885   1   4\n646    3    3    2    2  5.763412   0   4\n647    3    2    2    2  7.066767   1   4\n648    3    3    3    2  9.180560   0   4\n649    3    3    2    2 12.972046   1   4\n651    3    3    2    2 11.411023   1   4\n652    2    2    2    3 10.049973   0   4\n653    2    2    3    2 11.337266   0   4\n654    3    3    3    3 13.679508   0   4\n655    2    3    3    3  8.168574   1   4\n657    2    3    3    3  9.269406   0   4\n659    3    3    2    2  8.932260   1   4\n660    3    3    1    2  7.922082   0   4\n661    2    2    3    3 11.825439   0   4\n663    2    1    3    3 13.418967   0   4\n664    3    2    3    3 12.795091   0   4\n665    2    3    3    3  9.076854   0   4\n666    2    2    2    2  9.791845   1   4\n667    2    3    2    2  7.201118   0   4\n669    3    3    3    3 11.357964   1   4\n670    3    3    2    2 10.881354   0   4\n671    2    1    3    3 10.379563   0   4\n674    3    3    3    2  8.146615   1   4\n675    2    3    2    2  9.175585   0   4\n676    2    2    4    4 12.131668   1   4\n678    1    2    3    3 11.473233   1   4\n679    3    3    2    3  9.506655   1   4\n680    2    3    2    2 10.030170   0   4\n682    1    1    3    4 10.668823   0   4\n683    2    3    3    3  9.386863   1   4\n684    2    2    3    3  7.093356   1   4\n685    2    2    3    3 12.640182   1   4\n686    1    2    3    3  8.807493   1   4\n687    3    3    3    3 14.291764   0   4\n689    3    3    2    3  5.439760   0   4\n691    2    2    3    3  8.718412   1   4\n692    3    3    2    2  8.041810   1   4\n694    3    2    3    3 10.982985   1   4\n695    1    2    2    3 10.007353   0   4\n696    3    2    2    2  8.467930   0   4\n698    2    2    3    3 10.826550   1   4\n699    3    2    2    2  9.543067   1   4\n700    3    3    1    2 10.025428   1   4\n701    2    3    3    3 10.668717   1   4\n702    3    3    3    3 10.518729   1   4\n703    3    3    2    2 10.808743   1   4\n704    2    2    2    2  7.725368   1   4\n705    3    3    2    3 10.498354   1   4\n707    3    4    2    2 11.808316   1   4\n708    2    2    4    4  9.354355   0   4\n709    1    1    4    4  6.893923   0   4\n710    2    3    2    3 10.715373   1   4\n712    2    3    2    3 10.579138   1   4\n713    3    2    3    3  7.743470   1   4\n715    3    3    1    2 11.443266   1   4\n716    3    2    3    3 10.739886   0   4\n719    4    3    2    2  9.963483   1   4\n720    3    3    3    3 12.146356   0   4\n722    1    1    4    4 12.437140   0   4\n723    3    3    2    2  9.361663   0   4\n725    4    3    2    2 10.954406   0   4\n726    2    3    3    3  8.813882   1   4\n727    2    2    3    3  8.399134   1   4\n732    3    3    2    2 10.646740   1   4\n733    2    4    2    1 10.350377   0   4\n734    3    3    2    2 10.019486   1   4\n735    3    2    2    2  9.739026   1   4\n736    2    3    3    4  8.826410   0   4\n737    2    2    3    3  8.191695   1   4\n738    2    2    3    3  9.700108   0   4\n739    2    2    3    3  8.267847   0   4\n740    3    4    2    2  8.238960   1   4\n741    3    4    2    3  8.657699   1   4\n742    2    2    3    3 12.724873   1   4\n743    1    1    3    3  9.056560   1   4\n744    2    1    3    3 10.776392   1   4\n745    3    2    2    3 11.332372   0   4\n746    3    3    2    2  9.605044   0   4\n747    3    3    2    2 12.553403   0   4\n748    3    3    3    2  8.607291   1   4\n750    3    3    3    2 12.253184   1   4\n\n\n\n\nLike in [Identify duplicates], exclusion of missings can be done using dplyr::filter(). The following code filters all cases that do not have a missing value in all variables.\n\nShow/hide codeexDat |&gt; \n  dplyr::filter(if_all(everything(),\n                       ~ !is.na(.x)))\n\n    msc1 msc2 msc3 msc4       age sex edu\n1      2    3    2    2  9.815538   0   0\n2      3    2    1    1  8.980194   1   0\n3      2    2    3    3 12.758157   0   0\n4      2    2    3    2 10.578846   0   0\n5      3    2    2    2  9.894364   1   0\n6      3    3    3    2 10.446850   0   0\n7      4    4    1    2 10.897605   1   0\n8      3    3    2    1  7.977382   1   0\n9      3    3    2    2  9.105864   0   0\n10     2    1    3    3  8.540117   0   0\n11     2    2    3    3 11.841954   0   0\n12     2    2    3    4 11.647655   0   0\n13     2    3    3    3 11.745306   0   0\n14     2    3    3    3  9.970630   0   0\n15     2    2    2    2  7.773473   1   0\n16     2    2    3    3  9.339448   0   0\n17     4    3    2    2  9.831947   0   0\n18     2    3    3    3  9.890266   1   0\n19     2    3    2    2 11.501609   0   0\n20     3    3    2    2 11.540030   1   0\n21     2    3    3    3 10.098491   1   0\n22     4    3    2    2 10.851320   1   0\n23     3    2    2    2  6.735228   1   0\n24     3    4    2    2 10.690059   1   0\n25     3    2    2    3  9.746659   1   0\n26     2    1    4    4  8.983450   0   0\n27     2    2    3    2  8.057455   1   0\n28     2    2    3    3 10.134752   0   0\n29     2    3    3    2  8.096160   0   0\n30     3    3    3    3 12.156118   0   0\n31     2    2    3    2  9.600157   0   0\n32     2    3    3    3 11.591400   0   0\n33     3    4    2    2 10.691193   1   0\n34     3    3    3    2 12.622380   0   0\n35     3    2    2    2 10.043774   1   0\n36     4    3    2    2  8.452508   0   0\n37     4    3    2    2 12.029754   1   0\n38     3    2    3    3  8.213722   1   0\n39     2    3    2    3 11.654911   0   0\n40     4    3    1    1  9.086209   1   0\n41     2    3    3    3  9.617718   0   0\n42     2    3    2    2 10.347768   1   0\n43     2    1    3    3 10.735626   0   1\n44     3    3    3    2 10.903281   1   1\n45     2    3    4    3 10.824752   0   1\n46     3    3    3    3  9.282584   0   1\n47     2    3    3    3  8.747505   1   1\n48     2    2    3    4  8.992998   1   1\n49     2    2    3    3 12.632563   1   1\n50     2    2    3    3 11.015445   1   1\n51     3    3    2    2  9.529734   1   1\n52     4    3    1    1 11.569437   1   1\n53     4    3    2    2 11.626011   1   1\n54     2    2    2    3  8.712209   1   1\n55     1    2    3    2 12.271368   0   1\n56     3    3    2    2 11.514336   1   1\n57     2    2    2    2 10.858827   1   1\n58     2    2    3    4 11.416986   0   1\n59     2    3    3    3  9.417725   1   1\n60     4    3    1    2 10.788379   1   1\n61     2    3    2    2  7.527881   1   1\n62     2    2    3    3  7.697320   0   1\n63     3    4    3    2  9.723288   1   1\n64     3    3    3    3  9.552697   1   1\n65     3    3    3    3 10.766935   1   1\n66     2    3    2    2 10.027268   0   1\n67     4    3    2    2 11.108152   1   1\n68     3    3    2    2  9.364853   1   1\n69     4    3    1    1  8.791437   0   1\n70     2    2    3    3 14.699514   1   1\n71     1    2    4    3  9.310963   0   1\n72     3    4    1    2  9.164070   0   1\n73     3    2    3    2  9.904690   0   1\n74     1    2    3    3  9.949049   0   1\n75     1    2    3    2 10.874213   0   1\n76     2    3    3    3  9.589440   0   1\n77     2    2    3    3  8.396720   0   1\n78     1    2    3    3  8.633062   1   1\n79     3    4    2    2 10.174559   1   1\n80     4    3    2    2  6.022669   1   1\n81     3    3    2    2 10.701638   1   1\n82     2    3    3    3 11.536565   0   1\n83     2    2    3    3  7.082311   1   1\n84     3    3    2    3  7.990254   1   1\n85     2    2    3    3 13.223930   1   1\n86     2    3    2    3  8.847114   0   1\n87     2    2    3    2  8.917741   1   1\n88     2    2    3    4  9.059646   0   1\n89     2    2    3    3  8.336241   0   1\n90     3    3    2    2 12.158201   1   1\n91     2    2    4    3 11.067872   1   1\n92     3    2    3    2  9.562434   0   1\n93     3    3    3    2  8.977396   0   1\n94     3    2    3    2 10.162202   0   1\n95     3    3    3    2  9.885336   0   1\n96     3    2    3    3 12.560990   1   1\n97     2    2    4    4 11.087431   1   1\n98     3    3    4    3 10.371456   1   1\n99     3    4    1    2  9.319275   1   1\n100    2    2    2    3 11.008828   1   1\n101    1    2    3    2  9.656535   0   1\n102    1    2    3    4 10.032404   0   1\n103    2    2    3    3  6.974716   1   1\n104    3    2    2    3  9.168019   1   1\n105    2    1    3    4 10.658201   1   1\n106    3    2    2    2 10.723573   1   1\n107    1    2    4    3  9.564175   1   1\n108    2    3    3    2  9.440463   1   1\n109    1    2    3    4  8.574188   1   1\n110    2    2    3    3  8.336412   0   1\n111    3    2    2    2 11.316498   0   1\n112    4    3    2    2 10.089194   1   1\n113    3    3    2    2 11.326115   0   1\n114    2    3    2    2 10.544879   1   1\n115    4    3    2    2  8.278763   0   1\n116    3    3    2    2  9.165442   0   1\n117    3    4    2    2 14.840083   0   1\n118    4    4    1    1  9.177470   0   1\n119    2    3    1    1 10.392509   1   1\n120    3    3    2    3 10.074265   1   1\n121    2    2    3    3 11.303224   0   2\n122    3    3    2    2  8.301101   0   2\n123    3    4    2    2 11.552966   1   2\n124    3    3    2    2 10.420355   1   2\n125    3    4    2    2 12.648300   1   2\n126    2    2    3    2  9.985757   1   2\n127    2    3    2    2 10.504636   0   2\n128    2    2    3    3  9.576623   0   2\n129    3    3    2    2 12.855773   1   2\n130    2    1    3    4 10.131071   0   2\n131    2    3    3    3 11.018442   1   2\n132    3    3    2    2 10.910317   1   2\n133    3    2    3    3 10.402108   1   2\n134    2    2    3    2 11.020302   0   2\n135    2    2    3    3 10.862003   1   2\n136    3    3    2    1 11.156488   1   2\n137    1    2    3    3 11.774043   0   2\n138    3    2    3    2  9.014673   0   2\n139    4    4    1    1  9.755259   1   2\n140    3    3    3    3  7.710862   0   2\n141    1    1    4    4 11.418964   1   2\n142    1    2    4    3 10.702477   0   2\n143    3    2    3    2 11.237905   1   2\n144    3    1    2    2  9.225546   0   2\n145    3    3    2    2  9.673228   0   2\n146    2    3    2    2  9.358897   0   2\n147    3    2    3    3  9.252146   1   2\n148    2    2    3    3  8.616693   0   2\n149    3    4    2    2 10.721936   0   2\n150    3    3    2    2 11.054393   0   2\n151    1    1    4    4  8.094315   1   2\n152    3    3    1    2  9.231779   0   2\n153    3    3    2    2  8.547865   1   2\n154    3    3    3    3 10.345779   0   2\n155    2    2    3    4 10.411992   0   2\n156    3    3    2    3  8.971620   1   2\n157    1    2    4    4 10.898386   0   2\n158    2    2    3    3 10.625394   1   2\n159    2    2    3    4  6.357136   0   2\n160    1    2    3    3 12.102026   1   2\n161    2    3    3    3  6.586317   1   2\n162    3    3    3    2  9.050529   1   2\n163    2    2    3    3 12.723541   1   2\n164    2    2    2    2 13.303115   1   2\n165    3    3    2    2 11.445677   0   2\n166    2    2    2    2  9.306572   0   2\n167    3    1    3    3  8.328087   0   2\n168    3    4    1    2 10.359319   0   2\n169    2    2    3    2  9.748836   1   2\n170    2    2    3    3 11.357677   0   2\n171    3    3    2    2  9.790493   1   2\n172    3    3    3    3  8.325024   0   2\n173    2    2    2    2  9.281008   1   2\n174    3    2    2    2 13.164568   0   2\n175    2    2    2    2  7.828867   0   2\n176    3    3    3    3 10.665805   0   2\n177    2    1    3    3 10.635206   1   2\n178    2    2    2    3  8.923574   0   2\n179    3    3    3    2 10.397873   1   2\n180    4    3    2    2 10.241358   1   2\n181    3    3    2    1  9.874614   1   2\n182    2    3    2    2  9.251216   0   2\n183    3    2    2    2 11.927287   0   2\n184    4    4    2    2 10.327432   0   2\n185    3    2    3    2  6.475004   0   2\n186    2    3    3    3 11.338842   0   2\n187    3    3    2    2  7.933710   0   2\n188    2    3    3    3 10.721250   1   2\n189    3    2    3    3  8.086553   0   2\n190    2    2    2    3 11.260712   0   2\n191    2    3    2    3  9.606693   1   2\n192    2    2    2    2  9.965807   1   2\n193    2    2    2    2 11.588374   1   2\n194    2    1    3    3 12.054486   0   2\n195    2    1    3    2  8.551229   1   2\n196    1    1    4    4 14.758472   1   2\n197    3    3    2    1 10.601619   1   2\n198    2    3    2    3  9.608768   1   2\n199    2    2    3    4 10.631563   0   2\n200    3    4    1    1  9.195155   0   2\n201    3    2    3    3 12.153778   1   2\n202    2    1    4    4 11.594112   1   2\n203    3    3    2    2 12.749052   0   2\n204    2    1    3    3 10.904641   1   2\n205    3    3    1    1  9.382583   1   2\n206    2    2    4    3 10.075463   1   2\n207    3    3    2    2 10.003249   0   2\n208    2    2    3    3 10.357645   0   2\n209    1    2    3    3 11.427154   0   2\n210    1    2    4    3 11.141758   1   2\n211    2    2    3    3 11.717822   0   2\n212    3    3    2    1  8.591719   1   2\n213    4    3    2    2  7.199316   1   2\n214    3    2    1    1  9.901684   1   2\n215    2    2    2    3 11.543191   1   2\n216    3    2    3    2  9.905296   0   2\n217    3    3    2    2 10.804370   0   2\n218    3    3    1    1  9.135004   1   2\n219    4    4    2    2 10.110370   1   2\n220    2    3    3    3  8.910521   1   2\n221    3    3    2    2 11.335096   0   2\n222    2    3    3    3 10.872968   1   2\n223    3    3    2    2  9.550622   0   2\n224    2    2    2    2  9.628909   0   2\n225    2    2    3    3 13.948810   0   2\n226    3    2    2    2  9.487855   1   2\n227    3    3    3    2 10.250928   0   2\n228    3    2    3    3 10.038493   0   2\n229    3    3    2    3 11.294503   1   2\n230    2    2    3    3 12.974758   0   2\n231    3    3    2    2 10.285506   0   2\n232    3    2    3    3 10.156128   1   2\n233    3    4    3    3 10.477511   0   2\n234    2    2    3    4 11.463436   0   2\n235    2    3    2    2 10.958489   0   2\n236    3    2    2    2  8.164545   0   2\n237    2    3    3    3 10.140617   0   2\n238    2    3    2    3  9.384978   1   3\n239    2    2    3    3  7.993749   1   3\n240    2    3    3    3  6.955896   1   3\n241    4    3    2    2 10.535078   0   3\n242    4    4    1    1 10.504347   1   3\n243    2    3    2    2  9.939982   0   3\n244    3    3    3    3 10.389400   1   3\n245    2    2    3    3  9.448678   1   3\n246    2    4    1    2 10.221263   1   3\n247    3    3    2    1 11.177018   1   3\n248    2    2    3    2  9.339305   0   3\n249    3    2    2    2  6.542470   1   3\n250    4    3    1    2  8.953333   1   3\n251    2    1    3    3  7.581036   0   3\n252    3    2    3    3 10.881096   1   3\n253    2    2    4    3  9.503126   1   3\n254    3    3    2    2 10.542913   1   3\n255    2    1    4    3  7.226064   1   3\n256    3    3    1    2 10.473550   1   3\n257    3    3    2    2 10.490264   0   3\n258    3    3    2    1 11.740022   1   3\n259    3    3    2    2 11.473238   0   3\n260    3    3    2    2  7.619042   0   3\n261    3    2    2    2  9.525225   1   3\n262    3    2    2    2  9.301695   1   3\n263    1    1    4    4 10.235494   1   3\n264    3    2    3    3 10.078303   0   3\n265    2    3    2    2  9.613427   0   3\n266    2    3    2    2 10.440469   1   3\n267    2    2    3    3  9.632019   0   3\n268    3    3    2    3 10.358045   0   3\n269    3    3    2    3  9.452587   0   3\n270    2    2    3    3 10.616298   0   3\n271    2    2    3    4 10.531881   1   3\n272    3    2    3    3 10.917065   0   3\n273    3    4    2    2  6.753558   1   3\n274    3    3    1    1  9.081102   1   3\n275    2    2    3    3  9.324282   0   3\n276    3    4    2    2  9.556236   1   3\n277    3    3    2    3  8.404846   1   3\n278    3    3    2    2  9.835171   1   3\n279    3    3    2    2  9.347660   1   3\n280    3    3    2    2  8.146446   0   3\n281    3    3    1    2  7.774709   1   3\n282    3    3    2    2  6.083013   1   3\n283    2    3    3    3  8.618334   1   3\n284    2    3    3    3 11.498595   0   3\n285    3    4    2    2 11.885905   0   3\n286    2    1    3    3 10.151313   0   3\n287    2    3    2    3  8.703436   1   3\n288    1    2    3    4 11.715882   1   3\n289    2    2    3    2  9.260014   0   3\n290    2    1    4    4 12.764876   0   3\n291    2    3    3    3 11.855908   0   3\n292    2    2    3    3 11.346669   1   3\n293    2    3    3    2 10.437059   0   3\n294    3    2    2    3 11.449698   0   3\n295    3    3    2    1 10.240093   1   3\n296    3    3    3    3 12.629684   0   3\n297    3    3    2    2 10.858224   0   3\n298    3    3    2    2  8.881271   1   3\n299    3    3    3    3 10.192251   0   3\n300    3    3    1    2 11.065900   0   3\n301    3    3    2    2 10.998406   1   3\n302    2    2    3    2  8.552346   1   3\n303    4    3    1    2  9.412805   0   3\n304    3    2    3    3  9.242431   1   3\n305    3    3    3    3 10.084902   1   3\n306    3    2    2    2 10.097882   0   3\n307    3    3    1    1 11.672478   0   3\n308    3    4    2    1 13.353267   0   3\n309    1    2    4    4 10.107733   0   3\n310    2    3    3    3 10.847647   0   3\n311    3    3    1    1  8.989002   1   3\n312    4    3    2    2  9.767775   0   3\n313    3    3    3    2  8.104969   1   3\n314    3    3    2    2 11.940227   0   3\n315    2    1    4    3  8.396467   1   3\n316    2    2    2    3  9.927729   1   3\n317    3    3    2    2  9.120070   0   3\n318    3    2    2    2  9.359507   1   3\n319    3    2    3    3  7.340234   0   3\n320    3    3    2    2  8.565667   1   3\n321    3    2    2    3 11.829203   1   3\n322    2    2    2    2  9.444976   1   3\n323    1    1    4    4  8.163760   1   3\n324    1    2    2    3  7.971904   0   3\n325    2    2    3    2 10.435981   1   3\n326    1    2    3    3 11.167197   0   3\n327    4    3    2    2  9.076633   0   3\n328    3    3    2    2  9.734855   0   3\n329    3    3    1    1  9.520808   0   3\n330    2    2    2    2  8.750194   0   3\n331    2    2    3    3 10.203757   1   3\n332    3    3    2    2  8.855370   0   3\n333    3    2    3    2 13.023492   1   3\n334    2    2    3    4  8.328651   1   3\n335    3    2    3    2  9.358613   0   3\n336    4    3    2    2 11.184436   0   3\n337    4    4    1    1  9.609236   0   3\n338    2    3    2    2  9.303808   0   3\n339    3    3    2    2 10.739005   0   3\n340    2    3    3    3 10.028578   1   3\n341    4    4    2    2 10.703093   1   3\n342    3    2    3    3 10.775893   1   3\n343    2    2    3    3 10.714497   0   3\n344    3    2    2    2  9.476227   0   3\n345    3    3    2    2  9.860913   0   3\n346    3    4    1    2  9.406198   1   3\n347    3    3    2    2  7.358570   0   3\n348    3    4    2    2  9.143064   1   3\n349    3    4    2    2 11.833885   0   3\n350    2    2    4    3 10.510292   1   3\n351    4    3    2    2 11.219608   1   3\n352    2    2    3    3 13.257474   0   3\n353    2    2    3    4  7.569693   0   3\n354    2    2    4    3 11.684286   1   3\n355    2    2    3    3  9.203611   1   3\n356    2    2    3    3 11.462454   1   3\n357    3    2    3    3  8.608740   1   3\n358    3    3    3    2  8.550825   0   3\n359    3    3    2    2  9.638242   0   3\n360    4    3    2    2 11.559736   0   3\n361    2    3    2    2  9.289579   1   3\n362    2    2    4    3 10.660731   0   3\n363    1    2    4    4  8.653708   1   3\n364    2    2    2    2 10.394297   0   3\n365    2    1    3    3 11.588138   1   3\n366    3    2    3    3  9.701818   1   3\n367    2    2    3    3 10.131820   0   3\n368    3    2    2    3 11.851048   0   3\n369    2    2    3    3  8.094906   0   3\n370    2    3    2    3  6.522122   0   3\n371    3    2    2    2  7.171610   1   3\n372    4    3    1    2 10.449040   1   3\n373    3    3    2    2  8.565564   1   3\n374    2    3    2    3  9.692163   0   3\n375    2    3    3    2 10.544790   0   3\n376    1    1    4    4  9.152848   1   3\n377    3    4    2    2 12.157326   1   3\n378    2    2    4    3  8.071642   1   3\n379    2    2    2    2  9.657121   1   3\n380    2    2    3    3  8.421820   1   3\n381    2    2    3    2 11.234864   0   3\n382    3    3    3    2 11.684493   1   3\n383    3    2    3    3  9.518572   0   4\n384    3    2    2    2  9.394796   1   4\n385    3    2    2    2 10.871842   0   4\n386    3    3    1    1 11.807168   1   4\n387    2    3    3    3 11.295793   0   4\n388    3    2    3    3  9.704389   1   4\n389    3    3    2    1 12.982000   1   4\n390    3    2    2    3  8.051677   0   4\n391    2    3    3    3 10.134297   1   4\n392    2    3    2    2 10.915921   0   4\n393    3    2    3    3  9.377179   1   4\n394    2    2    3    3  9.799799   0   4\n395    2    2    3    3  9.352013   0   4\n396    3    2    3    3  7.578805   0   4\n397    2    3    3    2  8.955748   0   4\n398    3    3    1    2  7.345759   1   4\n399    2    3    3    2  9.038828   0   4\n400    3    2    3    3  6.462564   0   4\n401    3    3    2    2  8.710578   0   4\n402    2    2    3    3  8.078165   1   4\n403    3    3    3    3  9.308461   0   4\n404    2    3    3    2  9.621561   0   4\n405    2    3    2    2 10.468559   1   4\n406    2    2    4    3 12.527006   0   4\n407    1    1    4    4  9.713401   0   4\n408    2    3    2    3 12.449355   1   4\n409    4    3    1    2 10.171527   1   4\n410    2    2    4    3 11.592511   1   4\n411    2    2    3    3  9.746639   0   4\n412    2    2    2    3 11.539024   0   4\n413    3    4    1    1 12.662389   1   4\n414    3    3    2    2  8.558018   1   4\n415    3    4    1    2 12.490442   0   4\n416    3    4    2    2  8.849825   1   4\n417    2    2    2    3  9.856794   1   4\n418    2    3    2    3 10.455994   0   4\n419    3    3    1    2  8.953355   0   4\n420    3    3    2    2 10.233466   1   4\n421    3    3    2    1 11.511366   0   4\n422    3    3    2    2  7.030045   0   4\n423    2    1    4    4 11.833564   0   4\n424    2    3    2    2 10.669845   1   4\n425    3    3    3    2 11.945497   0   4\n426    3    3    1    1  7.631776   0   4\n427    2    2    3    3  7.929047   0   4\n428    2    3    2    2 10.655136   1   4\n429    4    4    1    1 11.651111   1   4\n430    3    3    2    2  9.499631   0   4\n431    2    3    2    3  9.869376   1   4\n432    3    3    1    2 10.573739   0   4\n433    2    2    3    4  6.777733   0   4\n434    3    3    2    1 10.292540   0   4\n435    3    2    3    2  8.420615   0   4\n436    3    3    2    2  9.567283   1   4\n437    3    2    2    2  9.700664   1   4\n438    2    2    4    3  9.035493   1   4\n439    2    2    3    3  6.920118   0   4\n440    4    4    1    1 11.561428   0   4\n441    3    2    2    2 10.479614   1   4\n442    3    2    2    3 12.062231   0   4\n443    3    3    3    2 11.258923   1   4\n444    2    2    3    3  8.535113   1   4\n445    3    3    2    2  9.513192   0   4\n446    1    2    3    3  7.840196   1   4\n447    2    3    3    3 11.716523   1   4\n448    2    2    3    3 10.115714   0   4\n449    2    1    2    3 10.487666   1   4\n450    3    3    2    2 10.129045   1   4\n451    4    3    2    2 10.213173   0   4\n452    1    1    3    3 12.114688   1   4\n453    2    2    3    3 11.655211   0   4\n454    1    2    4    4 10.474828   1   4\n455    2    3    3    2  9.222274   0   4\n456    3    3    3    3 10.053230   0   4\n457    3    3    3    2 10.611019   0   4\n458    2    3    3    3 12.403272   0   4\n459    4    3    1    1 12.933026   0   4\n460    3    2    3    3  9.797451   0   4\n461    2    3    3    3  5.697734   1   4\n462    4    3    3    2 11.315240   0   4\n463    3    3    2    2  9.398728   0   4\n464    3    4    2    1  7.712797   0   4\n465    4    3    2    2 11.397924   1   4\n466    2    1    4    3  8.434417   1   4\n467    2    2    3    3  9.741397   1   4\n468    3    3    2    2  8.498451   0   4\n469    1    2    3    3 10.447842   0   4\n470    3    3    3    3  6.916193   0   4\n471    3    2    3    3  7.967729   0   4\n472    2    2    3    3 10.971877   0   4\n473    1    2    3    3 10.036674   1   4\n474    4    4    1    2 11.171656   0   4\n475    2    2    3    3  9.809559   1   4\n476    3    2    2    2  8.970928   0   4\n477    2    2    4    4 10.715082   0   4\n478    3    3    3    2  7.928970   1   4\n479    2    3    3    3  6.909529   1   4\n480    2    3    3    2 10.799244   0   4\n481    2    2    2    1 12.505498   0   4\n482    4    4    1    1  9.779263   1   4\n483    3    3    2    3  9.474470   0   4\n484    2    2    3    3 12.139497   0   4\n485    3    3    3    2 11.067315   0   4\n486    3    4    2    3  8.320202   0   4\n487    3    2    2    2  7.182648   1   4\n488    2    2    4    4 10.130177   0   4\n489    3    3    3    3 12.496180   0   4\n490    2    2    3    3 12.592766   0   4\n491    2    2    2    3  9.907003   0   4\n492    3    2    3    3 11.737818   1   4\n493    3    2    2    1  8.821091   0   4\n494    2    3    3    2  6.860783   0   4\n495    3    2    3    3 10.268927   1   4\n496    3    3    2    2 10.266885   1   4\n497    3    3    2    2  5.763412   0   4\n498    3    2    2    2  7.066767   1   4\n499    3    3    3    2  9.180560   0   4\n500    3    3    2    2 12.972046   1   4\n501    3    3    2    2 11.411023   1   4\n502    2    2    2    3 10.049973   0   4\n503    2    2    3    2 11.337266   0   4\n504    3    3    3    3 13.679508   0   4\n505    2    3    3    3  8.168574   1   4\n506    2    3    3    3  9.269406   0   4\n507    3    3    2    2  8.932260   1   4\n508    3    3    1    2  7.922082   0   4\n509    2    2    3    3 11.825439   0   4\n510    2    1    3    3 13.418967   0   4\n511    3    2    3    3 12.795091   0   4\n512    2    3    3    3  9.076854   0   4\n513    2    2    2    2  9.791845   1   4\n514    2    3    2    2  7.201118   0   4\n515    3    3    3    3 11.357964   1   4\n516    3    3    2    2 10.881354   0   4\n517    2    1    3    3 10.379563   0   4\n518    3    3    3    2  8.146615   1   4\n519    2    3    2    2  9.175585   0   4\n520    2    2    4    4 12.131668   1   4\n521    1    2    3    3 11.473233   1   4\n522    3    3    2    3  9.506655   1   4\n523    2    3    2    2 10.030170   0   4\n524    1    1    3    4 10.668823   0   4\n525    2    3    3    3  9.386863   1   4\n526    2    2    3    3  7.093356   1   4\n527    2    2    3    3 12.640182   1   4\n528    1    2    3    3  8.807493   1   4\n529    3    3    3    3 14.291764   0   4\n530    3    3    2    3  5.439760   0   4\n531    2    2    3    3  8.718412   1   4\n532    3    3    2    2  8.041810   1   4\n533    3    2    3    3 10.982985   1   4\n534    1    2    2    3 10.007353   0   4\n535    3    2    2    2  8.467930   0   4\n536    2    2    3    3 10.826550   1   4\n537    3    2    2    2  9.543067   1   4\n538    3    3    1    2 10.025428   1   4\n539    2    3    3    3 10.668717   1   4\n540    3    3    3    3 10.518729   1   4\n541    3    3    2    2 10.808743   1   4\n542    2    2    2    2  7.725368   1   4\n543    3    3    2    3 10.498354   1   4\n544    3    4    2    2 11.808316   1   4\n545    2    2    4    4  9.354355   0   4\n546    1    1    4    4  6.893923   0   4\n547    2    3    2    3 10.715373   1   4\n548    2    3    2    3 10.579138   1   4\n549    3    2    3    3  7.743470   1   4\n550    3    3    1    2 11.443266   1   4\n551    3    2    3    3 10.739886   0   4\n552    4    3    2    2  9.963483   1   4\n553    3    3    3    3 12.146356   0   4\n554    1    1    4    4 12.437140   0   4\n555    3    3    2    2  9.361663   0   4\n556    4    3    2    2 10.954406   0   4\n557    2    3    3    3  8.813882   1   4\n558    2    2    3    3  8.399134   1   4\n559    3    3    2    2 10.646740   1   4\n560    2    4    2    1 10.350377   0   4\n561    3    3    2    2 10.019486   1   4\n562    3    2    2    2  9.739026   1   4\n563    2    3    3    4  8.826410   0   4\n564    2    2    3    3  8.191695   1   4\n565    2    2    3    3  9.700108   0   4\n566    2    2    3    3  8.267847   0   4\n567    3    4    2    2  8.238960   1   4\n568    3    4    2    3  8.657699   1   4\n569    2    2    3    3 12.724873   1   4\n570    1    1    3    3  9.056560   1   4\n571    2    1    3    3 10.776392   1   4\n572    3    2    2    3 11.332372   0   4\n573    3    3    2    2  9.605044   0   4\n574    3    3    2    2 12.553403   0   4\n575    3    3    3    2  8.607291   1   4\n576    3    3    3    2 12.253184   1   4\n\n\n\n\n\n\n\n\n\n\n\nExercise: Remove missing values!\n\n\n\n\n\nDefine -99 as NA across all columns and remove all rows including missing values from dataFrame exampleDat.RDS and assign the dataFrame to an object exDat_noNA."
  },
  {
    "objectID": "data-cleaning.html#plausibility-checks",
    "href": "data-cleaning.html#plausibility-checks",
    "title": "\n4  Data cleaning\n",
    "section": "\n4.3 Plausibility checks",
    "text": "4.3 Plausibility checks\nPlausibility checks can be performed analytically or graphically.\nPurpose: Detecting\n\nstructural errors (e.g. in coding and input)\n\ntheoretical inconsistencies\n\nvariables with high proportions of missing values\n\noutliers\n\n\n\n\n\n\n\nExcursus: Outliers\n\n\n\n\n\nDefinition: +/- 2 or 3 standard deviations\n\n“Extreme observation value that signals a qualitative element that differs from the totality.”\n\n– Rönz & Strohe, 1994\n\n\nOutliers must be detected, as they can introduce bias into parameter estimates and compromise validity.\nDifferent ways of handling outliers:\n\nBox plots and histograms\n\nUnivariate distributions\n\nExamine extreme values\n\nExamine distributions of subgroups\n\nMultivariate scatterplots\n\nRecommended procedure for handling outliers:\n(personal preference)\n\nExamine extreme values\n\nz-standardize variables\\[z = \\frac{x_{m} - \\bar{x}}{s_{x}} \\tag{4.1}\\]\n\nexamine for values above -/+ 2 or -/+ 3 standard deviations\n\n\n\nCoded these extreme values to 1 in a dummy variable\n\n\n1 = outlier, 0 = no outlier\n\n\n\n\n\n\n\n4.3.1 Discrete variables\n(= countable)\n\nAfter assigning the value labels and after coding the missing values\n\nThen check if non-coded numerical values exist\n\nProcedure:\n\n\nFrequency tables\n\n\nBar charts\n\nRange of items\n\nFrequency tables\nR provides a function table() “to build a contingency table of the counts at each combination of factor levels” (R Core Team 2023). By default, NAs are not included in the table. This can be changed by the argument useNA. It accepts a string as input with the accepted values \"ifany\" (only if the count is positive) and \"always\" (even for zero counts.\n\nShow/hide codetable(exDat$edu, useNA = \"always\")\n\n\n   0    1    2    3    4 &lt;NA&gt; \n  50  100  150  200  250    0 \n\n\nThis function can be embedded in another function proportions() which creates a relative frequency table. As the R Documentation on proportions() notes, “prop.table() is an earlier name, retained for back-compatibility.”\nProportions are often numerics with many decimal places. Therefore, it may be useful to round the values to four decimal places or to convert them to percentages with two decimal places.\n\nShow/hide coderound(proportions(table(exDat$edu)), 4)\n\n\n     0      1      2      3      4 \n0.0667 0.1333 0.2000 0.2667 0.3333 \n\nShow/hide coderound(proportions(table(exDat$edu)) * 100, 2)\n\n\n    0     1     2     3     4 \n 6.67 13.33 20.00 26.67 33.33 \n\n\nBar charts\nBar charts are one way of graphically checking the plausibility of discrete variables. Plots can be created with Base R (R Core Team 2023), as shown below. However, there are also packages like ggplot2 (Wickham, Chang, et al. 2023) that are specifically designed for data visualization. See the tidyverse documentation of ggplot2-package for more details.\n\nShow/hide codebarplot(table(exDat$edu, useNA = \"always\"),\n        names.arg = c(0:4, \"NA\"),\n        main = \"Education in example data set\", # plot title\n        xlab = \"exDat$edu\", # x-axis label\n        ylab = \"Count\",  # y-axis label\n        ylim = c(0, 300) # y-axis range\n        )\n\n\n\nFigure 4.1: Frequencies of the education expression in the example data set\n\n\n\n\nRange of items\n\n\nAnalytical\nGraphical\n\n\n\nTo explicitly find out the range of a variable, the function range() can be used. By default, the function includes NAs. Use the argument na.rm to specify whether missings should be excluded.\n\nShow/hide coderange(exDat$edu, na.rm = T)\n\n[1] 0 4\n\n\nThis function can be applied to all numeric variables and generates a matrix.\n\nShow/hide codesapply(exDat,\n       function(x) if (is.numeric(x)) range(x, na.rm = T))\n\n\n\nShow/hide codeexDat_ranges &lt;- data.frame(\n  sapply(exDat,\n         function(x) if (is.numeric(x)) range(x, na.rm = T)),\n  row.names = c(\"min\", \"max\")\n)\n\nknitr::kable(exDat_ranges,\n             row.names = T) |&gt; \n  kableExtra::kable_classic(\"hover\")\n\n\nRanges of all numeric variables in example data set {#tbl-range-of-items-all-ranges}\n\n\nmsc1\nmsc2\nmsc3\nmsc4\nage\nsex\nedu\n\n\n\nmin\n1\n1\n1\n1\n5.43976\n0\n0\n\n\nmax\n4\n4\n4\n4\n14.84008\n1\n4\n\n\n\n\n\n\n\nBoxplots allow visualization of the most important robust measures of location and dispersion.\n\n\nDifferent parts of a boxplot (Galarnyk, 2019)\n\n\n\nShow/hide codeboxplot(exDat[, -5],\n        main = \"Ranges of all discrete variables in example data set\", # plot title\n        xlab = \"Variables\", # x-axis label\n        ylab = \"Range\" # y-axis label\n        )\n\n\n\nFigure 4.2: Ranges of all discrete variables in example data set\n\n\n\n\n\n\n\n\n4.3.2 Metric variables\n(= infinite number of real values within a given interval)\n\nCode missing values first!\n\nAfterwards: Consideration of the observed range of values\n\nQuestion: Are there any unplausible values? (e.g. age = -9)\n\n\n\nProcedure:\n\n\nDescriptive statistics\n\nHistogram\n\nDescriptive statistics\nThe package psych (Revelle 2023) provides useful functions for descriptive statistical analyses.\n\n\nBase R\npsych package\n\n\n\nThe summary() function, introduced in chapter 4.2.1, provides an overview of descriptive statistics.\n\nShow/hide codesummary(exDat$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  5.440   9.052  10.030  10.009  11.018  14.840      80 \n\n\n\n\nThe function psych::describe() contains additional descriptive statistics to those of the Base R function (e.g. number of valid cases, skewness, kurtosis, standard error).\n\nShow/hide codepsych::describe(exDat$age)\n\n   vars   n  mean   sd median trimmed  mad  min   max range  skew kurtosis   se\nX1    1 670 10.01 1.58  10.03   10.02 1.46 5.44 14.84   9.4 -0.06     0.07 0.06\n\n\n\n\n\nHistogram\nHistograms are graphical representations of frequency distributions of metric variables. Just like bar charts, these visualizations can be modified more using packages like ggplot2 (Wickham, Chang, et al. 2023).\n\nShow/hide codehist(exDat$age,\n     main = \"Age in example data set\",\n     breaks = 20,\n     xlim = c(min(round(exDat$age), na.rm = T) - 1,\n              max(round(exDat$age), na.rm = T) + 1),\n     ylim = c(0, 100))\n\n\n\nFigure 4.3: Frequency distribution of age in example data set\n\n\n\n\n\n\n\n\n\n\nPlot probability density\n\n\n\n\n\n\nShow/hide code# histogram with probability density\nhist(exDat$age,\n     main = \"Age in example data set\",\n     probability = T)\n# draw mean\nabline(v = mean(exDat$age, na.rm = T),\n       col = \"red\",\n       lwd = 3)\n# draw probability density line\nlines(density(exDat$age, na.rm = T),\n      col = \"green\",\n      lwd = 3)\n\n\n\nFigure 4.4: Probability density of age in example data set"
  },
  {
    "objectID": "data-cleaning.html#recoding-variables",
    "href": "data-cleaning.html#recoding-variables",
    "title": "\n4  Data cleaning\n",
    "section": "\n5.1 Recoding variables",
    "text": "5.1 Recoding variables\nWhen recoding variables, new values are assigned to the old values (e.g. reversed polarity items).\nThe old values can either be overwritten by the new values or saved as a new variable.\n\n\n\n\n\n\nWe always create a new variable when recoding!\n\n\n\n\n\n\nold values are not lost\n\nerrors during recoding can be reproduced\n\n\n\n\nProcedure:\n\nTransform\n\nRecode in new variable"
  },
  {
    "objectID": "data-cleaning.html#auto-recoding",
    "href": "data-cleaning.html#auto-recoding",
    "title": "\n4  Data cleaning\n",
    "section": "\n5.2 Auto-recoding",
    "text": "5.2 Auto-recoding"
  },
  {
    "objectID": "data-cleaning.html#building-new-variables",
    "href": "data-cleaning.html#building-new-variables",
    "title": "\n4  Data cleaning\n",
    "section": "\n5.3 Building new variables",
    "text": "5.3 Building new variables\n\n\n\n\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRevelle, William. 2023. Psych: Procedures for Psychological, Psychometric, and Personality Research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "item-analy-descr.html#descriptive-statistics",
    "href": "item-analy-descr.html#descriptive-statistics",
    "title": "5  Descriptive statistics and item analysis",
    "section": "\n5.1 Descriptive statistics",
    "text": "5.1 Descriptive statistics\nTypical descriptive statistics are:\n\nmean\nstandard deviation\nminimum and maximum\nabsolute and relative frequencies\n\nR provides functions to calculate the statistics: mean, sd, min, max, table, …\nIn addition, there are packages such as the psych package (Revelle 2023) that offer additional functionality.\n\n\nBase R\npsych package\n\n\n\nFor example, if we want to calculate the mean and the standard deviation of the variable age, we can use the respective functions (i.e., mean & sd):\n\n\n\nShow/hide codemean(exDat$age, na.rm = T)\n\n[1] 10.00921\n\n\n\n\n\n\nShow/hide codesd(exDat$age, na.rm = T)\n\n[1] 1.581207\n\n\n\n\nOr, if you are interested in absolute and/or relative frequencies, we can use the table function:\n\n\n\nShow/hide codetable(exDat$sex)\n\n\n  0   1 \n357 354 \n\n\n\n\n\n\nShow/hide codetable(exDat$sex,\n      useNA = \"always\")/length(exDat$sex)*100\n\n\n   0    1 &lt;NA&gt; \n47.6 47.2  5.2 \n\n\n\n\nHowever, often you need to calculate the descriptive statistics not only for a single variable, but for many variables. Again, in R this can be done in many different ways. Here we depict a base R solution using the apply function.\nThe apply function needs the following arguments (copied from the function description):\n\n\nX: an array, including a matrix.\n\nMARGIN: a vector giving the subscripts which the function will be applied over. E.g., for a matrix 1 indicates rows, 2 indicates columns, c(1, 2) indicates rows and columns. Where X has named dimnames, it can be a character vector selecting dimension names.\n\nFUN: the function to be applied: see ‘Details’.\n\nIn order to better retrace the calculation procedure, we present it in a two-step1 approach:\n\n\nTwo-step approach\nOne-step approach\n\n\n\n\nUsing the apply function and save the output in an object (here: exDescr):\n\nInput X is the example data set: exDat\n\nSet MARGIN value to 2, because we want to apply the function over columns of exDat\n\n\nFUN: Here we define a function2 that calculates the mean, standard deviation, minimum and maximum (combined through the c function). Within the braces { you can state several (consecutive) arguments. Finally, we return the object (fOut) of the function. Note the fOut object is not saved in the workspace.\n\n\n\n\nShow/hide codeexDescr &lt;- apply(X = exDat,\n                 MARGIN = 2,\n                 FUN = function(x) {\n                   fOut &lt;- c(\n                     mean(x, na.rm = T),\n                     sd(x, na.rm = T),\n                     min(x, na.rm = T),\n                     max(x, na.rm = T)\n                     )\n                   return(fOut)\n                   })\n\n\n\nIn the second step, we first transpose (t function) the returned matrix, transform it then to a data.frame3 object and provide the column names.\n\n\nShow/hide codeexDescr &lt;- as.data.frame(\n  t(exDescr)\n  )\ncolnames(exDescr) &lt;- c(\"Mean\", \"SD\", \"Min\", \"Max\")\nexDescr\n\n            Mean        SD     Min      Max\nmsc1   2.5186667 0.7373668 1.00000  4.00000\nmsc2   2.5441176 0.7186516 1.00000  4.00000\nmsc3   2.4880000 0.7482887 1.00000  4.00000\nmsc4   2.4800000 0.7463306 1.00000  4.00000\nage   10.0092114 1.5812066 5.43976 14.84008\nsex    0.4978903 0.5003475 0.00000  1.00000\nedu    2.6666667 1.2480514 0.00000  4.00000\nmsc3r  2.5120000 0.7482887 1.00000  4.00000\nmsc4r  2.5200000 0.7463306 1.00000  4.00000\nmsc    2.5275735 0.6106209 1.00000  4.00000\n\n\n(3. Finally, if you need an formatted table, the kbl function from the kableExtra package (Zhu 2021) transforms matrices or data frames into nice tables.)\n\nShow/hide codekableExtra::kbl(exDescr,\n                digits = 2,\n                caption = \"Descriptive Statistics of the example data set\") |&gt;\n  kableExtra::kable_classic() |&gt;\n  kableExtra::footnote(general = \"This is a nice formatted table using the kableExtra package [@R-kableExtra].\")\n\n\nDescriptive Statistics of the example data set\n\n\nMean\nSD\nMin\nMax\n\n\n\nmsc1\n2.52\n0.74\n1.00\n4.00\n\n\nmsc2\n2.54\n0.72\n1.00\n4.00\n\n\nmsc3\n2.49\n0.75\n1.00\n4.00\n\n\nmsc4\n2.48\n0.75\n1.00\n4.00\n\n\nage\n10.01\n1.58\n5.44\n14.84\n\n\nsex\n0.50\n0.50\n0.00\n1.00\n\n\nedu\n2.67\n1.25\n0.00\n4.00\n\n\nmsc3r\n2.51\n0.75\n1.00\n4.00\n\n\nmsc4r\n2.52\n0.75\n1.00\n4.00\n\n\nmsc\n2.53\n0.61\n1.00\n4.00\n\n\n\n\nNote: \n\n\n\n\n\n\n\n This is a nice formatted table using the kableExtra package [@R-kableExtra].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAlthough it is probably a matter of coding taste, we do not recommend such a approach. We like it neat.\n\n\n\nShow/hide codekableExtra::kbl(x = t(\n  apply(exDat,\n        MARGIN = 2,\n        FUN = function(x) {\n          fOut &lt;- c(\n            mean(x, na.rm = T),\n            sd(x, na.rm = T),\n            min(x, na.rm = T),\n            max(x, na.rm = T)\n            )\n          return(fOut)\n          })\n  ),\n  digits = 2,\n  col.names = c(\"Mean\", \"SD\", \"Min\", \"Max\"),\n  caption = \"Descriptive Statistics of the example data set\") |&gt;\n  kableExtra::kable_classic() |&gt;\n  kableExtra::footnote(general = \"This is a nice formated table using the kableExtra package [@R-kableExtra].\")\n\n\nDescriptive Statistics of the example data set\n\n\nMean\nSD\nMin\nMax\n\n\n\nmsc1\n2.52\n0.74\n1.00\n4.00\n\n\nmsc2\n2.54\n0.72\n1.00\n4.00\n\n\nmsc3\n2.49\n0.75\n1.00\n4.00\n\n\nmsc4\n2.48\n0.75\n1.00\n4.00\n\n\nage\n10.01\n1.58\n5.44\n14.84\n\n\nsex\n0.50\n0.50\n0.00\n1.00\n\n\nedu\n2.67\n1.25\n0.00\n4.00\n\n\nmsc3r\n2.51\n0.75\n1.00\n4.00\n\n\nmsc4r\n2.52\n0.75\n1.00\n4.00\n\n\nmsc\n2.53\n0.61\n1.00\n4.00\n\n\n\n\nNote: \n\n\n\n\n\n\n\n This is a nice formated table using the kableExtra package [@R-kableExtra].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the function description (see ?psych::describe):\n\nThe describe function in the psych package is meant to produce the most frequently requested stats in psychometric and psychology studies, and to produce them in an easy to read data.frame. If a grouping variable is called for in formula mode, it will also call describeBy to the processing.\n\nThe function has many input argument (see again ?psych::describe), but requires only x: A data frame or matrix\n\nShow/hide codepsych::describe(x = exDat)\n\n      vars   n  mean   sd median trimmed  mad  min   max range  skew kurtosis\nmsc1     1 750  2.52 0.74   3.00    2.52 1.48 1.00  4.00   3.0 -0.02    -0.31\nmsc2     2 680  2.54 0.72   3.00    2.53 1.48 1.00  4.00   3.0 -0.02    -0.27\nmsc3     3 750  2.49 0.75   2.00    2.49 1.48 1.00  4.00   3.0  0.00    -0.34\nmsc4     4 750  2.48 0.75   2.00    2.48 1.48 1.00  4.00   3.0  0.06    -0.33\nage      5 670 10.01 1.58  10.03   10.02 1.46 5.44 14.84   9.4 -0.06     0.07\nsex      6 711  0.50 0.50   0.00    0.50 0.00 0.00  1.00   1.0  0.01    -2.00\nedu      7 750  2.67 1.25   3.00    2.79 1.48 0.00  4.00   4.0 -0.59    -0.73\nmsc3r    8 750  2.51 0.75   3.00    2.51 1.48 1.00  4.00   3.0  0.00    -0.34\nmsc4r    9 750  2.52 0.75   3.00    2.52 1.48 1.00  4.00   3.0 -0.06    -0.33\nmsc     10 680  2.53 0.61   2.50    2.53 0.74 1.00  4.00   3.0 -0.07    -0.35\n        se\nmsc1  0.03\nmsc2  0.03\nmsc3  0.03\nmsc4  0.03\nage   0.06\nsex   0.02\nedu   0.05\nmsc3r 0.03\nmsc4r 0.03\nmsc   0.02\n\n\nThe describe output is easily transformed into a data.frame which then can be passed to the kbl function from the kableExtra package (Zhu 2021).\n\nShow/hide codekableExtra::kbl(x = as.data.frame(psych::describe(x = exDat))[c(\"n\", \"mean\", \"sd\")],\n                caption = \"Descriptive Statistics of the example data set calculated by the psych package [@R-psych]\",\n                digits = 2) |&gt;\n  kableExtra::kable_paper()\n\n\nDescriptive Statistics of the example data set calculated by the psych package [@R-psych]\n\n\nn\nmean\nsd\n\n\n\nmsc1\n750\n2.52\n0.74\n\n\nmsc2\n680\n2.54\n0.72\n\n\nmsc3\n750\n2.49\n0.75\n\n\nmsc4\n750\n2.48\n0.75\n\n\nage\n670\n10.01\n1.58\n\n\nsex\n711\n0.50\n0.50\n\n\nedu\n750\n2.67\n1.25\n\n\nmsc3r\n750\n2.51\n0.75\n\n\nmsc4r\n750\n2.52\n0.75\n\n\nmsc\n680\n2.53\n0.61\n\n\n\n\n\nIf you need to calculate the descriptive statistics separate for groups, there is the describeBy function. Use the group argument.\n\nShow/hide codepsych::describeBy(x = exDat, group =\"sex\")\n\n\n Descriptive statistics by group \nsex: 0\n      vars   n  mean   sd median trimmed  mad  min   max range  skew kurtosis\nmsc1     1 357  2.48 0.72   2.00    2.48 1.48 1.00  4.00   3.0  0.01    -0.28\nmsc2     2 323  2.53 0.71   3.00    2.54 1.48 1.00  4.00   3.0 -0.10    -0.25\nmsc3     3 357  2.52 0.71   3.00    2.53 1.48 1.00  4.00   3.0 -0.10    -0.26\nmsc4     4 357  2.50 0.73   2.00    2.47 1.48 1.00  4.00   3.0  0.18    -0.30\nage      5 320 10.08 1.62  10.07   10.11 1.51 5.44 14.84   9.4 -0.14     0.00\nsex      6 357  0.00 0.00   0.00    0.00 0.00 0.00  0.00   0.0   NaN      NaN\nedu      7 357  2.71 1.26   3.00    2.85 1.48 0.00  4.00   4.0 -0.65    -0.67\nmsc3r    8 357  2.48 0.71   2.00    2.47 1.48 1.00  4.00   3.0  0.10    -0.26\nmsc4r    9 357  2.50 0.73   3.00    2.53 1.48 1.00  4.00   3.0 -0.18    -0.30\nmsc     10 323  2.50 0.59   2.50    2.50 0.74 1.00  4.00   3.0 -0.04    -0.20\n        se\nmsc1  0.04\nmsc2  0.04\nmsc3  0.04\nmsc4  0.04\nage   0.09\nsex   0.00\nedu   0.07\nmsc3r 0.04\nmsc4r 0.04\nmsc   0.03\n------------------------------------------------------------ \nsex: 1\n      vars   n mean   sd median trimmed  mad min   max range  skew kurtosis\nmsc1     1 354 2.55 0.76   3.00    2.54 1.48 1.0  4.00  3.00 -0.06    -0.36\nmsc2     2 321 2.56 0.73   3.00    2.54 1.48 1.0  4.00  3.00 -0.01    -0.31\nmsc3     3 354 2.46 0.79   2.00    2.46 1.48 1.0  4.00  3.00  0.08    -0.43\nmsc4     4 354 2.47 0.76   2.00    2.49 1.48 1.0  4.00  3.00 -0.02    -0.38\nage      5 313 9.94 1.53  10.02    9.94 1.45 5.7 14.76  9.06  0.03     0.16\nsex      6 354 1.00 0.00   1.00    1.00 0.00 1.0  1.00  0.00   NaN      NaN\nedu      7 354 2.62 1.25   3.00    2.73 1.48 0.0  4.00  4.00 -0.51    -0.85\nmsc3r    8 354 2.54 0.79   3.00    2.54 1.48 1.0  4.00  3.00 -0.08    -0.43\nmsc4r    9 354 2.53 0.76   3.00    2.51 1.48 1.0  4.00  3.00  0.02    -0.38\nmsc     10 321 2.55 0.63   2.50    2.57 0.74 1.0  4.00  3.00 -0.13    -0.42\n        se\nmsc1  0.04\nmsc2  0.04\nmsc3  0.04\nmsc4  0.04\nage   0.09\nsex   0.00\nedu   0.07\nmsc3r 0.04\nmsc4r 0.04\nmsc   0.04"
  },
  {
    "objectID": "item-analy-descr.html#cronbachs-alpha-and-item-statistics",
    "href": "item-analy-descr.html#cronbachs-alpha-and-item-statistics",
    "title": "5  Descriptive statistics and item analysis",
    "section": "\n5.2 Cronbachs \\(\\alpha\\) and item statistics",
    "text": "5.2 Cronbachs \\(\\alpha\\) and item statistics\n\nCoefficient \\(\\alpha\\) is often called an internal consistency reliability coefficient, as it is based on covariances among scale items and thus internal consistency among items. But internal consistency should not be conflated with homogeneity, where homogeneity implies that a single dimension underlies the set of items (Widaman and Revelle 2022).\n\n\n\n\n\n\n\nCoefficient \\(\\alpha\\) debate\n\n\n\nSome interesting reads: Cronbach (1951);Revelle and Zinbarg (2009); Sijtsma (2009); McNeish (2017); Savalei and Reise (2019)\n\n\nFollowing again the description and notation of Widaman and Revelle (2022):\nCoefficient alpha, or \\(\\alpha\\) can be written as\n\\[\n\\alpha = (\\frac{p}{p-1})\\left(\\frac{\\sigma_Y^2-\\sum\\limits_{j=1}^p\\sigma_j^2}{\\sigma_Y^2}\\right) = (\\frac{p}{p-1})\\left(1- \\frac{\\sum\\limits_{j=1}^p\\sigma_j^2}{\\sigma_Y^2}\\right)\n\\tag{5.1}\\]\nwhere \\(p\\) is the number of items on the scale, \\(\\sigma_j^2\\) (\\(j=1,...,p\\)) is the variance of item \\(j\\), […]. \\(\\sigma_Y^2\\) is the variance of the sum score.\nNow lets calculate Cronbachs \\(\\alpha\\). We use the variables msc1,msc2,msc3r, & msc4r from the example data set (exDat).\n\n\n\n\n\n\nMissing values and Cronbachs \\(\\alpha\\)\n\n\n\n\n\nThere are many different packages which implemented the calculation of Cronbachs \\(\\alpha\\). For example:\n\nalpha function from the psych package (Revelle 2023)\nitemstats function from the mirt package (Chalmers 2022)\ncronbach function from the psy package (Falissard 2022)\ncronbach.alpha function from the ltm package (Rizopoulos 2022)\n\nInterestingly, these package implemented different approaches (and options) in how they deal with missing values which (may) lead to (slightly) different results.\n\nShow/hide codeexDatmiss &lt;- exDat\n\n# add some more missing data, this adds up when calculating the sum score\n\nexDatmiss$msc3r &lt;- ifelse (\n  rbinom(\n    nrow(exDatmiss),\n    size = 1,\n    .25) == 1,\n  NA,\n  exDatmiss$msc3r\n  )\n\nexDatmiss$msc1 &lt;- ifelse (\n  rbinom(\n    nrow(exDatmiss),\n    size = 1,\n    .15) == 1,\n  NA,\n  exDatmiss$msc1\n  )\n\n\n\nShow/hide codealphaOver &lt;- data.frame(\n  \"alpha\" = rbind(\n    psych::alpha(exDatmiss[,names(mscItems)])$total$raw_alpha,\n    psy::cronbach(exDatmiss[,names(mscItems)])$alpha,\n    mirt::itemstats(exDatmiss[,names(mscItems)])$overall$alpha,\n    ltm::cronbach.alpha(exDatmiss[,names(mscItems)], na.rm = T)$alpha\n    )\n  )\n    \nalphaOver$Package &lt;- c(\"psych\", \"psy\", \"mirt\", \"ltm\")\n\nkableExtra::kbl(alphaOver[,c(\"Package\", \"alpha\")],\n                col.names = c(\"Package\", \"Cronbachs $\\\\alpha$\"),\n                digits = 5,\n                centering = TRUE) |&gt;\n  kableExtra::kable_styling(full_width = FALSE,\n                            bootstrap_options = c(\"hover\", \"responsive\"))\n\n\n\nOverview of different Cronbach \\(\\alpha\\) calculations {#tbl-alpha-over}\n\nPackage\nCronbachs $\\alpha$\n\n\n\npsych\n0.85450\n\n\npsy\n0.85385\n\n\nmirt\n0.85385\n\n\nltm\n0.84913\n\n\n\n\n\n\n\n\n\n\n\n\n\nCronbachs \\(\\alpha\\) and item statistics with base R\nCronbachs \\(\\alpha\\) and item statistics with psych\n\n\n\n\nBefore we calculate Cronbachs \\(\\alpha\\), we remove (using the na.omit function) all incomplete cases from the data set.\n\n\nShow/hide codeitemDF &lt;- na.omit(exDat[names(mscItems)])\n\n\n\nGet the number of items (\\(p\\))\n\n\nShow/hide codep &lt;- length(mscItems)\n\n\n\nCalculate the sum (i.e., sum function) of \\(\\sigma_j^2\\) of all items using the apply function (see also above) and \\(\\sigma_Y^2\\) of the total score (that is calculated by the rowSums function; see below for a detailed description of the function).\n\n\nShow/hide codesigmaInd &lt;- sum(apply(itemDF, 2, sd)^2)\nsigmaTot &lt;- var(rowSums(itemDF))\n\n\n\nApply Equation 5.1\n\n\n\nShow/hide codealpha &lt;- (p/(p - 1)) * (1 - sigmaInd/ sigmaTot )\nalpha\n\n[1] 0.8496289\n\n\nAn important item statistics is the so-called Item whole correlation for this item against the scale without this item (in the alpha function from the psych package (Revelle 2023) this is called: r.drop).\n\nRecall, the names of the items are stored in the named list object (i.e., mscItems).\n\n\nShow/hide codenames(mscItems)\n\n[1] \"msc1\"  \"msc2\"  \"msc3r\" \"msc4r\"\n\n\n\nTo correlate the first item with the sum score, we use the cor function. To ignore the item when calculating the sum score, we state [-1] after the names call of the named list.\n\n\nShow/hide codecor(x = exDat[,\"msc1\"],\n    y = rowSums(exDat[names(mscItems)[-1]]),\n    use = \"pairwise.complete.obs\")\n\n[1] 0.6657391\n\n\n\nNow, we do it for all items. Therefore, we may use the sapply function. More specifically, we iterate through the item names (or to be precise, through the length of the item names)4. In the input argument x we (only) use the respective item [itemNr], while we ignore it [-itemNr] when calculating the sum score in the second input argument y.\n\n\nShow/hide codesapply(1:length(names(mscItems)),\n       function(itemNr) cor(x = exDat[,names(mscItems)[itemNr]],\n                            y = rowSums(exDat[names(mscItems)[-itemNr]]),\n                            use = \"pairwise.complete.obs\"))\n\n[1] 0.6657391 0.6269790 0.7422577 0.7205174\n\n\n\n\nIn the psych package (Revelle 2023), the alpha function is designed to calculate Cronbachs \\(\\alpha\\). The function has several input arguments (see ?psych::alpha), but requires only x: A data.frame or matrix of data, or a covariance or correlation matrix.\nThe function returns a couple of lists, including:\n\ndifferent \\(\\alpha\\) estimates (i.e., raw_alpha, std.alpha)\nitem statistics (e.g., item whole correlation corrected for item overlap and scale reliability, item whole correlation for this item against the scale without this item, …)\nresponse frequencies\ncalculated mean- or sum score (depending on the cumulative argument)\n…\n\n\nShow/hide codepsych::alpha(x = exDat[names(mscItems)])\n\n\nReliability analysis   \nCall: psych::alpha(x = exDat[names(mscItems)])\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.85      0.85    0.82      0.59 5.7 0.0089  2.5 0.62     0.57\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.83  0.85  0.87\nDuhachek  0.83  0.85  0.87\n\n Reliability if an item is dropped:\n      raw_alpha std.alpha G6(smc) average_r S/N alpha se   var.r med.r\nmsc1       0.82      0.82    0.76      0.60 4.5    0.012 0.01145  0.55\nmsc2       0.84      0.84    0.78      0.63 5.2    0.010 0.00617  0.59\nmsc3r      0.79      0.79    0.71      0.55 3.7    0.013 0.00080  0.55\nmsc4r      0.79      0.79    0.72      0.56 3.9    0.013 0.00063  0.55\n\n Item statistics \n        n raw.r std.r r.cor r.drop mean   sd\nmsc1  750  0.82  0.82  0.72   0.67  2.5 0.74\nmsc2  680  0.79  0.79  0.67   0.62  2.5 0.72\nmsc3r 750  0.87  0.86  0.82   0.74  2.5 0.75\nmsc4r 750  0.86  0.85  0.80   0.73  2.5 0.75\n\nNon missing response frequency for each item\n         1    2    3    4 miss\nmsc1  0.07 0.42 0.44 0.08 0.00\nmsc2  0.06 0.41 0.45 0.07 0.09\nmsc3r 0.07 0.42 0.43 0.08 0.00\nmsc4r 0.08 0.41 0.44 0.08 0.00"
  },
  {
    "objectID": "item-analy-descr.html#calculating-scale-scores",
    "href": "item-analy-descr.html#calculating-scale-scores",
    "title": "5  Descriptive statistics and item analysis",
    "section": "\n5.3 Calculating scale scores",
    "text": "5.3 Calculating scale scores\nNow, we calculate scale scores (i.e., \\(msc_{sum}\\), \\(msc_{avg}\\)) of the items \\(msc_1,msc_2,msc_3r,msc_{4r}\\).\n\n\n\n\n\n\nScale scores\n\n\n\nSome interesting reads: Widaman and Revelle (2022); McNeish and Wolf (2020); Rose et al. (2019)\n\n\n\n\nrowSums from base R\nscoreItems from psych\n\n\n\nThe rowSums function needs one input (copied from the function description):\n\n\nx: an array of two or more dimensions, containing numeric, complex, integer or logical values, or a numeric data frame.\n\nBut the na.rm argument needs special attention:\n\n\nna.rm: logical. Should missing values (including NaN) be omitted from the calculations?\n\nThis argument is important when some items have missing data. The question is: Should the scores be build based on the available items (this procedure is called person mean imputation) or discarded?\nEnders (2010) summarizes it as follows (p.51):\n\nUntil more research accumulates, you should use person mean imputation with caution and should perhaps avoid it altogether, particularly if there are high rates of item nonresponse.\n\nThis means, we set na.rm = FALSE. It is important to note, that there are options to circumvent this issue, such as a model-based estimation of composite scores (Rose et al. 2019) or multiple imputation (see e.g., Schafer and Graham 2002; Enders 2010)\n\nCalculation of the sum score\n\n\nShow/hide codeexDat$mscsum &lt;- rowSums(x = exDat[,names(mscItems)],\n                        na.rm = FALSE)\n\n\n\nCalculation of the average score\n\n\nShow/hide codeexDat$mscavg &lt;- rowSums(x = exDat[,names(mscItems)],\n                        na.rm = FALSE)/length(names(mscItems))\n\n\n\n\nTo calculate scale scores, you can also use the scoreItems function from the psych package (Revelle 2023).\nThe scoreItems function needs at least two inputs (copied from the package description):\n\n\nkeys: list of scoring keys or a matrix or data.frame of -1, 0, or 1 weights for each item on each scale which may be created by hand […]. Here we assign an equal weight (=1) for all items\n\nitems: Matrix or data.frame of raw item scores\n\nHowever, there a more input arguments that are important:\n\n\ntotals: if TRUE find total scores (!aka sum scores), if FALSE (default), find average scores\n\nmissing: missing = TRUE is the normal case and data are imputed according to the impute option. missing = FALSE, only complete cases are scored.\n\nIt is recommended to use missing = FALSE (see Approach 1: rowSums).\nBecause the function calculates several other statistics (e.g., Cronbachs \\(\\alpha\\), average correlation within a scale, …), we do it in two-step approach. Executing the function and save the information in an object, and then extracting (with the $ operator) the scores from the object (i.e., MscsumPsych$scores) while merging the scores with the example data set (i.e., by rownames via by = 0) . Merging is necessary because of missing = FALSE.\n\nCalculation of the sum score\n\n\nShow/hide codeMscsumPsych &lt;- psych::scoreItems(keys = rep(1, length(names(mscItems))),\n                                 items = exDat[,names(mscItems)],\n                                 totals = TRUE,\n                                 missing = FALSE,\n                                 min = 1,\n                                 max = 4)\n\n\ncolnames(MscsumPsych$scores) &lt;- \"mscsum2\"\n\nexDat &lt;- merge(exDat, MscsumPsych$scores,\n               by = 0,\n               all.x = T)\nexDat$Row.names &lt;- NULL\n\n\n\nCalculation of the average score\n\n\nShow/hide codeMscavgPsych &lt;- psych::scoreItems(keys = rep(1, length(names(mscItems))),\n                                 items = exDat[,names(mscItems)],\n                                 totals = FALSE,\n                                 missing = FALSE,\n                                 min = 1,\n                                 max = 4)\n\n\ncolnames(MscavgPsych$scores) &lt;- \"mscavg2\"\n\nexDat &lt;- merge(exDat, MscavgPsych$scores,\n               by = 0,\n               all.x = T)\nexDat$Row.names &lt;- NULL\n\n\n\n\n\n\n5.3.1 Calculating many scale scores\n\n\nShow/hide code#names(scaleList)\n\n\nThen using the sapply function to iterate through the list elements and applying the rowSums function. Note we calculate average scores, because we divide through the total score through the number of items.\n\nShow/hide codeexDat[,names(scaleList)] &lt;- sapply(scaleList,\n                                     function(s) rowSums(x = exDat[,s],\n                                                         na.rm = FALSE)/length(s),\n                                     simplify = FALSE)\n\n\n\n\n\n\n\n\nChalmers, Phil. 2022. Mirt: Multidimensional Item Response Theory. https://CRAN.R-project.org/package=mirt.\n\n\nCronbach, Lee J. 1951. “Coefficient Alpha and the Internal Structure of Tests.” Psychometrika 16 (3): 297–334. https://doi.org/10.1007/BF02310555.\n\n\nEnders, Craig K. 2010. Applied Missing Data Analysis. Methodology in the Social Sciences. New York: Guilford Press.\n\n\nFalissard, Bruno. 2022. Psy: Various Procedures Used in Psychometrics. https://CRAN.R-project.org/package=psy.\n\n\nMcNeish, Daniel. 2017. “Thanks Coefficient Alpha, We’ll Take It from Here.” Psychological Methods. https://doi.org/10.1037/met0000144.\n\n\nMcNeish, Daniel, and Melissa Gordon Wolf. 2020. “Thinking Twice about Sum Scores.” Behavior Research Methods 52 (6): 2287–2305. https://doi.org/10.3758/s13428-020-01398-0.\n\n\nRevelle, William. 2023. Psych: Procedures for Psychological, Psychometric, and Personality Research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf.\n\n\nRevelle, William, and Richard E. Zinbarg. 2009. “Coefficients Alpha, Beta, Omega, and the Glb: Comments on Sijtsma.” Psychometrika 74 (1): 145–54. https://doi.org/10.1007/s11336-008-9102-z.\n\n\nRizopoulos, Dimitris. 2022. Ltm: Latent Trait Models Under IRT. https://github.com/drizopoulos/ltm.\n\n\nRose, Norman, Wolfgang Wagner, Axel Mayer, and Benjamin Nagengast. 2019. “Model-Based Manifest and Latent Composite Scores in Structural Equation Models.” Collabra: Psychology 5 (1): 243. https://doi.org/10.1525/collabra.143.\n\n\nSavalei, Victoria, and Steven P. Reise. 2019. “Don’t Forget the Model in Your Model-Based Reliability Coefficients: A Reply to McNeish (2018).” Collabra: Psychology 5 (1): 36. https://doi.org/10.1525/collabra.247.\n\n\nSchafer, Joseph L., and John W. Graham. 2002. “Missing Data: Our View of the State of the Art.” Psychological Methods 7 (2): 147–77. https://doi.org/10.1037/1082-989X.7.2.147.\n\n\nSijtsma, Klaas. 2009. “On the Use, the Misuse, and the Very Limited Usefulness of Cronbach’s Alpha.” Psychometrika 74 (1): 107–20. https://doi.org/10.1007/s11336-008-9101-0.\n\n\nWidaman, Keith F., and William Revelle. 2022. “Thinking Thrice about Sum Scores, and Then Some More about Measurement and Analysis.” Behavior Research Methods. https://doi.org/10.3758/s13428-022-01849-w.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "item-analy-descr.html#footnotes",
    "href": "item-analy-descr.html#footnotes",
    "title": "5  Descriptive statistics and item analysis",
    "section": "",
    "text": "That is actually a three-step approach.↩︎\nIt is also possible to write a function in advance and use them in this argument. A short introduction how to write function can be found here.↩︎\nNote that this is actually not necessary.↩︎\nCheck it by writing: 1:length(names(mscItems))↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aden-Buie, Garrick, Barret Schloerke, JJ Allaire, and Alexander Rossell\nHayes. 2023. Learnr: Interactive Tutorials for r. https://CRAN.R-project.org/package=learnr.\n\n\nAllaire, JJ. 2022. Quarto: R Interface to Quarto Markdown Publishing\nSystem. https://github.com/quarto-dev/quarto-r.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier\nLuraschi, Kevin Ushey, Aron Atkins, et al. 2023. Rmarkdown: Dynamic\nDocuments for r. https://CRAN.R-project.org/package=rmarkdown.\n\n\nChalmers, Phil. 2022. Mirt: Multidimensional Item Response\nTheory. https://CRAN.R-project.org/package=mirt.\n\n\nCronbach, Lee J. 1951. “Coefficient Alpha and the Internal\nStructure of Tests.” Psychometrika 16 (3): 297–334. https://doi.org/10.1007/BF02310555.\n\n\nDowle, Matt, and Arun Srinivasan. 2023. Data.table: Extension of\n‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nEnders, Craig K. 2010. Applied Missing Data Analysis.\nMethodology in the Social Sciences. New York: Guilford\nPress.\n\n\nFalissard, Bruno. 2022. Psy: Various Procedures Used in\nPsychometrics. https://CRAN.R-project.org/package=psy.\n\n\nFox, John, Sanford Weisberg, and Brad Price. 2022. Car: Companion to\nApplied Regression. https://CRAN.R-project.org/package=car.\n\n\nMcNeish, Daniel. 2017. “Thanks Coefficient Alpha, We’ll Take It\nfrom Here.” Psychological Methods. https://doi.org/10.1037/met0000144.\n\n\nMcNeish, Daniel, and Melissa Gordon Wolf. 2020. “Thinking Twice\nabout Sum Scores.” Behavior Research Methods 52 (6):\n2287–2305. https://doi.org/10.3758/s13428-020-01398-0.\n\n\nPosit team. 2023. RStudio: Integrated Development Environment for\nr. Boston, MA: Posit Software, PBC. http://www.posit.co/.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nRevelle, William. 2023. Psych: Procedures for Psychological,\nPsychometric, and Personality Research. https://personality-project.org/r/psych/\nhttps://personality-project.org/r/psych-manual.pdf.\n\n\nRevelle, William, and Richard E. Zinbarg. 2009. “Coefficients\nAlpha, Beta, Omega, and the Glb: Comments on Sijtsma.”\nPsychometrika 74 (1): 145–54. https://doi.org/10.1007/s11336-008-9102-z.\n\n\nRizopoulos, Dimitris. 2022. Ltm: Latent Trait Models Under IRT.\nhttps://github.com/drizopoulos/ltm.\n\n\nRose, Norman, Wolfgang Wagner, Axel Mayer, and Benjamin Nagengast. 2019.\n“Model-Based Manifest and Latent Composite Scores in Structural\nEquation Models.” Collabra: Psychology 5 (1): 243. https://doi.org/10.1525/collabra.143.\n\n\nRosseel, Yves, Terrence D. Jorgensen, and Nicholas Rockwood. 2023.\nLavaan: Latent Variable Analysis. https://lavaan.ugent.be.\n\n\nSavalei, Victoria, and Steven P. Reise. 2019. “Don’t Forget the\nModel in Your Model-Based Reliability Coefficients: A Reply to McNeish\n(2018).” Collabra: Psychology 5 (1): 36. https://doi.org/10.1525/collabra.247.\n\n\nSchafer, Joseph L., and John W. Graham. 2002. “Missing Data: Our\nView of the State of the Art.” Psychological Methods 7\n(2): 147–77. https://doi.org/10.1037/1082-989X.7.2.147.\n\n\nSijtsma, Klaas. 2009. “On the Use, the Misuse, and the Very\nLimited Usefulness of Cronbach’s Alpha.” Psychometrika\n74 (1): 107–20. https://doi.org/10.1007/s11336-008-9101-0.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWidaman, Keith F., and William Revelle. 2022. “Thinking Thrice\nabout Sum Scores, and Then Some More about Measurement and\nAnalysis.” Behavior Research Methods. https://doi.org/10.3758/s13428-022-01849-w.\n\n\nWissik, T., and M. Ďurčo. 2015. “Research Data Workflows: From\nResearch Data Lifecycle Models to Institutional Solutions.”\nCLARIN 2015 Selected Papers, Linköping Electronic\nConference Proceedings, Annual Conference 2015, October 14–16, 2015,\nWroclaw, Poland (Pp. 94–107). Linköping University\nElectronic Press, Linköpings Universitet. http://www.ep.liu.se/ecp/123/008/ecp15123008.pdf.\n\n\nXie, Yihui. 2023. Knitr: A General-Purpose Package for Dynamic\nReport Generation in r. https://yihui.org/knitr/.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and\nPipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  }
]